{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP9418 Assignment2<br><br>\n",
    "student:<br>\n",
    "    z5192086, Pan Luo<br>\n",
    "    z5181142, Zhidong Luo<br>\n",
    "    z5190380, Jiawei Ren<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1  Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make division default to floating-point, saving confusion\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# ordered dictionaries are useful for keeping ordered sets of variables\n",
    "from collections import OrderedDict as odict\n",
    "# table formating for screen output\n",
    "from tabulate import tabulate\n",
    "from copy import deepcopy\n",
    "from itertools import compress, combinations, product\n",
    "from collections import defaultdict, Counter, deque\n",
    "from collections import OrderedDict as odict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from graphviz import Digraph, Graph\n",
    "import math\n",
    "import random\n",
    "import sys\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tute6\n",
    "tute_factor = {\n",
    "    'H': {\n",
    "        'dom': ('H'), \n",
    "        'table': odict([\n",
    "            ((0,), 0.80),\n",
    "            ((1,), 0.20),\n",
    "        ])\n",
    "    },\n",
    "    \n",
    "    'V': {\n",
    "        'dom': ('L', 'H', 'V'), \n",
    "        'table': odict([\n",
    "            ((0, 0, 0), 0.05),\n",
    "            ((0, 0, 1), 0.95),\n",
    "            ((0, 1, 0), 0.99),\n",
    "            ((0, 1, 1), 0.01),\n",
    "            ((1, 0, 0), 0),\n",
    "            ((1, 0, 1), 1),\n",
    "            ((1, 1, 0), 1),\n",
    "            ((1, 1, 1), 0),\n",
    "        ])\n",
    "    },\n",
    "\n",
    "    'C' : {\n",
    "        'dom': ('V', 'C'), \n",
    "        'table': odict([\n",
    "            ((0, 0), 0.94),\n",
    "            ((0, 1), 0.04),\n",
    "            ((0, 2), 0.02),\n",
    "            ((1, 0), 0.02),\n",
    "            ((1, 1), 0.26),\n",
    "            ((1, 2), 0.72),\n",
    "        ])\n",
    "    },\n",
    "\n",
    "    'L' : {\n",
    "        'dom': ('L'), \n",
    "        'table': odict([\n",
    "            ((0, ), 0.95),\n",
    "            ((1, ), 0.05),\n",
    "        ])\n",
    "    },\n",
    "\n",
    "    'S' : {\n",
    "        'dom': ('L', 'H', 'S'), \n",
    "        'table': odict([\n",
    "            ((0, 0, 0), 0.04),\n",
    "            ((0, 0, 1), 0.96),\n",
    "            ((0, 1, 0), 0.48),\n",
    "            ((0, 1, 1), 0.52),\n",
    "            ((1, 0, 0), 0.95),\n",
    "            ((1, 0, 1), 0.05),\n",
    "            ((1, 1, 0), 0),\n",
    "            ((1, 1, 1), 1),\n",
    "        ])\n",
    "    },\n",
    "\n",
    "    'O' : {\n",
    "        'dom': ('S', 'V', 'O'), \n",
    "        'table': odict([\n",
    "            ((0, 0, 0), 0.97),\n",
    "            ((0, 0, 1), 0.01),\n",
    "            ((0, 0, 2), 0.02),\n",
    "            ((0, 1, 0), 0.78),\n",
    "            ((0, 1, 1), 0.19),\n",
    "            ((0, 1, 2), 0.03),\n",
    "            ((1, 0, 0), 0.22),\n",
    "            ((1, 0, 1), 0.76),\n",
    "            ((1, 0, 2), 0.02),\n",
    "            ((1, 1, 0), 0.01),\n",
    "            ((1, 1, 1), 0.01),\n",
    "            ((1, 1, 2), 0.98),        \n",
    "        ])\n",
    "    },\n",
    "\n",
    "    'T': {\n",
    "        'dom': ('A', 'T'), \n",
    "        'table': odict([\n",
    "            ((0, 0), 0.30),\n",
    "            ((0, 1), 0.70),\n",
    "            ((1, 0), 1),\n",
    "            ((1, 1), 0),\n",
    "        ])\n",
    "    },\n",
    "\n",
    "    'B' : {\n",
    "        'dom': ('O', 'T', 'B'), \n",
    "        'table': odict([\n",
    "            ((0, 0, 0), 1),\n",
    "            ((0, 0, 1), 0),\n",
    "            ((0, 0, 2), 0),\n",
    "            ((0, 1, 0), 0.30),\n",
    "            ((0, 1, 1), 0.62),\n",
    "            ((0, 1, 2), 0.08),\n",
    "            ((1, 0, 0), 0.93),\n",
    "            ((1, 0, 1), 0.07),\n",
    "            ((1, 0, 2), 0),\n",
    "            ((1, 1, 0), 0.02),\n",
    "            ((1, 1, 1), 0.49),\n",
    "            ((1, 1, 2), 0.49),\n",
    "            ((2, 0, 0), 0.90),\n",
    "            ((2, 0, 1), 0.08),\n",
    "            ((2, 0, 2), 0.02),\n",
    "            ((2, 1, 0), 0.01),\n",
    "            ((2, 1, 1), 0.08),\n",
    "            ((2, 1, 2), 0.91),        \n",
    "        ])\n",
    "    },\n",
    "\n",
    "    'A' : {\n",
    "        'dom': ('A'), \n",
    "        'table': odict([\n",
    "            ((0, ), 0.99),\n",
    "            ((1, ), 0.01),\n",
    "        ])\n",
    "    }\n",
    "}\n",
    "tute_os = dict(\n",
    "    H=(0,1),\n",
    "    L=(0,1),\n",
    "    A=(0,1),\n",
    "    V=(0,1),\n",
    "    S=(0,1),\n",
    "    T=(0,1),\n",
    "    C=(0,1,2),\n",
    "    O=(0,1,2),\n",
    "    B=(0,1,2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printFactor(f):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f`, a factor to print on screen\n",
    "    \"\"\"\n",
    "    # Create a empty list that we will fill in with the probability table entries\n",
    "    table = list()\n",
    "    \n",
    "    # Iterate over all keys and probability values in the table\n",
    "    for key, item in f['table'].items():\n",
    "        # Convert the tuple to a list to be able to manipulate it\n",
    "        k = list(key)\n",
    "        # Append the probability value to the list with key values\n",
    "        k.append(item)\n",
    "        # Append an entire row to the table\n",
    "        table.append(k)\n",
    "    # dom is used as table header. We need it converted to list\n",
    "    dom = list(f['dom'])\n",
    "    # Append a 'Pr' to indicate the probabity column\n",
    "    dom.append('Pr')\n",
    "    print(tabulate(table,headers=dom,tablefmt='orgtbl'))\n",
    "\n",
    "\n",
    "def evidence(var, e, outcomeSpace):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `var`, a valid variable identifier.\n",
    "    `e`, the observed value for var.\n",
    "    `outcomeSpace`, dictionary with the domain of each variable\n",
    "    \n",
    "    Returns dictionary with a copy of outcomeSpace with var = e\n",
    "    \"\"\"    \n",
    "    newOutcomeSpace = outcomeSpace.copy()      # Make a copy of outcomeSpace with a copy to method copy(). 1 line\n",
    "    newOutcomeSpace[var] = (e,)                # Replace the domain of variable var with a tuple with a single element e. 1 line\n",
    "    return newOutcomeSpace\n",
    "    \n",
    "def join(f1, f2, outcomeSpace):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f1`, first factor to be joined.\n",
    "    `f2`, second factor to be joined.\n",
    "    `outcomeSpace`, dictionary with the domain of each variable\n",
    "    \n",
    "    Returns a new factor with a join of f1 and f2\n",
    "    \"\"\"\n",
    "    \n",
    "    # First, we need to determine the domain of the new factor. It will be union of the domain in f1 and f2\n",
    "    # But it is important to eliminate the repetitions\n",
    "    common_vars = list(f1['dom']) + list(set(f2['dom']) - set(f1['dom']))\n",
    "    \n",
    "    # We will build a table from scratch, starting with an empty list. Later on, we will transform the list into a odict\n",
    "    table = list()\n",
    "    \n",
    "    # Here is where the magic happens. The product iterator will generate all combinations of varible values \n",
    "    # as specified in outcomeSpace. Therefore, it will naturally respect observed values\n",
    "    for entries in product(*[outcomeSpace[node] for node in common_vars]):\n",
    "        \n",
    "        # We need to map the entries to the domain of the factors f1 and f2\n",
    "        entryDict = dict(zip(common_vars, entries))\n",
    "        f1_entry = (entryDict[var] for var in f1['dom'])\n",
    "        f2_entry = (entryDict[var] for var in f2['dom'])\n",
    "        \n",
    "        # Insert your code here\n",
    "        p1 = prob(f1, *f1_entry)           # Use the fuction prob to calculate the probability in factor f1 for entry f1_entry \n",
    "        p2 = prob(f2, *f2_entry)           # Use the fuction prob to calculate the probability in factor f2 for entry f2_entry \n",
    "        \n",
    "        # Create a new table entry with the multiplication of p1 and p2\n",
    "        table.append((entries, p1 * p2))\n",
    "    return {'dom': tuple(common_vars), 'table': odict(table)}\n",
    "\n",
    "\n",
    "def normalize(f):\n",
    "    table = list()\n",
    "    sum = 0\n",
    "    for k, p in f['table'].items():\n",
    "        sum = sum + p\n",
    "    for k, p in f['table'].items():\n",
    "        table.append((k, p/sum))\n",
    "    return {'dom': f['dom'], 'table': odict(table)}\n",
    "\n",
    "def prob(factor, *entry):\n",
    "    return factor['table'][entry]\n",
    "\n",
    "def marginalize(f, var, outcomeSpace):\n",
    "    # Let's make a copy of f domain and convert it to a list. We need a list to be able to modify its elements\n",
    "    new_dom = list(f['dom'])\n",
    "    new_dom.remove(var)            # Remove var from the list new_dom by calling the method remove(). 1 line\n",
    "    table = list()                 # Create an empty list for table. We will fill in table from scratch. 1 line\n",
    "    for entries in product(*[outcomeSpace[node] for node in new_dom]):\n",
    "        s = 0;                     # Initialize the summation variable s. 1 line\n",
    "        # We need to iterate over all possible outcomes of the variable var\n",
    "        for val in outcomeSpace[var]:\n",
    "            # To modify the tuple entries, we will need to convert it to a list\n",
    "            entriesList = list(entries)\n",
    "            # We need to insert the value of var in the right position in entriesList\n",
    "            entriesList.insert(f['dom'].index(var), val)\n",
    "            p = prob(f, *tuple(entriesList))     # Calculate the probability of factor f for entriesList. 1 line\n",
    "            s = s + p                            # Sum over all values of var by accumulating the sum in s. 1 line            \n",
    "        # Create a new table entry with the multiplication of p1 and p2\n",
    "        table.append((entries, s))\n",
    "    return {'dom': tuple(new_dom), 'table': odict(table)}\n",
    "   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1  Insert and remove nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.insert nodes\n",
    "def insert_nodes(factor, outcomespace, newNode, node_os):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `factor`, factor dictionary.\n",
    "    `outcomeSpace`, dictionary with the domain of each variable.\n",
    "    `newNode`, insered node name.\n",
    "    `node_os`, possible value for new node\n",
    "    \n",
    "    Returns a new factor and a new outcomespace\n",
    "    \"\"\"\n",
    "    f = deepcopy(factor)\n",
    "    os = deepcopy(outcomespace)\n",
    "    os[newNode] = node_os\n",
    "    f[newNode] = dict()\n",
    "    f[newNode]['dom'] = tuple([newNode])\n",
    "    # init all probability as 0\n",
    "    f[newNode]['table'] = odict.fromkeys(product(*[os[n] for n in list(f[newNode]['dom'])]), 0)\n",
    "    return f, os\n",
    "# test for insert node\n",
    "# insert_nodes(tute_factor,tute_os,'D',(0,1))\n",
    "# expected outpput\n",
    "# 'D': {'dom': ('D',), 'table': OrderedDict([((0,), 0), ((1,), 0)])}}\n",
    "\n",
    "#2.remove nodes\n",
    "def remove_nodes(factor, outcomespace, node):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `factor`, factor dictionary.\n",
    "    `outcomeSpace`, dictionary with the domain of each variable.\n",
    "    'node`, node name to be deleted.\n",
    "    \n",
    "    Returns a new factor and a new outcomespace\n",
    "    \"\"\"\n",
    "    f = deepcopy(factor)\n",
    "    os = deepcopy(outcomespace)\n",
    "    # disconnect all edges\n",
    "    for key in f.keys():\n",
    "        if key != node:\n",
    "            f, os = disconnect_nodes(f, os, key, node)\n",
    "    # deleted node\n",
    "    f.pop(node)\n",
    "    os.pop(node)\n",
    "    return f, os            \n",
    "# test for remove node\n",
    "# remove_nodes(tute_factor,tute_os,'V')\n",
    "# output will return the new factor and outcomespace without 'V'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2  Connect and disconnect nodes with edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.Connect nodes with edges.\n",
    "def connect_nodes(factor, outcomespace, node_a, node_b):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `factor`, factor dictionary.\n",
    "    `outcomeSpace`, dictionary with the domain of each variable.\n",
    "    `node_a`, source node name.\n",
    "    `node_b`, destination node name\n",
    "    \n",
    "    Returns a new factor and a new outcomespace\n",
    "    \"\"\"\n",
    "    f = deepcopy(factor)\n",
    "    os = deepcopy(outcomespace)\n",
    "    # check not connected before connect\n",
    "    if node_a == node_b:\n",
    "        return f, os\n",
    "    elif node_a in f[node_b]['dom']:\n",
    "        return f, os\n",
    "    else:\n",
    "        pass\n",
    "    firstnode = None\n",
    "    p = None\n",
    "    # join all nodes and get the joint distributino prob\n",
    "    for node in os.keys():\n",
    "        if firstnode is None:\n",
    "            firstnode = node\n",
    "            p = f[firstnode]\n",
    "        else:\n",
    "            p = join(p, f[node], os)\n",
    "    p = normalize(p)\n",
    "    # marginalise and get P(..., b)\n",
    "    ll = list(f[node_b]['dom']) + [node_a]\n",
    "    for node in os.keys():\n",
    "        if node not in ll:\n",
    "            p = marginalize(p, node, os)\n",
    "    \n",
    "    # marginalise b and get P(....)\n",
    "    p_x = marginalize(p, node_b, os)\n",
    "\n",
    "    # compute P(... | b) = P(..., b) / P(...)\n",
    "    for k in p_x['table']:\n",
    "        i = p_x['table'][k]\n",
    "        if p_x['table'][k] != 0:\n",
    "            p_x['table'][k] = 1 / p_x['table'][k]\n",
    "    p = join(p, p_x, os)\n",
    "#     printFactor(p)\n",
    "    f[node_b] = p\n",
    "    return f, os\n",
    "# test for connect node   \n",
    "# connect_nodes(tute_factor, tute_os, 'V', 'T')\n",
    "#  output will return the new factor and outcomespace with 'V' in 'T''s dom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.Disconnect nodes with edges.\n",
    "\n",
    "def disconnect_nodes(factor, outcomespace, node_a, node_b):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `factor`, factor dictionary.\n",
    "    `outcomeSpace`, dictionary with the domain of each variable.\n",
    "    `node_a`, first node\n",
    "    `node_b`, second node\n",
    "    \n",
    "    Returns a new factor and a new outcomespace\n",
    "    \"\"\"\n",
    "    f = deepcopy(factor)\n",
    "    os = deepcopy(outcomespace)\n",
    "    # check\n",
    "    if node_a == node_b:\n",
    "        return f, os\n",
    "    elif node_a in f[node_b]['dom']:\n",
    "        pass\n",
    "    # swap order\n",
    "    elif node_b in f[node_a]['dom']:\n",
    "        node_a, node_b = node_b, node_a\n",
    "    else:\n",
    "        return f, os\n",
    "    \n",
    "    # a in b. b->a P(b | ... - a) = P(..., b) / P(....)\n",
    "    \n",
    "    # step1 get p_join\n",
    "    # step1.5 normalise\n",
    "    # step2 marginalise (all except b, ...)\n",
    "    # step3 marginalise (b)\n",
    "    \n",
    "    # join and get the joint distribution prob\n",
    "    firstnode = None\n",
    "    p = None\n",
    "    for node in os.keys():\n",
    "        if firstnode is None:\n",
    "            firstnode = node\n",
    "            p = f[firstnode]\n",
    "        else:\n",
    "            p = join(p, f[node], os)\n",
    "    p = normalize(p)\n",
    "    # marginalise and get P(..., a, b)\n",
    "    for node in os.keys():\n",
    "        if node not in f[node_b]['dom']:\n",
    "            p = marginalize(p, node, os)\n",
    "    # marginalise a and get P(..., b)\n",
    "    p = marginalize(p, node_a, os)\n",
    "    # marginalise b and get P(....)\n",
    "    p_x = marginalize(p, node_b, os)\n",
    "    # compute P(...|b)\n",
    "    for k in p_x['table']:\n",
    "        i = p_x['table'][k]\n",
    "        if p_x['table'][k] != 0:\n",
    "            p_x['table'][k] = 1 / p_x['table'][k]\n",
    "    p = join(p, p_x, os)\n",
    "#     printFactor(p)\n",
    "    f[node_b] = p\n",
    "    return f, os\n",
    "    \n",
    "# test for disconnect node \n",
    "# disconnect_nodes(tute_factor, tute_os, 'T', 'B')\n",
    "# output will return the new factor and outcomespace with 'T' not in 'B''s dom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3  Specify probabilities for a node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.Specify probabilities for a node.\n",
    "def set_probability(factor, node, prob_dict):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `factor`, factor dictionary.\n",
    "    `node`, node name\n",
    "    `prob_dict`, a dictionary storing all prob\n",
    "    \n",
    "    Returns a new factor\n",
    "    \"\"\"\n",
    "    f = deepcopy(factor)\n",
    "    for key, prob in prob_dict.items():\n",
    "        f[node]['table'][key]  = prob\n",
    "    return f\n",
    "# test for this part\n",
    "# set_probability(tute_factor,'A',odict([((0, ), 0.69),((1, ), 0.31)]))\n",
    "#expected output\n",
    "# 'A': {'dom': 'A', 'table': OrderedDict([((0,), 0.69), ((1,), 0.31)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Save Bayesian network to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Save Bayesian network to a file.\n",
    "def save_to_file(factor, outcomespace ,file):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `factor`, factor dictionary.\n",
    "    `outcomeSpace`, dictionary with the domain of each variable.\n",
    "    `file`, file name.\n",
    "    \n",
    "    \"\"\"\n",
    "    with open(file ,\"w\") as f:\n",
    "        # header\n",
    "        print('net\\n{\\n}', file = f)\n",
    "        # write nodes in the file \n",
    "        for node in outcomespace.keys():\n",
    "            os = list(outcomespace[node])\n",
    "            os = [f'\"{o}\"' for o in os]\n",
    "            os = ' '.join(os)\n",
    "            print(os)\n",
    "            print(f'node {node}\\n{{\\n  states = ( {os} );\\n}}', file = f)\n",
    "        # write probability in the file\n",
    "        for node in factor:\n",
    "            if len(factor[node]['dom']) == 1:\n",
    "                data = list(factor[node][\"table\"].values())\n",
    "                data = ' '.join([str(d) for d in data])\n",
    "                print(f'potential ( {node} )\\n{{\\n  data = ( {data} );\\n}}', file = f)\n",
    "\n",
    "            else:\n",
    "                parent = list(factor[node][\"dom\"][:-1])\n",
    "                parent = ' '.join(parent)\n",
    "                data = list(factor[node][\"table\"].values())\n",
    "                data = [str(d) for d in data]\n",
    "                flag = 0\n",
    "                for n in factor[node][\"dom\"][-1::-1]:\n",
    "                    group_nb = len(data) // len(outcomespace[n])\n",
    "                    nb_of_group = len(outcomespace[n])\n",
    "    \n",
    "                    data = [data[nb_of_group * i: nb_of_group *  i + nb_of_group] for i in range(group_nb)]\n",
    "                    if flag == 0:\n",
    "                        data = [f'({\" \".join(i)})' for i in data]\n",
    "                        flag = 1\n",
    "                    else:\n",
    "                        data = [f'({\"\".join(i)})' for i in data]\n",
    "                print(f'potential ( {node} | {parent} )\\n{{\\n  data = {data[0]} ;\\n}}', file = f)\n",
    "#test code \n",
    "# save_to_file(tute_factor, tute_os ,'factor.net')                                                                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Load Bayesian network from a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7.Load Bayesian network from a file.\n",
    "def load_from_file(file):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `file`, input file name.\n",
    "    \n",
    "    Return a new factor and a new outcomespace\n",
    "    \"\"\"\n",
    "    with open(file ,\"r\") as f:\n",
    "        node = None\n",
    "        state = None\n",
    "        os = dict()\n",
    "        factor = {}\n",
    "        for i in f:\n",
    "            line = i.strip()\n",
    "            if line.startswith('net') or line.startswith('{') or line.startswith('}'):\n",
    "                pass\n",
    "            # get node name\n",
    "            elif line.startswith('node'):\n",
    "                node = line.split()[1].strip()\n",
    "                factor[node] = dict()\n",
    "            # get os\n",
    "            elif line.startswith('states'):\n",
    "                state_info = line[line.index('(') + 1: line.index(')')]\n",
    "                state_info = state_info.replace('\"', '').replace(\"'\", '')\n",
    "                state = tuple(state_info.split())\n",
    "                os[node] = state\n",
    "            # get relationship\n",
    "            elif line.startswith('potential'):\n",
    "                info = line[line.index('(') + 1: line.index(')')]\n",
    "                # conditional\n",
    "                if '|' in info :\n",
    "                    node = info.split('|')[0].strip()\n",
    "                    parent = info.split('|')[1].split()\n",
    "                    factor[node]['dom'] = tuple(parent + [node])\n",
    "                else:\n",
    "                    node = info.strip()\n",
    "                    factor[node]['dom'] = tuple([node])\n",
    "            # get prob\n",
    "            elif line.startswith('data'):\n",
    "                info = line[line.index('(') + 1: line.rindex(')')]\n",
    "                info_list = info.replace('(', ' ').replace(')', ' ').split()\n",
    "                it = iter(info_list)\n",
    "                factor[node]['table'] = odict.fromkeys(product(*[os[n] for n in list(factor[node]['dom'])]), 0)\n",
    "                for key in factor[node]['table'].keys():\n",
    "                    factor[node]['table'][key] = float(next(it))\n",
    "            else:\n",
    "                pass\n",
    "    return factor, os\n",
    "# test code\n",
    "# load_from_file('factor.net')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is our benchmark for task 1, we only test for loading some large network files to bayesian network and check the running time. Further analysis will be shown in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1 ms\n"
     ]
    }
   ],
   "source": [
    "#medium network with 37 nodes and 509 parameters\n",
    "%time f,s=load_from_file('alarm.net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.03 ms\n"
     ]
    }
   ],
   "source": [
    "#large network with 70 nodes and 1453 parameters\n",
    "%time f,s=load_from_file('hepar2.net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 83 ms\n"
     ]
    }
   ],
   "source": [
    "#very large network with 1051 nodes and 80592 parameters\n",
    "%time f,s=load_from_file('munin.net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_factor, small_os = load_from_file('asia.net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_factor, medium_os = load_from_file('child.net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_factor, large_os = load_from_file('hailfinder.net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "verylarge_factor, verylarge_os = load_from_file('pathfinder.net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "massive_factor, massive_os = load_from_file('munin.net')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2  Pruning and pre-processing techniques for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepocessing for task 2\n",
    "# convert factor to directed graph\n",
    "def factor_to_graph(f):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `factor`, factor dictionary.\n",
    "    \n",
    "    Return the directed grpah of f\n",
    "    \"\"\"\n",
    "    g = defaultdict(list)\n",
    "    for k in f.keys():\n",
    "        for n in list(f[k]['dom']):\n",
    "            if n == k:\n",
    "                continue\n",
    "            g[n].append(k)\n",
    "    return g\n",
    "    \n",
    "# change outcomespace to 0 1\n",
    "def ttransform(f, os):\n",
    "    ff = deepcopy(f)\n",
    "    o = deepcopy(os)\n",
    "    d = dict()\n",
    "    for k, v in os.items():\n",
    "        #v\n",
    "        d[k] = dict(zip(v, range(len(v))))\n",
    "        o[k] = tuple(list(range(len(v))))\n",
    "    \n",
    "    for k, v in f.items():\n",
    "        ff[k] = dict()\n",
    "        ff[k]['dom'] = f[k]['dom']\n",
    "        ff[k]['table'] = odict()\n",
    "        \n",
    "        for kk, vv in f[k]['table'].items():\n",
    "            it = iter(list(f[k]['dom']))\n",
    "            l = []\n",
    "            for i in kk:\n",
    "                node = next(it)\n",
    "                l.append(d[node][i])\n",
    "            l = tuple(l)\n",
    "            ff[k]['table'][l] = vv\n",
    "\n",
    "    return ff, o\n",
    "# printFactor(w_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_graph = {\n",
    "    'A': ['B', 'C'],\n",
    "    'B': ['D'],\n",
    "    'C': ['D', 'E'],\n",
    "\n",
    "}\n",
    "\n",
    "sample_factors = {\n",
    "    'A': {\n",
    "        'dom': ('A'), \n",
    "        'table': odict([\n",
    "            ((0,), 0.40),\n",
    "            ((1,), 0.60),\n",
    "        ])\n",
    "    },\n",
    "    \n",
    "    'B': {\n",
    "        'dom': ('A', 'B'), \n",
    "        'table': odict([\n",
    "            ((0, 0), 0.25),\n",
    "            ((0, 1), 0.75),\n",
    "            ((1, 0), 0.80),\n",
    "            ((1, 1), 0.20),\n",
    "        ])\n",
    "    },\n",
    "\n",
    "    'C' : {\n",
    "        'dom': ('A', 'C'), \n",
    "        'table': odict([\n",
    "            ((0, 0), 0.90),\n",
    "            ((0, 1), 0.10),\n",
    "            ((1, 0), 0.20),\n",
    "            ((1, 1), 0.80),\n",
    "        ])\n",
    "    },\n",
    "\n",
    "    'D' : {\n",
    "        'dom': ('B', 'C', 'D'), \n",
    "        'table': odict([\n",
    "            ((0, 0, 0), 1.00),\n",
    "            ((0, 0, 1), 0.00),\n",
    "            ((0, 1, 0), 0.20),\n",
    "            ((0, 1, 1), 0.80),\n",
    "            ((1, 0, 0), 0.10),\n",
    "            ((1, 0, 1), 0.90),\n",
    "            ((1, 1, 0), 0.05),\n",
    "            ((1, 1, 1), 0.95),\n",
    "            \n",
    "        ])\n",
    "    },\n",
    "\n",
    "    'E' : {\n",
    "        'dom': ('C', 'E'), \n",
    "        'table': odict([\n",
    "            ((0, 0), 1.00),\n",
    "            ((0, 1), 0.00),\n",
    "            ((1, 0), 0.30),\n",
    "            ((1, 1), 0.70),\n",
    "        ])\n",
    "    },\n",
    "\n",
    "}\n",
    "\n",
    "sample_outcomeSpace = dict(\n",
    "    A=(0,1),\n",
    "    B=(0,1),\n",
    "    C=(0,1),\n",
    "    D=(0,1),\n",
    "    E=(0,1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Network pruning techniques based on query structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to assignment 1, we use a numpy to represent the graph in adjacent matrix format. When removing a node, we delete the corresponding information in the factor. When removing an edge, we marginalise the corresponding information in the factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recursion function for removing leaf node\n",
    "def remove_leaf_r(matrix, l, union_set, F):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `matrix`, adjacent matrix for a graph\n",
    "    `l`, order list\n",
    "    `union_set`, a set containing nodes cannot be removed\n",
    "    `F`, factor\n",
    "    \n",
    "    Return matrix after removing all leaf nodes\n",
    "    \"\"\"\n",
    "    # get the number of outgoing edges\n",
    "    line_sum = np.sum(matrix, axis = 1)\n",
    "    # get the index of leaf nodes\n",
    "    bool_list = np.equal(line_sum, 0)\n",
    "    index_list = [*compress(range(matrix.shape[0]), bool_list)]\n",
    "    # we cannot delete leaf node which belongs to X ∪ Y ∪ Z\n",
    "    deleted_list = []\n",
    "    copied_list = index_list.copy()\n",
    "    for i in copied_list:\n",
    "        if l[i] in union_set:\n",
    "            index_list.remove(i)\n",
    "        else:\n",
    "            deleted_list.append(l[i])\n",
    "    # when we have leaf node to delete\n",
    "    if len(deleted_list) > 0:\n",
    "        # delete that leaf node. In numpy matrix, we delete the corresponding row and column\n",
    "        matrix = np.delete(matrix, index_list, axis = 0)\n",
    "        matrix = np.delete(matrix, index_list, axis = 1)\n",
    "        # update the nodes list\n",
    "        for i in deleted_list:\n",
    "            l.remove(i)\n",
    "            # remove node from factor\n",
    "            del F[i]\n",
    "        # recursively delete leaf nodes from the newly created graph\n",
    "        matrix = remove_leaf_r(matrix, l, union_set, F)\n",
    "    return matrix\n",
    "    \n",
    "# time comlexity: O(n + e)    \n",
    "def prune(G, F, outcomeSpace, Q, E):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `G`, graph dict\n",
    "    `F`, factor\n",
    "    `outcomeSpace`, outcomespace dict\n",
    "    `Q`, query variable\n",
    "    `E`, evidence dict\n",
    "    \n",
    "    \"\"\"\n",
    "    FF = deepcopy(F)\n",
    "    # get the union set of Q ∪ E\n",
    "    union_set = set(Q) | set(E.keys())\n",
    "    # get all nodes name\n",
    "    nodes = (set(G.keys()) | set(node for children in G.values() for node in children))\n",
    "    # sort nodes name\n",
    "    order_node_list = sorted(nodes)\n",
    "    # represent graph in a adjacent matrix using numpy\n",
    "    matrix = np.zeros((len(nodes), len(nodes)), dtype = int)\n",
    "    for key, values in G.items():\n",
    "        for value in values:\n",
    "            matrix[order_node_list.index(key), order_node_list.index(value)] = 1\n",
    "    # recursively remove leaf nodes\n",
    "    matrix = remove_leaf_r(matrix, order_node_list, union_set, FF)\n",
    "    # delete outgoing edges from Z\n",
    "    o = deepcopy(outcomeSpace)\n",
    "    for i in E.keys():\n",
    "        delete_edge_index = np.where(matrix[order_node_list.index(i)] > 0)\n",
    "        matrix[order_node_list.index(i), delete_edge_index] = 0\n",
    "        # marginalise to get the new prob\n",
    "        for index in delete_edge_index[0]:\n",
    "            node = order_node_list[index]\n",
    "            o = evidence(i, E[i], o)\n",
    "            FF[node] = marginalize(FF[node], i, o)\n",
    "            \n",
    "    # represent graph in a adjacent list format using python dictionary\n",
    "    G = dict()\n",
    "    for i in order_node_list:\n",
    "        G[i] = []\n",
    "    for i in range(matrix.shape[0]):\n",
    "        for j in range(matrix.shape[1]):\n",
    "            if matrix[i, j] > 0:\n",
    "                G[order_node_list[i]].append(order_node_list[j])\n",
    "    return G, FF, o\n",
    "\n",
    "##############################\n",
    "# Test code\n",
    "##############################\n",
    "graph1, F, o = prune(sample_graph, sample_factors, sample_outcomeSpace, {'D', 'E'}, {'A' : 1, 'C' : 0})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw the graph after pruning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"278pt\" height=\"116pt\"\r\n",
       " viewBox=\"0.00 0.00 278.00 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-112 274,-112 274,4 -4,4\"/>\r\n",
       "<!-- A -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>A</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">A</text>\r\n",
       "</g>\r\n",
       "<!-- B -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>B</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"99\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">B</text>\r\n",
       "</g>\r\n",
       "<!-- D -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>D</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"99\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">D</text>\r\n",
       "</g>\r\n",
       "<!-- B&#45;&gt;D -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>B&#45;&gt;D</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M99,-71.6966C99,-63.9827 99,-54.7125 99,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"102.5,-46.1043 99,-36.1043 95.5001,-46.1044 102.5,-46.1043\"/>\r\n",
       "</g>\r\n",
       "<!-- C -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>C</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"171\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"171\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">C</text>\r\n",
       "</g>\r\n",
       "<!-- E -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>E</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"243\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"243\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">E</text>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x13410306588>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# graphT = transposeGraph(graph)\n",
    "\n",
    "dot = Digraph(comment='Direct transpose graph GT')\n",
    "\n",
    "for v in graph1:\n",
    "    dot.node(str(v))\n",
    "\n",
    "for v in graph1:\n",
    "    for w in graph1[v]:\n",
    "        dot.edge(str(v), str(w))\n",
    "dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Min-fill heuristic for variable order elimination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tutorial minDegree\n",
    "def minDegree(ig):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `ig`, an induced graph,\n",
    "    Returns a elimination order according to the min-degree heuristic\n",
    "    \"\"\"      \n",
    "    # Initialize order with empty list. This variable will have the answer in the end of the execution\n",
    "    order = []\n",
    "    # While the induced graph has nodes to be eliminated\n",
    "    while ig:\n",
    "        # Initialize minDegree with a large number: math.inf\n",
    "        minDegree = math.inf\n",
    "        for var in ig.keys():\n",
    "            # Test if var has a degree smaller than minDegree\n",
    "            if len(ig[var]) < minDegree:\n",
    "                # We have found a new candidate to be the next eliminated variable. Let's save its degree and name\n",
    "                minDegree = len(ig[var])\n",
    "                minVar = var\n",
    "        # Insert in order the variable in minVar\n",
    "        order.append(minVar)\n",
    "        # Now, we need to remove minVar from the adjacency list of every node\n",
    "        for var in ig.keys():\n",
    "            if minVar in ig[var]:\n",
    "                ig[var].remove(minVar)\n",
    "        # As well as remove minVar adjacency list from the graph\n",
    "        del ig[minVar]\n",
    "    return order\n",
    "\n",
    "####################\n",
    "# Test code\n",
    "# minDegree(induceGraph(sample_factors, sample_outcomeSpace))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we finished minFill and Deterministic and stochastic composition of minFill and minDegree.<br>Specifically, minFill function is the simple minFill. minFill_then_minDegree function uses minFill firstly and uses minDegree to break ties. minDegree_then_minFill funtion uses minDegree firstly and uses minFill to break ties. stochastic_minDegree_and_minFill function uses a random number to decide to check minFill or minDegree firstly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transposeGraph(G):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `G`, a directed graph,\n",
    "    \n",
    "    Returns a transposed graph of G\n",
    "    \"\"\"      \n",
    "    GT = dict((v, []) for v in G)\n",
    "    for v in G:\n",
    "        for w in G[v]:\n",
    "            if w in GT:\n",
    "                GT[w].append(v)\n",
    "            else:\n",
    "                GT[w] = [v]\n",
    "    return GT\n",
    "#convert directed graph to undi graph\n",
    "def moralise(G):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `G`, a directed graph,\n",
    "    \n",
    "    Returns a moralised graph of G\n",
    "    \"\"\"\n",
    "    GT = transposeGraph(G)\n",
    "    MG = deepcopy(G)\n",
    "    for v in G:\n",
    "        for w in G[v]:\n",
    "            if w not in MG:\n",
    "                MG[w] = []\n",
    "            if v not in MG[w]:\n",
    "                MG[w].append(v)\n",
    "                \n",
    "    for v in GT:\n",
    "        if len(GT[v]) > 1:\n",
    "            for a, b in combinations(GT[v], 2):\n",
    "                if a not in MG[b]:\n",
    "                    MG[b].append(a)\n",
    "                    MG[a].append(b)\n",
    "    return MG\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def minFill(g):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `g`, an directed graph,\n",
    "    Returns a elimination order according to the min-fill heuristic\n",
    "    \"\"\"      \n",
    "    # Initialize order with empty list.\n",
    "    order = []\n",
    "    # moralise\n",
    "    mg = moralise(g)\n",
    "    v_list = [node for node in mg.keys()]\n",
    "    v_list.sort()\n",
    "    while mg:\n",
    "        minFill = math.inf\n",
    "        for var in v_list:\n",
    "            # compute fill-in node number\n",
    "            fill = 0\n",
    "            for a, b in combinations(mg[var], 2):\n",
    "                if a not in mg[b]:\n",
    "                    fill += 1\n",
    "            # get min fill-in node number\n",
    "            if fill < minFill:\n",
    "                minFill = fill\n",
    "                minVar = var\n",
    "        order.append(minVar)\n",
    "        # fill in\n",
    "        for a, b in combinations(mg[minVar], 2):\n",
    "            if a not in mg[b]:\n",
    "                mg[b].append(a)\n",
    "                mg[a].append(b)\n",
    "        # remove node we chose\n",
    "        for var in mg.keys():\n",
    "            if minVar in mg[var]:\n",
    "                mg[var].remove(minVar)\n",
    "        del mg[minVar]\n",
    "        v_list.remove(minVar)\n",
    "    return order\n",
    "\n",
    "def minFill_then_minDegree(g):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `g`, an directed graph,\n",
    "    Returns a elimination order according to the minFill_then_minDegree heuristic\n",
    "    \"\"\"    \n",
    "    # Initialize order with empty list.\n",
    "    order = []\n",
    "    mg = moralise(g)\n",
    "    v_list = [node for node in mg.keys()]\n",
    "    v_list.sort()\n",
    "    while mg:\n",
    "        minFill = math.inf\n",
    "        candidate = []\n",
    "        for var in v_list:\n",
    "            # compute fill-in node number\n",
    "            fill = 0\n",
    "            for a, b in combinations(mg[var], 2):\n",
    "                if a not in mg[b]:\n",
    "                    fill += 1\n",
    "            if fill < minFill:\n",
    "                minFill = fill\n",
    "                minVar = var\n",
    "                candidate = [minVar]\n",
    "            elif fill == minFill:\n",
    "                candidate.append(var)\n",
    "        # if we have multiple choice\n",
    "        if len(candidate) > 1:\n",
    "            # start minDegree\n",
    "            minDegree = math.inf\n",
    "            for var in candidate:\n",
    "                if len(mg[var]) < minDegree:\n",
    "                    minDegree = len(mg[var])\n",
    "                    minVar = var\n",
    "        order.append(minVar)\n",
    "        # fill in\n",
    "        for a, b in combinations(mg[minVar], 2):\n",
    "            if a not in mg[b]:\n",
    "                mg[b].append(a)\n",
    "                mg[a].append(b)\n",
    "        # remove the node we chose\n",
    "        for var in mg.keys():\n",
    "            if minVar in mg[var]:\n",
    "                mg[var].remove(minVar)\n",
    "        del mg[minVar]\n",
    "        v_list.remove(minVar)\n",
    "    return order\n",
    "\n",
    "def minDegree_then_minFill(g):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `g`, an directed graph,\n",
    "    Returns a elimination order according to the minDegree_then_minFill heuristic\n",
    "    \"\"\"       \n",
    "    # Initialize order with empty list.\n",
    "    order = []\n",
    "    mg = moralise(g)\n",
    "    v_list = [node for node in mg.keys()]\n",
    "    v_list.sort()\n",
    "    while mg:\n",
    "        candidate = []\n",
    "        # start minDegree\n",
    "        minDegree = math.inf\n",
    "        for var in v_list:\n",
    "            if len(mg[var]) < minDegree:\n",
    "                minDegree = len(mg[var])\n",
    "                minVar = var\n",
    "                candidate = [minVar]\n",
    "            elif len(mg[var]) == minDegree:\n",
    "                candidate.append(var)\n",
    "        # if we have multiple choice\n",
    "        if len(candidate) > 1:\n",
    "            # start minFill\n",
    "            minFill = math.inf\n",
    "            for var in candidate:\n",
    "                # compute the fill-in node number\n",
    "                fill = 0\n",
    "                for a, b in combinations(mg[var], 2):\n",
    "                    if a not in mg[b]:\n",
    "                        fill += 1\n",
    "                if fill < minFill:\n",
    "                    minFill = fill\n",
    "                    minVar = var\n",
    "        order.append(minVar)\n",
    "        # fill in\n",
    "        for a, b in combinations(mg[minVar], 2):\n",
    "            if a not in mg[b]:\n",
    "                mg[b].append(a)\n",
    "                mg[a].append(b)\n",
    "        # remove the node we chose\n",
    "        for var in mg.keys():\n",
    "            if minVar in mg[var]:\n",
    "                mg[var].remove(minVar)\n",
    "        del mg[minVar]\n",
    "        v_list.remove(minVar)\n",
    "    return order\n",
    "\n",
    "def stochastic_minDegree_and_minFill(g):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `g`, an directed graph,\n",
    "    Returns a elimination order according to the stochastic_minDegree_and_minFill heuristic\n",
    "    \"\"\"            \n",
    "    # Initialize order with empty list.\n",
    "    order = []\n",
    "    mg = moralise(g)\n",
    "    v_list = [node for node in mg.keys()]\n",
    "    v_list.sort()\n",
    "    while mg:\n",
    "        # start minDegree_then_minFill\n",
    "        if random.random() > 0.5:\n",
    "            candidate = []\n",
    "            minDegree = math.inf\n",
    "            for var in v_list:\n",
    "                if len(mg[var]) < minDegree:\n",
    "                    minDegree = len(mg[var])\n",
    "                    minVar = var\n",
    "                    candidate = [minVar]\n",
    "                elif len(mg[var]) == minDegree:\n",
    "                    candidate.append(var)\n",
    "            if len(candidate) > 1:\n",
    "                minFill = math.inf\n",
    "                for var in candidate:\n",
    "                    fill = 0\n",
    "                    for a, b in combinations(mg[var], 2):\n",
    "                        if a not in mg[b]:\n",
    "                            fill += 1\n",
    "                    if fill < minFill:\n",
    "                        minFill = fill\n",
    "                        minVar = var\n",
    "        # start minFill_then_minDegree\n",
    "        else:\n",
    "            minFill = math.inf\n",
    "            candidate = []\n",
    "            for var in v_list:\n",
    "                # var,\n",
    "                # mg[var]\n",
    "                fill = 0\n",
    "                for a, b in combinations(mg[var], 2):\n",
    "                    if a not in mg[b]:\n",
    "                        fill += 1\n",
    "                if fill < minFill:\n",
    "                    minFill = fill\n",
    "                    minVar = var\n",
    "                    candidate = [minVar]\n",
    "                elif fill == minFill:\n",
    "                    candidate.append(var)\n",
    "            if len(candidate) > 1:\n",
    "                # start minDegree\n",
    "                minDegree = math.inf\n",
    "                for var in candidate:\n",
    "                    if len(mg[var]) < minDegree:\n",
    "                        minDegree = len(mg[var])\n",
    "                        minVar = var\n",
    "        order.append(minVar)\n",
    "        for a, b in combinations(mg[minVar], 2):\n",
    "            if a not in mg[b]:\n",
    "                mg[b].append(a)\n",
    "                mg[a].append(b)\n",
    "        for var in mg.keys():\n",
    "            if minVar in mg[var]:\n",
    "                mg[var].remove(minVar)\n",
    "        del mg[minVar]\n",
    "        v_list.remove(minVar)\n",
    "    return order\n",
    "\n",
    "\n",
    "####################\n",
    "# Test code\n",
    "# t_graph = {'A': ['B', 'C'], 'B': ['A', 'C', 'D'], 'C': ['A', 'B', 'D', 'E'], 'D': ['B', 'C'], 'E': ['C']}\n",
    "\n",
    "# mg = moralise(t_graph)\n",
    "# order = minFill(t_graph)\n",
    "# print(order)\n",
    "# order = minFill_then_minDegree(t_graph)\n",
    "# print(order)\n",
    "# order = minDegree_then_minFill(t_graph)\n",
    "# print(order)\n",
    "# order = stochastic_minDegree_and_minFill(t_graph)\n",
    "# print(order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def induceGraph(factors, outcomeSpace):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `factors`, a dictionary of factors, each factor is a dictionary of domain and probability values,\n",
    "    `outcomeSpace`, a dictionary with variable names and respective domains.\n",
    "    Returns an adjacency list representation of the induced graph\n",
    "    \"\"\"        \n",
    "    # Initialize representation that is a dictionary of node ids\n",
    "    ig = {}\n",
    "    # Initialize each adjacency list with an empty list\n",
    "    for var in outcomeSpace.keys():\n",
    "        ig[var] = []\n",
    "    for f_id in factors.keys():\n",
    "        for var1 in factors[f_id]['dom']:\n",
    "            for var2 in factors[f_id]['dom']:\n",
    "                if var1 != var2 and var2 not in ig[var1]:\n",
    "                    # Connect node var1 with var2 by adding var2 in the adjaceny list of var1\n",
    "                    ig[var1].append(var2)\n",
    "    return ig\n",
    "\n",
    "def VE(factors, order, outcomeSpace):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `factors`, a dictionary of factors, each factor is a dictionary of domain and probability values,\n",
    "    `order`, a list of variable names specifying an elimination order,\n",
    "    `outcomeSpace`, a dictionary with variable names and respective domains.\n",
    "    Returns a dictionary with non-eliminated factors\n",
    "    \"\"\"    \n",
    "\n",
    "    # Let's make a copy of factors, so we can freely modify it without distroying the original dictionary\n",
    "    f = factors.copy()\n",
    "    # We process the factor in elimination order  \n",
    "    for i, var in enumerate(order):\n",
    "        # This is the domain of the new factor. We use sets as it is handy to eliminate duplicate variables\n",
    "        newFactorDom = set()\n",
    "        # This is a list of factors that will be removed from f because they were joined with other factors\n",
    "        listFactorsRemove = list()\n",
    "        # This is a flag to indicate if we are processing the first factor\n",
    "        first = True\n",
    "        # Lets iterate over all factors\n",
    "        for f_id in f.keys():\n",
    "            # and select the ones that have the variable to be eliminated\n",
    "            if var in f[f_id]['dom']:        \n",
    "                if first:\n",
    "                    # We need this code since join requires two factors, so we save the first one in fx and wait for the next\n",
    "                    fx = f[f_id]\n",
    "                    first = False\n",
    "                else:\n",
    "                    # Join fx and f[f_id] and save the result in fx\n",
    "                    fx = join(fx, f[f_id], outcomeSpace)\n",
    "                # f_id was joined, so we will need to eliminate it from f later. Let's save that factor id for future removal\n",
    "                listFactorsRemove.append(f_id)\n",
    "        # Now, we need to remove var from the domain of the new factor doing a marginalization              \n",
    "        fx = marginalize(fx, var, outcomeSpace)\n",
    "        # Now, we remove all factors that we joined in the simulation. We do it outside the for loop since it modifies the data structure\n",
    "        for f_id in listFactorsRemove:\n",
    "            del f[f_id]\n",
    "        # We will create a new factor with id equal a sequential number and insert it into f, so it can be used in future joins          \n",
    "        f[i] = fx\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join(f1, f2, outcomeSpace):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f1`, first factor to be joined.\n",
    "    `f2`, second factor to be joined.\n",
    "    `outcomeSpace`, dictionary with the domain of each variable\n",
    "    \n",
    "    Returns a new factor with a join of f1 and f2\n",
    "    \"\"\"\n",
    "    \n",
    "    #########################\n",
    "    # Insert your code here #\n",
    "    #########################\n",
    "    global muls\n",
    "\n",
    "    # First, we need to determine the domain of the new factor. It will be union of the domain in f1 and f2\n",
    "    # But it is important to eliminate the repetitions\n",
    "    common_vars = list(f1['dom']) + list(set(f2['dom']) - set(f1['dom']))\n",
    "    \n",
    "    # We will build a table from scratch, starting with an empty list. Later on, we will transform the list into a odict\n",
    "    table = list()\n",
    "    \n",
    "    # Here is where the magic happens. The product iterator will generate all combinations of varible values \n",
    "    # as specified in outcomeSpace. Therefore, it will naturally respect observed values\n",
    "    for entries in product(*[outcomeSpace[node] for node in common_vars]):\n",
    "        \n",
    "        # We need to map the entries to the domain of the factors f1 and f2\n",
    "        entryDict = dict(zip(common_vars, entries))\n",
    "        f1_entry = (entryDict[var] for var in f1['dom'])\n",
    "        f2_entry = (entryDict[var] for var in f2['dom'])\n",
    "        \n",
    "        # Insert your code here\n",
    "        p1 = prob(f1, *f1_entry)           # Use the fuction prob to calculate the probability in factor f1 for entry f1_entry \n",
    "        p2 = prob(f2, *f2_entry)           # Use the fuction prob to calculate the probability in factor f2 for entry f2_entry \n",
    "        \n",
    "        # Create a new table entry with the multiplication of p1 and p2\n",
    "        table.append((entries, p1 * p2))\n",
    "        \n",
    "        #########################\n",
    "        # Insert your code here #\n",
    "        #########################\n",
    "        muls = muls + 1\n",
    "    return {'dom': tuple(common_vars), 'table': odict(table)}\n",
    "\n",
    "\n",
    "\n",
    "def marginalize(f, var, outcomeSpace):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f`, factor to be marginalized.\n",
    "    `var`, variable to be summed out.\n",
    "    `outcomeSpace`, dictionary with the domain of each variable\n",
    "    \n",
    "    Returns a new factor f' with dom(f') = dom(f) - {var}\n",
    "    \"\"\"    \n",
    "\n",
    "    #########################\n",
    "    # Insert your code here #\n",
    "    #########################    \n",
    "    global adds\n",
    "\n",
    "    # Let's make a copy of f domain and convert it to a list. We need a list to be able to modify its elements\n",
    "    new_dom = list(f['dom'])\n",
    "    new_dom.remove(var)            # Remove var from the list new_dom by calling the method remove(). 1 line\n",
    "    table = list()                 # Create an empty list for table. We will fill in table from scratch. 1 line\n",
    "    for entries in product(*[outcomeSpace[node] for node in new_dom]):\n",
    "        s = 0;                     # Initialize the summation variable s. 1 line\n",
    "\n",
    "        # We need to iterate over all possible outcomes of the variable var\n",
    "        for val in outcomeSpace[var]:\n",
    "            # To modify the tuple entries, we will need to convert it to a list\n",
    "            entriesList = list(entries)\n",
    "            # We need to insert the value of var in the right position in entriesList\n",
    "            entriesList.insert(f['dom'].index(var), val)\n",
    "            \n",
    "            p = prob(f, *tuple(entriesList))     # Calculate the probability of factor f for entriesList. 1 line\n",
    "            s = s + p                            # Sum over all values of var by accumulating the sum in s. 1 line\n",
    "            \n",
    "            #########################\n",
    "            # Insert your code here #\n",
    "            #########################\n",
    "            adds = adds + 1\n",
    "            \n",
    "        # Create a new table entry with the multiplication of p1 and p2\n",
    "        table.append((entries, s))\n",
    "    return {'dom': tuple(new_dom), 'table': odict(table)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following is our benchmark on testing the difference of add and multiply times on different algorithm. We use min_Degree as comparison with our algorithm implmented in task2.2. Besides, we will do the test on different dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1e+03 µs\n",
      "60\n",
      "64\n",
      "Wall time: 0 ns\n",
      "46\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "# small dataset\n",
    "adds = 0\n",
    "muls = 0\n",
    "%time VE(small_factor, minDegree(factor_to_graph(small_factor)), small_os)\n",
    "print(adds)\n",
    "print(muls)\n",
    "adds = 0\n",
    "muls = 0\n",
    "%time VE(small_factor, minDegree_then_minFill(factor_to_graph(small_factor)), small_os)\n",
    "print(adds)\n",
    "print(muls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 107 ms\n",
      "24702\n",
      "27072\n",
      "Wall time: 5.04 ms\n",
      "672\n",
      "1518\n"
     ]
    }
   ],
   "source": [
    "# medium dataset\n",
    "adds = 0\n",
    "muls = 0\n",
    "%time VE(medium_factor, minDegree(factor_to_graph(medium_factor)), medium_os)\n",
    "print(adds)\n",
    "print(muls)\n",
    "adds = 0\n",
    "muls = 0\n",
    "%time VE(medium_factor, minDegree_then_minFill(factor_to_graph(medium_factor)), medium_os)\n",
    "print(adds)\n",
    "print(muls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that later on we will not use min_degree to make comparison, because we find that min_degree function can not be used for large dataset. We try to use min_degree on 'hailfinder.net' and it last for 10 minutes but the result still not come out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 38 ms\n",
      "11023\n",
      "11000\n"
     ]
    }
   ],
   "source": [
    "# large dataset\n",
    "# adds = 0\n",
    "# muls = 0\n",
    "\n",
    "# %time VE(large_factor, minDegree(factor_to_graph(large_factor)), large_os)\n",
    "# print(adds)\n",
    "# print(muls)\n",
    "adds = 0\n",
    "muls = 0\n",
    "%time VE(large_factor, minDegree_then_minFill(factor_to_graph(large_factor)), large_os)\n",
    "print(adds)\n",
    "print(muls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1 s\n",
      "205069\n",
      "259182\n"
     ]
    }
   ],
   "source": [
    "# very large dataset\n",
    "adds = 0\n",
    "muls = 0\n",
    "%time VE(verylarge_factor, minDegree_then_minFill(factor_to_graph(verylarge_factor)), verylarge_os)\n",
    "print(adds)\n",
    "print(muls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 49s\n",
      "21533030\n",
      "24445078\n"
     ]
    }
   ],
   "source": [
    "# massive dataset\n",
    "adds = 0\n",
    "muls = 0\n",
    "%time VE(massive_factor, minDegree_then_minFill(factor_to_graph(massive_factor)), massive_os)\n",
    "print(adds)\n",
    "print(muls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3  Exact inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1  A representation for the jointree that can be specified by the user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a dict to store a jointree, the key in this dict is the cluster in each node of jointree and the corresponding valve(s) is/are the neighbor(s). We also use a dict to store the seperator, the key is the union of two clusters, and value is the corresponding seperator between the edge of these two clusters. For task 3.1, we just build two dicts which users can enter the information of node and seperator. But in the later part, the jointree and corresponding seperators will build automatically from an elimination order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is a helper funtion and used for user input and it is useless in the implementation of other function later. From later \n",
    "# on we will generate a jointree and corresponding seperators from an elimination order.\n",
    "\n",
    "def specify_jointree(tree, S):\n",
    "#     format of tree:\n",
    "\n",
    "#     tree=dict(\n",
    "# #     enter the node and neighbors here, for example    \n",
    "# #     L= ('S'),\n",
    "# #     H= ('S'),\n",
    "    \n",
    "#     )\n",
    "\n",
    "#     format of seperator:\n",
    "    \n",
    "#     S=dict(\n",
    "# #     enter the union cluster and corresponding seperator here, for example\n",
    "# #     LS= ('L'),\n",
    "# #     HS= ('H'),\n",
    "              \n",
    "#     )\n",
    "    \n",
    "    return tree,S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 A function that converts an elimination order into a jointree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  We use the algorithm in the slides which converts an elimination order to a join tree. First, get all factors from an elimination order. Let's call them clusters. Then delete all the nonmaximum clusters. Then do assembly(add edge between clusters based on some rules). We will introduce each step in the algorithm specifically in the following functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Specify factors of the graph and corresponding outcomespace\n",
    "\n",
    "icu_factors = {\n",
    "    'H': {\n",
    "        'dom': ('H'),\n",
    "        'table': odict([\n",
    "            ((0,), 0.80),\n",
    "            ((1,), 0.20),\n",
    "        ])\n",
    "    },\n",
    "\n",
    "    'V': {\n",
    "        'dom': ('L', 'H', 'V'),\n",
    "        'table': odict([\n",
    "            ((0, 0, 0), 0.05),\n",
    "            ((0, 0, 1), 0.95),\n",
    "            ((0, 1, 0), 0.99),\n",
    "            ((0, 1, 1), 0.01),\n",
    "            ((1, 0, 0), 0),\n",
    "            ((1, 0, 1), 1),\n",
    "            ((1, 1, 0), 1),\n",
    "            ((1, 1, 1), 0),\n",
    "        ])\n",
    "    },\n",
    "\n",
    "    'C': {\n",
    "        'dom': ('V', 'C'),\n",
    "        'table': odict([\n",
    "            ((0, 0), 0.94),\n",
    "            ((0, 1), 0.04),\n",
    "            ((0, 2), 0.02),\n",
    "            ((1, 0), 0.02),\n",
    "            ((1, 1), 0.26),\n",
    "            ((1, 2), 0.72),\n",
    "        ])\n",
    "    },\n",
    "\n",
    "    'L': {\n",
    "        'dom': ('L'),\n",
    "        'table': odict([\n",
    "            ((0,), 0.95),\n",
    "            ((1,), 0.05),\n",
    "        ])\n",
    "    },\n",
    "\n",
    "    'S': {\n",
    "        'dom': ('L', 'H', 'S'),\n",
    "        'table': odict([\n",
    "            ((0, 0, 0), 0.04),\n",
    "            ((0, 0, 1), 0.96),\n",
    "            ((0, 1, 0), 0.48),\n",
    "            ((0, 1, 1), 0.52),\n",
    "            ((1, 0, 0), 0.95),\n",
    "            ((1, 0, 1), 0.05),\n",
    "            ((1, 1, 0), 0),\n",
    "            ((1, 1, 1), 1),\n",
    "        ])\n",
    "    },\n",
    "\n",
    "    'O': {\n",
    "        'dom': ('S', 'V', 'O'),\n",
    "        'table': odict([\n",
    "            ((0, 0, 0), 0.97),\n",
    "            ((0, 0, 1), 0.01),\n",
    "            ((0, 0, 2), 0.02),\n",
    "            ((0, 1, 0), 0.78),\n",
    "            ((0, 1, 1), 0.19),\n",
    "            ((0, 1, 2), 0.03),\n",
    "            ((1, 0, 0), 0.22),\n",
    "            ((1, 0, 1), 0.76),\n",
    "            ((1, 0, 2), 0.02),\n",
    "            ((1, 1, 0), 0.01),\n",
    "            ((1, 1, 1), 0.01),\n",
    "            ((1, 1, 2), 0.98),\n",
    "        ])\n",
    "    },\n",
    "\n",
    "    'T': {\n",
    "        'dom': ('A', 'T'),\n",
    "        'table': odict([\n",
    "            ((0, 0), 0.30),\n",
    "            ((0, 1), 0.70),\n",
    "            ((1, 0), 1),\n",
    "            ((1, 1), 0),\n",
    "        ])\n",
    "    },\n",
    "\n",
    "    'B': {\n",
    "        'dom': ('O', 'T', 'B'),\n",
    "        'table': odict([\n",
    "            ((0, 0, 0), 1),\n",
    "            ((0, 0, 1), 0),\n",
    "            ((0, 0, 2), 0),\n",
    "            ((0, 1, 0), 0.30),\n",
    "            ((0, 1, 1), 0.62),\n",
    "            ((0, 1, 2), 0.08),\n",
    "            ((1, 0, 0), 0.93),\n",
    "            ((1, 0, 1), 0.07),\n",
    "            ((1, 0, 2), 0),\n",
    "            ((1, 1, 0), 0.02),\n",
    "            ((1, 1, 1), 0.49),\n",
    "            ((1, 1, 2), 0.49),\n",
    "            ((2, 0, 0), 0.90),\n",
    "            ((2, 0, 1), 0.08),\n",
    "            ((2, 0, 2), 0.02),\n",
    "            ((2, 1, 0), 0.01),\n",
    "            ((2, 1, 1), 0.08),\n",
    "            ((2, 1, 2), 0.91),\n",
    "        ])\n",
    "    },\n",
    "\n",
    "    'A': {\n",
    "        'dom': ('A'),\n",
    "        'table': odict([\n",
    "            ((0,), 0.99),\n",
    "            ((1,), 0.01),\n",
    "        ])\n",
    "    }\n",
    "}\n",
    "\n",
    "outcomeSpace = dict(\n",
    "    H=(0, 1),\n",
    "    L=(0, 1),\n",
    "    A=(0, 1),\n",
    "    V=(0, 1),\n",
    "    S=(0, 1),\n",
    "    T=(0, 1),\n",
    "    C=(0, 1, 2),\n",
    "    O=(0, 1, 2),\n",
    "    B=(0, 1, 2),\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# A helper function to get all clusters in a jointree from an elimination order. Modifyied from VE function in tutorial.\n",
    "\n",
    "def ne(factors, order, outcomeSpace):\n",
    "    \"\"\"\n",
    "    argument\n",
    "    `factors`, a dictionary of factors, each factor is a dictionary of domain and probability values,\n",
    "    `order`, a list of variable names specifying an elimination order,\n",
    "    `outcomeSpace`, a dictionary with variable names and respective domains.\n",
    "    Returns two lists , node and edge\n",
    "    \"\"\"\n",
    "    node = []\n",
    "    edge = []\n",
    "    # Let's make a copy of factors, so we can freely modify it without distroying the original dictionary\n",
    "    f = factors.copy()\n",
    "    # We process the factor in elimination order\n",
    "    for i, var in enumerate(order):\n",
    "        # This is the domain of the new factor. We use sets as it is handy to eliminate duplicate variables\n",
    "        newFactorDom = set()\n",
    "        # This is a list of factors that will be removed from f because they were joined with other factors\n",
    "        listFactorsRemove = list()\n",
    "        # This is a flag to indicate if we are processing the first factor\n",
    "        first = True\n",
    "        # Lets iterate over all factors\n",
    "        for f_id in f.keys():\n",
    "            # and select the ones that have the variable to be eliminated\n",
    "            if var in f[f_id]['dom']:\n",
    "                if first:\n",
    "                    # We need this code since join requires two factors, so we save the first one in fx and wait for the next\n",
    "                    fx = f[f_id]\n",
    "                    first = False\n",
    "                else:\n",
    "                    # Join fx and f[f_id] and save the result in fx\n",
    "                    fx = join(fx, f[f_id], outcomeSpace)\n",
    "\n",
    "                # f_id was joined, so we will need to eliminate it from f later. Let's save that factor id for future removal\n",
    "                listFactorsRemove.append(f_id)\n",
    "                # print(listFactorsRemove)\n",
    "        # Now, we need to remove var from the domain of the new factor doing a marginalization\n",
    "        node.append(fx['dom'])\n",
    "        fx = marginalize(fx, var, outcomeSpace)\n",
    "        edge.append(fx['dom'])\n",
    "        # Now, we remove all factors that we joined in the simulation. We do it outside the for loop since it modifies the data structure\n",
    "        for f_id in listFactorsRemove:\n",
    "            del f[f_id]\n",
    "        # We will create a new factor with id equal a sequential number and insert it into f, so it can be used in future joins\n",
    "        f[i] = fx\n",
    "\n",
    "    return node,edge\n",
    "\n",
    "\n",
    "# Four helper functions which copied from tutorial\n",
    "\n",
    "def printFactor(f):\n",
    "    \"\"\"\n",
    "    argument\n",
    "    `f`, a factor to print on screen\n",
    "    \"\"\"\n",
    "    # Create a empty list that we will fill in with the probability table entries\n",
    "    table = list()\n",
    "\n",
    "    # Iterate over all keys and probability values in the table\n",
    "    for key, item in f['table'].items():\n",
    "        # Convert the tuple to a list to be able to manipulate it\n",
    "        k = list(key)\n",
    "        # Append the probability value to the list with key values\n",
    "        k.append(item)\n",
    "        # Append an entire row to the table\n",
    "        table.append(k)\n",
    "    # dom is used as table header. We need it converted to list\n",
    "    dom = list(f['dom'])\n",
    "    # Append a 'Pr' to indicate the probabity column\n",
    "    dom.append('Pr')\n",
    "    print(tabulate(table, headers=dom, tablefmt='orgtbl'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def prob(factor, *entry):\n",
    "    \"\"\"\n",
    "    argument\n",
    "    `factor`, a dictionary of domain and probability values,\n",
    "    `entry`, a list of values, one for each variable in the same order as specified in the factor domain.\n",
    "\n",
    "    Returns p(entry)\n",
    "    \"\"\"\n",
    "\n",
    "    return factor['table'][entry]  # insert your code here, 1 line\n",
    "\n",
    "\n",
    "def marginalize(f, var, outcomeSpace):\n",
    "    \"\"\"\n",
    "    argument\n",
    "    `f`, factor to be marginalized.\n",
    "    `var`, variable to be summed out.\n",
    "    `outcomeSpace`, dictionary with the domain of each variable\n",
    "\n",
    "    Returns a new factor f' with dom(f') = dom(f) - {var}\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    global adds\n",
    "\n",
    "    # Let's make a copy of f domain and convert it to a list. We need a list to be able to modify its elements\n",
    "    new_dom = list(f['dom'])\n",
    "    new_dom.remove(var)  # Remove var from the list new_dom by calling the method remove(). 1 line\n",
    "    table = list()  # Create an empty list for table. We will fill in table from scratch. 1 line\n",
    "    for entries in product(*[outcomeSpace[node] for node in new_dom]):\n",
    "        s = 0;  # Initialize the summation variable s. 1 line\n",
    "\n",
    "        # We need to iterate over all possible outcomes of the variable var\n",
    "        for val in outcomeSpace[var]:\n",
    "            # To modify the tuple entries, we will need to convert it to a list\n",
    "            entriesList = list(entries)\n",
    "            # We need to insert the value of var in the right position in entriesList\n",
    "            entriesList.insert(f['dom'].index(var), val)\n",
    "\n",
    "            p = prob(f, *tuple(entriesList))  # Calculate the probability of factor f for entriesList. 1 line\n",
    "            s = s + p  # Sum over all values of var by accumulating the sum in s. 1 line\n",
    "\n",
    "\n",
    "        # Create a new table entry with the multiplication of p1 and p2\n",
    "        table.append((entries, s))\n",
    "    return {'dom': tuple(new_dom), 'table': odict(table)}\n",
    "\n",
    "\n",
    "def join(f1, f2, outcomeSpace):\n",
    "    \"\"\"\n",
    "    argument\n",
    "    `f1`, first factor to be joined.\n",
    "    `f2`, second factor to be joined.\n",
    "    `outcomeSpace`, dictionary with the domain of each variable\n",
    "\n",
    "    Returns a new factor with a join of f1 and f2\n",
    "    \"\"\"\n",
    "\n",
    "    global muls\n",
    "\n",
    "    # First, we need to determine the domain of the new factor. It will be union of the domain in f1 and f2\n",
    "    # But it is important to eliminate the repetitions\n",
    "    common_vars = list(f1['dom']) + list(set(f2['dom']) - set(f1['dom']))\n",
    "\n",
    "    # We will build a table from scratch, starting with an empty list. Later on, we will transform the list into a odict\n",
    "    table = list()\n",
    "\n",
    "    # Here is where the magic happens. The product iterator will generate all combinations of varible values\n",
    "    # as specified in outcomeSpace. Therefore, it will naturally respect observed values\n",
    "    for entries in product(*[outcomeSpace[node] for node in common_vars]):\n",
    "        # We need to map the entries to the domain of the factors f1 and f2\n",
    "        entryDict = dict(zip(common_vars, entries))\n",
    "        f1_entry = (entryDict[var] for var in f1['dom'])\n",
    "        f2_entry = (entryDict[var] for var in f2['dom'])\n",
    "\n",
    "        # Insert your code here\n",
    "        p1 = prob(f1, *f1_entry)  # Use the fuction prob to calculate the probability in factor f1 for entry f1_entry\n",
    "        p2 = prob(f2, *f2_entry)  # Use the fuction prob to calculate the probability in factor f2 for entry f2_entry\n",
    "\n",
    "        # Create a new table entry with the multiplication of p1 and p2\n",
    "        table.append((entries, p1 * p2))\n",
    "\n",
    "\n",
    "    return {'dom': tuple(common_vars), 'table': odict(table)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is used for deleting the nonmaximum clusters from all clusters generated from an elimination order in \"ne\" function\n",
    "Deleting nonmaximum clusters and replace it with a superset to keep the running interception property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delculster(li):\n",
    "    \"\"\"\n",
    "    argument\n",
    "    `li`, a list which contain all clusters produced in an elimination order, including mamximum and nonmaximum cluster\n",
    "    \n",
    "    Returns a list of all maximum clusters\n",
    "    \"\"\"\n",
    "    for i in range(len(li)):\n",
    "        j=i+1\n",
    "        while j<len(li):\n",
    "            if set(li[j]).issubset(set(li[i])):\n",
    "                del li[j]\n",
    "                move_element = li.pop(i)\n",
    "                li.insert(j - 1, move_element)\n",
    "                i=j-1\n",
    "            else:\n",
    "                j=j+1\n",
    "    return li"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is used for adding edge to all maximum clusters, make sure that the sequence always keep running insetersection property .\n",
    "\n",
    "```\n",
    "Algorithm: C1,C2...Cn  <---cluster sequence induced by elimination order pai\n",
    "           T <--- {Cn}\n",
    "           for i <-- n-1,...,1 do \n",
    "           T <-- T U {Ci}\n",
    "           add edge between Ci and Cj\n",
    "           return T\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_edge(li):\n",
    "    \"\"\"\n",
    "    argument\n",
    "    `li`, a list which remove all nonmaximum clusters\n",
    "    \n",
    "\n",
    "    Returns a list indicates the edge which should be added in clusters\n",
    "    \"\"\"\n",
    "    \n",
    "    l = li.copy()\n",
    "    inte = []     #stand for intersection set \n",
    "    uni = []     #stand for union set\n",
    "    first = True\n",
    "#   Traverse the list，calculate the value of Ci & (Ci+1 U Ci+2 ... Cn） and save the value into inte[]\n",
    "    for i in range(len(l)):\n",
    "        if first:\n",
    "            uni.append(l[i])\n",
    "            first = False\n",
    "        else:\n",
    "            inte.append(set(l[i]) & set(\"\".join(uni)))\n",
    "            uni.append(l[i])\n",
    "    edge2 = []\n",
    "    uni2=[]\n",
    "#   Traverse list inte[] ，if one of the element in this list is a subset of cluster i，then add edge. Notice that the index in inte[]\n",
    "#   is always refer to the same location in  uni[]. So we can just traverse one list and add edge in one for loop.\n",
    "    for i in range(len(inte)):\n",
    "        for j in range(len(l)):\n",
    "            if inte[i].issubset(set(l[j])):\n",
    "                if i + 1 != j:\n",
    "                    edge2.append([j, i + 1])\n",
    "                    break   # break for avoid building a loop \n",
    "   \n",
    "    return edge2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is used for building join tree based on clusters and add_edge index. For example, if there is an edge index [0,1] which generated from \"add_edge\" function, then we will add an edge between cluster[0] and cluster[1]. In the dict, we will represent it by \n",
    "update {key[cluster[0]]:cluster[1]}. In order to represent the graph, we also add the reverse order {key[cluster[0]]:cluster[1]} in the\n",
    "jointree dict. But we make sure it is a tree structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_jointree(list1, list2):  # list 1 is inverted clusters, list 2 is edge index\n",
    "    \"\"\"\n",
    "    argument\n",
    "    `list1`, a list contains all clusters which follows the running intersection property\n",
    "    `list2`, a list indicates the edges between clusters\n",
    "    \n",
    "\n",
    "    Returns a dict of jointree\n",
    "    \"\"\"\n",
    "    l1 = list1.copy()\n",
    "    l2 = list2.copy()\n",
    "    jointree = defaultdict(list)\n",
    "    for i in range(len(l1)):\n",
    "        for j in range(len(l2)):\n",
    "            if l2[j][0] == i:\n",
    "                key = l1[i]\n",
    "                jointree[key].append(l1[l2[j][1]])\n",
    "    copy = jointree.copy()\n",
    "    for key in copy.keys():\n",
    "        for v in copy[key]:\n",
    "            if key not in jointree[v]:\n",
    "                jointree[v].append(key)\n",
    "    return dict(jointree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A helper function which represent a dict to a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawgraph(dic):\n",
    "    \"\"\"\n",
    "    argument\n",
    "    `dic`, a dict which indicates the jointree structure        \n",
    "    Returns a graph of jointree\n",
    "    \"\"\"\n",
    "    dot = Graph(comment='Tree', strict = True)\n",
    "    for v in dic:\n",
    "        dot.node(v)\n",
    "\n",
    "    for v in dic:\n",
    "        for w in dic[v]:\n",
    "            dot.edge(v, w)\n",
    "        \n",
    "    return dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following is the  auxiliary function for combine all the steps in converting an elimination orde to a jointree. The function receive three\n",
    "arguments: 1.An elimination order,type=str  2. Factors for one graph,type=dict 3.Outcomespace for corresponding factors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LHVS': ['SVO', 'VC'],\n",
       " 'SVO': ['OTB', 'LHVS'],\n",
       " 'OTB': ['AT', 'SVO'],\n",
       " 'VC': ['LHVS'],\n",
       " 'AT': ['OTB']}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def elimination_to_jointree(elimination_order,factors,outcomespace):\n",
    "    \"\"\"\n",
    "    argument\n",
    "    `elimination_order`, a tuple which indicates the elimination order\n",
    "    `factors`, a dict which refer to the oringin graph\n",
    "    'outcomespace', a dict which refer to the possible value for different variables\n",
    "    Returns a dict of jointree\n",
    "    \"\"\"\n",
    "    node,edge = ne(factors, elimination_order, outcomespace)\n",
    "    global order_list,edge_index\n",
    "    cluster = dict()\n",
    "    c2 = []\n",
    "    for i in range(len(node)):\n",
    "        c2.append(\"\".join(node[i]))\n",
    "    new_list = delculster(c2)\n",
    "    order_list = list(reversed(new_list))\n",
    "    edge_index = add_edge(order_list)\n",
    "    jointree = build_jointree(order_list, edge_index)\n",
    "    return jointree\n",
    "    \n",
    "elimination_to_jointree(('C', 'B', 'A', 'T', 'O', 'L', 'V', 'S', 'H'),icu_factors,outcomeSpace)\n",
    "\n",
    "# Just a remind that we add the inverse order for key[value] in the dict and save the jointree in this method. Two property of a jointree\n",
    "# 1. all maximum cluster is generated  by variable \"order_list\"        2. Adding edge method is generated by variable \"edge_index\"  \n",
    "# You can check the tree using the next cell's graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"138pt\" height=\"260pt\"\r\n",
       " viewBox=\"0.00 0.00 138.25 260.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 256)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-256 134.247,-256 134.247,4 -4,4\"/>\r\n",
       "<!-- LHVS -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>LHVS</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"66.2474\" cy=\"-234\" rx=\"34.394\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"66.2474\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">LHVS</text>\r\n",
       "</g>\r\n",
       "<!-- SVO -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>SVO</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"29.2474\" cy=\"-162\" rx=\"29.4969\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"29.2474\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">SVO</text>\r\n",
       "</g>\r\n",
       "<!-- LHVS&#45;&#45;SVO -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>LHVS&#45;&#45;SVO</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M57.4789,-216.411C51.5808,-205.252 43.8379,-190.604 37.9529,-179.47\"/>\r\n",
       "</g>\r\n",
       "<!-- VC -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>VC</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"103.247\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"103.247\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">VC</text>\r\n",
       "</g>\r\n",
       "<!-- LHVS&#45;&#45;VC -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>LHVS&#45;&#45;VC</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M75.0159,-216.411C80.914,-205.252 88.6569,-190.604 94.5419,-179.47\"/>\r\n",
       "</g>\r\n",
       "<!-- OTB -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>OTB</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"29.2474\" cy=\"-90\" rx=\"29.4969\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"29.2474\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">OTB</text>\r\n",
       "</g>\r\n",
       "<!-- SVO&#45;&#45;OTB -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>SVO&#45;&#45;OTB</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M29.2474,-143.697C29.2474,-132.846 29.2474,-118.917 29.2474,-108.104\"/>\r\n",
       "</g>\r\n",
       "<!-- AT -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>AT</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"29.2474\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"29.2474\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">AT</text>\r\n",
       "</g>\r\n",
       "<!-- OTB&#45;&#45;AT -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>OTB&#45;&#45;AT</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M29.2474,-71.6966C29.2474,-60.8463 29.2474,-46.9167 29.2474,-36.1043\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Graph at 0x1341037cda0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#draw the graph\n",
    "\n",
    "jointree=elimination_to_jointree(('C', 'B', 'A', 'T', 'O', 'L', 'V', 'S', 'H'),icu_factors,outcomeSpace)\n",
    "drawgraph(jointree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the way, we can use the following function to build a seperator for a jointree. Seperator will be used in the later query function when doing message propagation.This function receive two arguments which are the two key property for building a join tree in our method: \n",
    "```   \n",
    "1. A list which the expected input are all clusters in a jointree called \"order_list\"\n",
    "2. A list which the expected input are the add_edge index called \"edge_lidex\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LHVSSVO': 'VS', 'OTBSVO': 'O', 'ATOTB': 'T', 'LHVSVC': 'V'}\n"
     ]
    }
   ],
   "source": [
    "def build_seperator(li1,li2):\n",
    "    \"\"\"\n",
    "    argument\n",
    "    `li1`, a list which indicates all the maximum clusters\n",
    "    `li2`, a list which indicates the egde which should be added \n",
    "    \n",
    "\n",
    "    Returns a dict seperetors in one edge between two clusters\n",
    "    \"\"\"\n",
    "    l1=li1.copy()\n",
    "    l2=li2.copy()\n",
    "    new_d=dict()\n",
    "    for j in range(len(l2)):\n",
    "        s=\"\".join(set(l1[l2[j][0]])&set(l1[l2[j][1]]))\n",
    "        if s!='':\n",
    "            #use sorted in order to make the sequence of the key always equal to the key in push function\n",
    "            skey=sorted([l1[l2[j][0]],l1[l2[j][1]]]) \n",
    "            new_d[skey[0]+skey[1]]=s\n",
    "\n",
    "    return new_d\n",
    "\n",
    "\n",
    "S=build_seperator(order_list,edge_index)\n",
    "print(S)\n",
    "\n",
    "# The output is a dict. Key is the union of two clusters and the value is the seperator in the edge which between these two clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 A function to set evidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inclusion of evidence allows us to answer queries of the form $P(X, e)$ and, after normalization, $P(X|e)$. There are two main ways to include evidence:\n",
    "\n",
    "1. Eliminate the rows of the factors that do not match the evidence.\n",
    "2. Create a new factor, known as evidence indicator, that associates a value 1 to the evidence and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l= {'V': {'dom': ('V',), 'table': OrderedDict([((0,), 0), ((1,), 1)])}}\n",
      "new outcomeSpace= {'H': (0, 1), 'L': (0, 1), 'A': (0, 1), 'V': (1,), 'S': (0, 1), 'T': (0, 1), 'C': (0, 1, 2), 'O': (0, 1, 2), 'B': (0, 1, 2)}\n"
     ]
    }
   ],
   "source": [
    "# We make some modification of the evidence functino in the tutorial. We compute the new outcomeSpcae by evidence variable and its value,\n",
    "# then we return it.\n",
    "\n",
    "def set_evidence(outcomeSpace, **q_evi):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `outcomeSpace`, dictionary with the domain of each variable\n",
    "    `q_evi`, dictionary of evidence in the form of variables names and values\n",
    "    \n",
    "    Returns dictionary with evidence factors \n",
    "    \"\"\"     \n",
    "    # Create an empty dictionary\n",
    "    lambdas = dict()\n",
    "    newOutcomeSpace = outcomeSpace.copy()\n",
    "    for var, evi in q_evi.items():\n",
    "        # Create an empty dictionary insde lambdas\n",
    "        lambdas[var] = dict()\n",
    "        # Domain of the evidence indicator (single variable)\n",
    "        lambdas[var]['dom'] = tuple(var)\n",
    "        # Probability table for the evidence indicator \n",
    "        lambdas[var]['table'] = odict(((v,),int(v==evi)) for v in outcomeSpace[var])\n",
    "        newOutcomeSpace[var] = (evi,)\n",
    "    \n",
    "    return lambdas,newOutcomeSpace\n",
    "\n",
    "l,outspace = set_evidence(outcomeSpace, V=1)\n",
    "print(\"l=\",l)\n",
    "print(\"new outcomeSpace=\",outspace)\n",
    "\n",
    "# The output indicates the evidence variable dict and the new outcomeSpace dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4  A function to answer a query based on the jointree clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the marginals for one or more variables inside the same cluster. \n",
    "\n",
    "`queryCluster` takes as input a node and a query, among other arguments. The query is a list of variable names. All variables must be in the node cluster. The function returns the marginal distribution for those variables. We can also include an evidence in our query. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following are some helper functions which modified from the tutorial, we add normalize step in the message probagation part. Because we notice that\n",
    "if we do not do normalization, the result for query is a numerical value instead of a probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(f):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f`, factor to be normalized.\n",
    "    \n",
    "    Returns a new factor f' as a copy of f with entries that sum up to 1\n",
    "    \"\"\" \n",
    "    table = list()\n",
    "    sum = 0\n",
    "    for k, p in f['table'].items():\n",
    "        sum = sum + p\n",
    "    for k, p in f['table'].items():\n",
    "        table.append((k, p/sum))\n",
    "    return {'dom': f['dom'], 'table': odict(table)}\n",
    "\n",
    "\n",
    "def getMessages_e(factors, root, eTree, S, lambdas, outcomeSpace):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `factors`, dictionary with all factors.\n",
    "    `root`, root node.\n",
    "    `eTree`, elimination tree.\n",
    "    `S`, separators dictionary.\n",
    "    'lambdas', evidence factors\n",
    "    `outcomeSpace`, dictionary with the domain of each variable\n",
    "    \n",
    "    Returns dictionary with all messages\n",
    "    \"\"\"     \n",
    "    messages = dict()   \n",
    "    for v in eTree[root]:\n",
    "        messages[v+root] = pull_e(v, root, factors, eTree, S, messages, lambdas, outcomeSpace)\n",
    "\n",
    "    for v in eTree[root]:\n",
    "        messages[root+v] = factors[root]\n",
    "        if (root in lambdas.keys()):\n",
    "            messages[root+v] = join(messages[root+v], lambdas[root], outcomeSpace)        \n",
    "        for w in eTree[root]:\n",
    "            if not v == w:\n",
    "                messages[root+v] = join(messages[root+v], messages[w+root], outcomeSpace)\n",
    "        for w in messages[root+v]['dom']:\n",
    "            if not w in S[''.join(sorted([v,root]))]:               \n",
    "                messages[root+v] = marginalize(messages[root+v], w, outcomeSpace)        \n",
    "        push_e(v, root, factors, eTree, S, messages, lambdas, outcomeSpace)\n",
    "    return messages\n",
    "\n",
    "def pull_e(root, previous, factors, eTree, S, messages, lambdas, outcomeSpace):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `root`, current node.\n",
    "    `previous`, node we came from in the search.\n",
    "    `factors`, dictionary with all factors.\n",
    "    `eTree`, elimination tree.\n",
    "    `S`, separators dictionary.\n",
    "    'lambdas', evidence factors\n",
    "    `messages`, dictionary with messages.\n",
    "    `outcomeSpace`, dictionary with the domain of each variable\n",
    "    \n",
    "    Returns a factor fx with a message from node previous to root\n",
    "    \"\"\"\n",
    "    fx = factors[root]\n",
    "    if (root in lambdas.keys()):\n",
    "        fx = join(fx, lambdas[root], outcomeSpace)\n",
    "    for v in eTree[root]:\n",
    "        if not v == previous:\n",
    "            messages[v+root] = pull_e(v, root, factors, eTree, S, messages, lambdas, outcomeSpace)\n",
    "            fx = join(fx, messages[v+root], outcomeSpace)\n",
    "    for v in fx['dom']:\n",
    "        if not v in S[''.join(sorted([previous,root]))]:\n",
    "            fx = marginalize(fx, v, outcomeSpace)\n",
    "    return fx\n",
    "\n",
    "def push_e(root, previous, factors, eTree, S, messages, lambdas, outcomeSpace):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `root`, factor to be marginalized.\n",
    "    `previous`, variable to be summed out.\n",
    "    `factors`, dictionary with all factors.\n",
    "    `eTree`, elimination tree.\n",
    "    `S`, separators dictionary.\n",
    "    'lambdas', evidence factors\n",
    "    `messages`, dictionary with messages.\n",
    "    `outcomeSpace`, dictionary with the domain of each variable\n",
    "    \n",
    "    Returns a factor fx with a message from node previous to root\n",
    "    \"\"\"    \n",
    "    for v in eTree[root]:\n",
    "        if not v == previous:\n",
    "            messages[root+v] = factors[root]\n",
    "            if (root in lambdas.keys()):\n",
    "                messages[root+v] = join(messages[root+v], lambdas[root], outcomeSpace)\n",
    "            for w in eTree[root]:\n",
    "                if not v == w:\n",
    "                    messages[root+v] = join(messages[root+v], messages[w+root], outcomeSpace)\n",
    "\n",
    "            for w in messages[root+v]['dom']:\n",
    "                if not w in S[''.join(sorted([v,root]))]:                   \n",
    "                    messages[root+v] = marginalize(messages[root+v], w, outcomeSpace)\n",
    "            push_e(v, root, factors, eTree, S, messages, lambdas, outcomeSpace)\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "def join2(factors, order, outcomeSpace, li):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f1`, first factor to be joined.\n",
    "    `f2`, second factor to be joined.\n",
    "    `outcomeSpace`, dictionary with the domain of each variable\n",
    "    'li', a list which indicates all the clusters in a jointree\n",
    "    \n",
    "    Returns a new factor which equals to the clusters in a jointree\n",
    "    \"\"\"\n",
    "    # Let's make a copy of factors, so we can freely modify it without distroying the original dictionary\n",
    "    f = factors.copy()\n",
    "    l = li.copy()\n",
    "    nf={}\n",
    "    # We process the factor in elimination order\n",
    "    for i, var in enumerate(order):\n",
    "        # This is the domain of the new factor. We use sets as it is handy to eliminate duplicate variables\n",
    "        newFactorDom = set()\n",
    "        # This is a list of factors that will be removed from f because they were joined with other factors\n",
    "        listFactorsRemove = list()\n",
    "        # This is a flag to indicate if we are processing the first factor\n",
    "        first = True\n",
    "        # Lets iterate over all factors\n",
    "        for f_id in f.keys():\n",
    "            # and select the ones that have the variable to be eliminated\n",
    "            if var in f[f_id]['dom']:\n",
    "                if first:\n",
    "                    # We need this code since join requires two factors, so we save the first one in fx and wait for the next\n",
    "                    fx = f[f_id]\n",
    "                    first = False\n",
    "                else:\n",
    "                    # Join fx and f[f_id] and save the result in fx\n",
    "                    fx = join(fx, f[f_id], outcomeSpace)\n",
    "                # f_id was joined, so we will need to eliminate it from f later. Let's save that factor id for future removal\n",
    "                listFactorsRemove.append(f_id)\n",
    "                # print(listFactorsRemove)\n",
    "        # Now, we need to remove var from the domain of the new factor doing a marginalization\n",
    "        if \"\".join(fx['dom']) in l:\n",
    "            nf[\"\".join(fx['dom'])] = fx\n",
    "        #node.append(fx['dom'])\n",
    "        fx = marginalize(fx, var, outcomeSpace)\n",
    "        #edge.append(fx['dom'])\n",
    "        # Now, we remove all factors that we joined in the simulation. We do it outside the for loop since it modifies the data structure\n",
    "        for f_id in listFactorsRemove:\n",
    "            del f[f_id]\n",
    "        # We will create a new factor with id equal a sequential number and insert it into f, so it can be used in future joins\n",
    "        f[i] = fx\n",
    "    \n",
    "    return nf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is used to answer a query based on jointree clusters. In order to answer a such query, we need to probagate messages in \n",
    "the jointree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryCluster(factors, eTree, messages, node, query,outcomeSpace):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `factors`, dictionary with all factors.\n",
    "    `eTree`, elimination tree.\n",
    "    `messages`, dictionary with messages between neighbouring nodes\n",
    "    `node`, a node in the elimination tree whose cluster contain the query variables.\n",
    "    `query`, a list with query variables\n",
    "    'outcomeSpace', an outcomeSpace which consistent with the evidence\n",
    "    \n",
    "    Returns factor with the marginal for the query variables\n",
    "    \"\"\" \n",
    "    # fx is an auxiliary factor. Initialize fx with the factor associated with the root node    \n",
    "    fx = factors[node]    \n",
    "    for v in eTree[node]:\n",
    "        # Call join to multiply the incomming messages from all nodes but v        \n",
    "        fx = join(fx, messages[v+node], outcomeSpace)\n",
    "    for v in fx['dom']:\n",
    "        if not v in query:\n",
    "            # Call marginalize to remove variable v from fx domain            \n",
    "            fx = marginalize(fx, v, outcomeSpace)\n",
    "    return normalize(fx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following is a helper functino which converts a factor dict to a DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factor_to_graph(f):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `factor`, factor dictionary.\n",
    "    \n",
    "    Return the directed grpah of f\n",
    "    \"\"\"\n",
    "    g = defaultdict(list)\n",
    "    for k in f.keys():\n",
    "        for n in f[k]['dom']:\n",
    "            if n == k:\n",
    "                continue\n",
    "            g[n].append(k)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function  query_t3 is used for answering query for task 3.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   B |   Pr |\n",
      "|-----+------|\n",
      "|   0 | 0.02 |\n",
      "|   1 | 0.49 |\n",
      "|   2 | 0.49 |\n"
     ]
    }
   ],
   "source": [
    "def query_t3(factors,outcomeSpace,q_var,**e_var):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `factor`, factor dictionary.\n",
    "    `outcomeSpace`, factor dictionary.\n",
    "    `q_var`, factor dictionary.\n",
    "    `**e_var`, factor dictionary.\n",
    "    \n",
    "    Return the directed grpah of f\n",
    "    \"\"\"\n",
    "    # build a DAG from factors\n",
    "    graph=factor_to_graph(factors)\n",
    "    # generate the elimination order\n",
    "    order=stochastic_minDegree_and_minFill(graph)\n",
    "    # set evidence and compute new outcomeSpace\n",
    "    l,new_outSpace=set_evidence(outcomeSpace,**e_var)\n",
    "    #build jointree\n",
    "    jointree=elimination_to_jointree(order,factors,new_outSpace)\n",
    "    #select root and node\n",
    "    for k,v in jointree.items():\n",
    "        if set(''.join(q_var)).issubset(k):\n",
    "            node=k\n",
    "            root=k\n",
    "            break\n",
    "    # build seperator\n",
    "    S=build_seperator(order_list,edge_index)\n",
    "    # compute new_factor\n",
    "    new_fac=join2(factors, order, new_outSpace, order_list)\n",
    "    # message propagate\n",
    "    m = getMessages_e(new_fac, root, jointree, S,l, new_outSpace)\n",
    "    # answer query\n",
    "    answer=queryCluster(new_fac, jointree, m, node, q_var,new_outSpace)\n",
    "    return answer\n",
    "\n",
    "printFactor(query_t3(icu_factors,outcomeSpace,['B'],O=1,T=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Four functions that provide the following jointree transformations:    add a variable,      merge clusters, add a cluster and remove a cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following four transformations preserve all three properties of a jointree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.1 Add a variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's draw the graph of the oringinal jointree, in order to make comparison with the four different action "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original jointree is: {'LHVS': ['SVO', 'VC'], 'SVO': ['OTB', 'LHVS'], 'OTB': ['AT', 'SVO'], 'VC': ['LHVS'], 'AT': ['OTB']}\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"138pt\" height=\"260pt\"\r\n",
       " viewBox=\"0.00 0.00 138.25 260.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 256)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-256 134.247,-256 134.247,4 -4,4\"/>\r\n",
       "<!-- LHVS -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>LHVS</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"66.2474\" cy=\"-234\" rx=\"34.394\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"66.2474\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">LHVS</text>\r\n",
       "</g>\r\n",
       "<!-- SVO -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>SVO</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"29.2474\" cy=\"-162\" rx=\"29.4969\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"29.2474\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">SVO</text>\r\n",
       "</g>\r\n",
       "<!-- LHVS&#45;&#45;SVO -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>LHVS&#45;&#45;SVO</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M57.4789,-216.411C51.5808,-205.252 43.8379,-190.604 37.9529,-179.47\"/>\r\n",
       "</g>\r\n",
       "<!-- VC -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>VC</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"103.247\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"103.247\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">VC</text>\r\n",
       "</g>\r\n",
       "<!-- LHVS&#45;&#45;VC -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>LHVS&#45;&#45;VC</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M75.0159,-216.411C80.914,-205.252 88.6569,-190.604 94.5419,-179.47\"/>\r\n",
       "</g>\r\n",
       "<!-- OTB -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>OTB</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"29.2474\" cy=\"-90\" rx=\"29.4969\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"29.2474\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">OTB</text>\r\n",
       "</g>\r\n",
       "<!-- SVO&#45;&#45;OTB -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>SVO&#45;&#45;OTB</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M29.2474,-143.697C29.2474,-132.846 29.2474,-118.917 29.2474,-108.104\"/>\r\n",
       "</g>\r\n",
       "<!-- AT -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>AT</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"29.2474\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"29.2474\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">AT</text>\r\n",
       "</g>\r\n",
       "<!-- OTB&#45;&#45;AT -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>OTB&#45;&#45;AT</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M29.2474,-71.6966C29.2474,-60.8463 29.2474,-46.9167 29.2474,-36.1043\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Graph at 0x1341053c400>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jointree=elimination_to_jointree(('C', 'B', 'A', 'T', 'O', 'L', 'V', 'S', 'H'),icu_factors,outcomeSpace)\n",
    "print('Original jointree is:',jointree)\n",
    "drawgraph(jointree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is used to add a variable to a cluster in a jointree. \n",
    "Add variable: We can add a variable X to a cluster Ci as long as Ci has a neighbour Cj that contains X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_variable(dic,cluster,var):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    'dic', a dict which refer to a jointree\n",
    "    'cluster', a str which refer to a cluster in the jointree\n",
    "    'var', a str refer to a variable which you want to add\n",
    "    \n",
    "    Returns a new dict which refer to a jointree\n",
    "    \"\"\" \n",
    "    l1=order_list.copy()\n",
    "    l2=edge_index.copy()\n",
    "    d=copy.deepcopy(dic)\n",
    "    # if the input cluster is invaild, return False\n",
    "    if not cluster in l1:\n",
    "        return False\n",
    "    for j in range(len(l2)):\n",
    "        if l1[l2[j][0]]==cluster:\n",
    "            if set(var).issubset(set(l1[l2[j][1]])):\n",
    "                # update the jointree dict, using dict[key+var] to replace dict[key] and then delete dict[key], this is one way for update dict\n",
    "                d[cluster+var]=d[cluster]\n",
    "                del d[cluster] \n",
    "                # update the jointree dict, find all the value which is equal to the old cluster, replace it with cluster+var\n",
    "                for k,v in d.items():  \n",
    "                    for i in range(len(v)):\n",
    "                        if v[i]==cluster:\n",
    "                            v[i]=cluster+var\n",
    "                # add var only once, otherwise the var will add (how much neighbors contains var) times\n",
    "                break\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New jointree is: {'LHVS': ['SVOB', 'VC'], 'OTB': ['AT', 'SVOB'], 'VC': ['LHVS'], 'AT': ['OTB'], 'SVOB': ['OTB', 'LHVS']}\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"222pt\" height=\"116pt\"\r\n",
       " viewBox=\"0.00 0.00 222.00 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-112 218,-112 218,4 -4,4\"/>\r\n",
       "<!-- LHVS -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>LHVS</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"66\" cy=\"-90\" rx=\"34.394\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"66\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">LHVS</text>\r\n",
       "</g>\r\n",
       "<!-- VC -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>VC</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">VC</text>\r\n",
       "</g>\r\n",
       "<!-- LHVS&#45;&#45;VC -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>LHVS&#45;&#45;VC</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M56.7575,-72.411C50.5406,-61.2524 42.3791,-46.6036 36.1761,-35.4699\"/>\r\n",
       "</g>\r\n",
       "<!-- SVOB -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>SVOB</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"107\" cy=\"-18\" rx=\"35.194\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"107\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">SVOB</text>\r\n",
       "</g>\r\n",
       "<!-- LHVS&#45;&#45;SVOB -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>LHVS&#45;&#45;SVOB</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M75.7164,-72.411C82.2522,-61.2524 90.8322,-46.6036 97.3533,-35.4699\"/>\r\n",
       "</g>\r\n",
       "<!-- OTB -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>OTB</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"167\" cy=\"-90\" rx=\"29.4969\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"167\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">OTB</text>\r\n",
       "</g>\r\n",
       "<!-- AT -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>AT</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"187\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"187\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">AT</text>\r\n",
       "</g>\r\n",
       "<!-- OTB&#45;&#45;AT -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>OTB&#45;&#45;AT</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M171.841,-72.055C174.986,-61.0492 179.068,-46.7636 182.203,-35.789\"/>\r\n",
       "</g>\r\n",
       "<!-- OTB&#45;&#45;SVOB -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>OTB&#45;&#45;SVOB</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M153.981,-73.811C144.055,-62.2305 130.43,-46.3355 120.409,-34.644\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Graph at 0x13410543080>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test 1\n",
    "\n",
    "addv_jt=add_variable(jointree,\"SVO\",\"B\")\n",
    "print('New jointree is:',addv_jt)\n",
    "drawgraph(addv_jt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New jointree is: {'SVO': ['OTB', 'LHVSC'], 'OTB': ['AT', 'SVO'], 'VC': ['LHVSC'], 'AT': ['OTB'], 'LHVSC': ['SVO', 'VC']}\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"166pt\" height=\"188pt\"\r\n",
       " viewBox=\"0.00 0.00 165.54 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-184 161.544,-184 161.544,4 -4,4\"/>\r\n",
       "<!-- SVO -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>SVO</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"36.2474\" cy=\"-162\" rx=\"29.4969\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"36.2474\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">SVO</text>\r\n",
       "</g>\r\n",
       "<!-- OTB -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>OTB</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"29.2474\" cy=\"-90\" rx=\"29.4969\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"29.2474\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">OTB</text>\r\n",
       "</g>\r\n",
       "<!-- SVO&#45;&#45;OTB -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>SVO&#45;&#45;OTB</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M34.5171,-143.697C33.432,-132.846 32.0391,-118.917 30.9578,-108.104\"/>\r\n",
       "</g>\r\n",
       "<!-- LHVSC -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>LHVSC</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"117.247\" cy=\"-90\" rx=\"40.0939\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"117.247\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">LHVSC</text>\r\n",
       "</g>\r\n",
       "<!-- SVO&#45;&#45;LHVSC -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>SVO&#45;&#45;LHVSC</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M52.639,-146.834C66.2298,-135.089 85.5156,-118.423 99.4747,-106.359\"/>\r\n",
       "</g>\r\n",
       "<!-- AT -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>AT</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"29.2474\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"29.2474\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">AT</text>\r\n",
       "</g>\r\n",
       "<!-- OTB&#45;&#45;AT -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>OTB&#45;&#45;AT</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M29.2474,-71.6966C29.2474,-60.8463 29.2474,-46.9167 29.2474,-36.1043\"/>\r\n",
       "</g>\r\n",
       "<!-- VC -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>VC</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"117.247\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"117.247\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">VC</text>\r\n",
       "</g>\r\n",
       "<!-- VC&#45;&#45;LHVSC -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>VC&#45;&#45;LHVSC</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M117.247,-143.697C117.247,-132.846 117.247,-118.917 117.247,-108.104\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Graph at 0x1341053c9e8>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test 2\n",
    "\n",
    "addv_jt2=add_variable(jointree,\"LHVS\",\"C\")\n",
    "print('New jointree is:',addv_jt2)\n",
    "drawgraph(addv_jt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.2 Merge culsters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following function is used merge two clusters in a jointree\n",
    "We can merge two neighbouring clusters Ci and Cj into a single cluster Ck = Ci ∪ Cj, where Ck inherits the neighbours of Ci and Cj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_cluster(dic,c1,c2):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `dic`, a dict which refer to a jointree\n",
    "    'c1', a str refer to a cluster in a dict\n",
    "    'c2', a str refer to a cluster in a dict\n",
    "    \n",
    "     Returns a new dict which refer to a jointree\n",
    "    \"\"\" \n",
    "    d=copy.deepcopy(dic)\n",
    "    l1=order_list.copy()\n",
    "    l2=edge_index.copy()\n",
    "    newc=[]\n",
    "    c1neighbor=[]\n",
    "    c2neighbor=[]\n",
    "    # if cluster1 or cluster2 is not a cluster in jointree, return False\n",
    "    if not c1 in l1 or not c2 in l1:\n",
    "        return False\n",
    "    for k in d.keys():\n",
    "        if k==c1 or k==c2:\n",
    "            newc.append(k)\n",
    "    # add cluster to the jointree dict\n",
    "    for key,value in d.items():\n",
    "        if key==c1:\n",
    "            for i in range(len(value)):\n",
    "                if value[i]!=c2:\n",
    "                    c1neighbor.append(value[i])\n",
    "        if key==c2:\n",
    "            for i in range(len(value)):\n",
    "                if value[i]!=c1:\n",
    "                    c2neighbor.append(value[i])\n",
    "    # if cluster1 and cluster2 are not leaf node of a tree\n",
    "    if len(c1neighbor)>0 and len(c2neighbor)>0:\n",
    "        d[\"\".join(sorted(newc))]=[''.join(c1neighbor),''.join(c2neighbor)]\n",
    "    # if cluster1 is a leaf node of a tree\n",
    "    elif len(c1neighbor)==0 and len(c2neighbor)>0:\n",
    "        d[\"\".join(sorted(newc))]=[''.join(c2neighbor)]\n",
    "    # if cluster2 is a leaf node of a tree\n",
    "    else:\n",
    "        d[\"\".join(sorted(newc))]=[''.join(c1neighbor)]\n",
    "    del d[c1]\n",
    "    del d[c2]\n",
    "    #update the jointree dict, revome node which previous neighbor is c1 or c2, and insert the merged cluster to its neighbor\n",
    "    for k,v in d.items():\n",
    "        for j in range(len(v)):\n",
    "            if v[j]==c1 or v[j]==c2:\n",
    "                del v[j]\n",
    "                if len(v)==0:\n",
    "                    v.append(\"\".join(sorted(newc)))\n",
    "                break\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LHVS': ['VC'], 'VC': ['LHVS'], 'AT': ['OTBSVO'], 'OTBSVO': ['LHVS', 'AT']}\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"104pt\" height=\"260pt\"\r\n",
       " viewBox=\"0.00 0.00 104.19 260.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 256)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-256 100.191,-256 100.191,4 -4,4\"/>\r\n",
       "<!-- LHVS -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>LHVS</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"48.0957\" cy=\"-90\" rx=\"34.394\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"48.0957\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">LHVS</text>\r\n",
       "</g>\r\n",
       "<!-- VC -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>VC</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"48.0957\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"48.0957\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">VC</text>\r\n",
       "</g>\r\n",
       "<!-- LHVS&#45;&#45;VC -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>LHVS&#45;&#45;VC</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M48.0957,-71.6966C48.0957,-60.8463 48.0957,-46.9167 48.0957,-36.1043\"/>\r\n",
       "</g>\r\n",
       "<!-- AT -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>AT</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"48.0957\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"48.0957\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">AT</text>\r\n",
       "</g>\r\n",
       "<!-- OTBSVO -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>OTBSVO</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"48.0957\" cy=\"-162\" rx=\"48.1917\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"48.0957\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">OTBSVO</text>\r\n",
       "</g>\r\n",
       "<!-- AT&#45;&#45;OTBSVO -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>AT&#45;&#45;OTBSVO</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M48.0957,-215.697C48.0957,-204.846 48.0957,-190.917 48.0957,-180.104\"/>\r\n",
       "</g>\r\n",
       "<!-- OTBSVO&#45;&#45;LHVS -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>OTBSVO&#45;&#45;LHVS</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M48.0957,-143.697C48.0957,-132.846 48.0957,-118.917 48.0957,-108.104\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Graph at 0x1341034bcc0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test1\n",
    "\n",
    "merge_jt=merge_cluster(jointree,\"SVO\",\"OTB\")\n",
    "print(merge_jt)\n",
    "drawgraph(merge_jt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LHVS': ['SVO', 'VC'], 'SVO': ['LHVS'], 'VC': ['LHVS'], 'ATOTB': ['SVO']}\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"178pt\" height=\"116pt\"\r\n",
       " viewBox=\"0.00 0.00 178.04 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-112 174.043,-112 174.043,4 -4,4\"/>\r\n",
       "<!-- LHVS -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>LHVS</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"135.596\" cy=\"-90\" rx=\"34.394\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"135.596\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">LHVS</text>\r\n",
       "</g>\r\n",
       "<!-- SVO -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>SVO</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"51.5963\" cy=\"-18\" rx=\"29.4969\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"51.5963\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">SVO</text>\r\n",
       "</g>\r\n",
       "<!-- LHVS&#45;&#45;SVO -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>LHVS&#45;&#45;SVO</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M117.782,-74.1548C103.142,-61.9545 82.5537,-44.7978 68.2422,-32.8716\"/>\r\n",
       "</g>\r\n",
       "<!-- VC -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>VC</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"135.596\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"135.596\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">VC</text>\r\n",
       "</g>\r\n",
       "<!-- LHVS&#45;&#45;VC -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>LHVS&#45;&#45;VC</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M135.596,-71.6966C135.596,-60.8463 135.596,-46.9167 135.596,-36.1043\"/>\r\n",
       "</g>\r\n",
       "<!-- ATOTB -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>ATOTB</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"41.5963\" cy=\"-90\" rx=\"41.6928\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"41.5963\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">ATOTB</text>\r\n",
       "</g>\r\n",
       "<!-- ATOTB&#45;&#45;SVO -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>ATOTB&#45;&#45;SVO</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M44.0682,-71.6966C45.6183,-60.8463 47.6082,-46.9167 49.1528,-36.1043\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Graph at 0x1341037c400>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test2\n",
    "\n",
    "merge_jt2=merge_cluster(jointree,\"AT\",\"OTB\")\n",
    "print(merge_jt2)\n",
    "drawgraph(merge_jt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.3 Add a cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following function is used to add a cluster to a cluster existed in a jointree\n",
    "We can add a new cluster Cj and make it a neighbour of an existing cluster Ci as long as Cj ⊆ Ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cluster(dic,cluster,addCluster):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `dic`, a dict which refer to a jointree\n",
    "    'cluster', a str refer to a cluster in a dict\n",
    "    'addCluster', a str refer to a cluster which you want to add it into your jointree\n",
    "    \n",
    "    Returns a new dict which refer to a jointree\n",
    "    \"\"\" \n",
    "    d=copy.deepcopy(dic)\n",
    "    l1=order_list.copy()\n",
    "    l2=edge_index.copy()\n",
    "    # if the cluster which you want to add is not a subset of the target cluster, return False\n",
    "    if not set(addCluster).issubset(set(cluster)):\n",
    "        return False\n",
    "    # add the input cluster to target cluster and update the jointree dict\n",
    "    for k,v in d.items():\n",
    "        if k==cluster:\n",
    "            v.append(addCluster)\n",
    "            d[addCluster]=[cluster]\n",
    "            break # add just perform once, break for reducing the running time\n",
    "    return d\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LHVS': ['SVO', 'VC'], 'SVO': ['OTB', 'LHVS'], 'OTB': ['AT', 'SVO'], 'VC': ['LHVS', 'C'], 'AT': ['OTB'], 'C': ['VC']}\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"138pt\" height=\"260pt\"\r\n",
       " viewBox=\"0.00 0.00 138.25 260.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 256)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-256 134.247,-256 134.247,4 -4,4\"/>\r\n",
       "<!-- LHVS -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>LHVS</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"66.2474\" cy=\"-234\" rx=\"34.394\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"66.2474\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">LHVS</text>\r\n",
       "</g>\r\n",
       "<!-- SVO -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>SVO</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"29.2474\" cy=\"-162\" rx=\"29.4969\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"29.2474\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">SVO</text>\r\n",
       "</g>\r\n",
       "<!-- LHVS&#45;&#45;SVO -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>LHVS&#45;&#45;SVO</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M57.4789,-216.411C51.5808,-205.252 43.8379,-190.604 37.9529,-179.47\"/>\r\n",
       "</g>\r\n",
       "<!-- VC -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>VC</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"103.247\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"103.247\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">VC</text>\r\n",
       "</g>\r\n",
       "<!-- LHVS&#45;&#45;VC -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>LHVS&#45;&#45;VC</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M75.0159,-216.411C80.914,-205.252 88.6569,-190.604 94.5419,-179.47\"/>\r\n",
       "</g>\r\n",
       "<!-- OTB -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>OTB</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"29.2474\" cy=\"-90\" rx=\"29.4969\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"29.2474\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">OTB</text>\r\n",
       "</g>\r\n",
       "<!-- SVO&#45;&#45;OTB -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>SVO&#45;&#45;OTB</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M29.2474,-143.697C29.2474,-132.846 29.2474,-118.917 29.2474,-108.104\"/>\r\n",
       "</g>\r\n",
       "<!-- AT -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>AT</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"29.2474\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"29.2474\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">AT</text>\r\n",
       "</g>\r\n",
       "<!-- OTB&#45;&#45;AT -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>OTB&#45;&#45;AT</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M29.2474,-71.6966C29.2474,-60.8463 29.2474,-46.9167 29.2474,-36.1043\"/>\r\n",
       "</g>\r\n",
       "<!-- C -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>C</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"103.247\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"103.247\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">C</text>\r\n",
       "</g>\r\n",
       "<!-- VC&#45;&#45;C -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>VC&#45;&#45;C</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M103.247,-143.697C103.247,-132.846 103.247,-118.917 103.247,-108.104\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Graph at 0x13414888c88>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test1\n",
    "\n",
    "addc_jt=add_cluster(jointree,\"VC\",\"C\")\n",
    "print(addc_jt)\n",
    "drawgraph(addc_jt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LHVS': ['SVO', 'VC'], 'SVO': ['OTB', 'LHVS', 'S'], 'OTB': ['AT', 'SVO'], 'VC': ['LHVS'], 'AT': ['OTB'], 'S': ['SVO']}\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"175pt\" height=\"260pt\"\r\n",
       " viewBox=\"0.00 0.00 175.25 260.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 256)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-256 171.247,-256 171.247,4 -4,4\"/>\r\n",
       "<!-- LHVS -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>LHVS</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"103.247\" cy=\"-234\" rx=\"34.394\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"103.247\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">LHVS</text>\r\n",
       "</g>\r\n",
       "<!-- SVO -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>SVO</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"66.2474\" cy=\"-162\" rx=\"29.4969\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"66.2474\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">SVO</text>\r\n",
       "</g>\r\n",
       "<!-- LHVS&#45;&#45;SVO -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>LHVS&#45;&#45;SVO</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M94.4789,-216.411C88.5808,-205.252 80.8379,-190.604 74.9529,-179.47\"/>\r\n",
       "</g>\r\n",
       "<!-- VC -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>VC</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"140.247\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"140.247\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">VC</text>\r\n",
       "</g>\r\n",
       "<!-- LHVS&#45;&#45;VC -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>LHVS&#45;&#45;VC</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M112.016,-216.411C117.914,-205.252 125.657,-190.604 131.542,-179.47\"/>\r\n",
       "</g>\r\n",
       "<!-- OTB -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>OTB</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"29.2474\" cy=\"-90\" rx=\"29.4969\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"29.2474\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">OTB</text>\r\n",
       "</g>\r\n",
       "<!-- SVO&#45;&#45;OTB -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>SVO&#45;&#45;OTB</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M57.6659,-144.765C51.7738,-133.618 43.9761,-118.865 38.0393,-107.633\"/>\r\n",
       "</g>\r\n",
       "<!-- S -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>S</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"103.247\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"103.247\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">S</text>\r\n",
       "</g>\r\n",
       "<!-- SVO&#45;&#45;S -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>SVO&#45;&#45;S</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M74.8289,-144.765C80.8064,-133.456 88.7452,-118.437 94.7124,-107.147\"/>\r\n",
       "</g>\r\n",
       "<!-- AT -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>AT</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"29.2474\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"29.2474\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">AT</text>\r\n",
       "</g>\r\n",
       "<!-- OTB&#45;&#45;AT -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>OTB&#45;&#45;AT</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M29.2474,-71.6966C29.2474,-60.8463 29.2474,-46.9167 29.2474,-36.1043\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Graph at 0x134148881d0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test2\n",
    "\n",
    "addc_jt2=add_cluster(jointree,\"SVO\",\"S\")\n",
    "print(addc_jt2)\n",
    "drawgraph(addc_jt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.4 Delete a cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is used to delete a cluster in a jointree.\n",
    "We can add a new cluster Cj and make it a neighbour of an existing cluster Cj as long as Cj ⊆ Ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to delete a cluster in a jointree\n",
    "# We can add a new cluster Cj and make it a neighbour of an existing cluster Cj as long as Cj ⊆ Ci\n",
    "\n",
    "def del_cluster(dic,cluster):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `dic`, a dict which refer to a jointree\n",
    "    'cluster', a str refer to a cluster in a dict that you want to delete\n",
    "    \n",
    "    \n",
    "    Returns a new dict which refer to a jointree\n",
    "    \"\"\" \n",
    "    d=copy.deepcopy(dic)\n",
    "    l1=order_list.copy()\n",
    "    l2=edge_index.copy()\n",
    "    \n",
    "    # if the cluster you want to delete has more than one neighbor, return False\n",
    "    for k,v in d.items():\n",
    "        if k==cluster:\n",
    "            if len(v)>1:\n",
    "                return False                      \n",
    "            else: # first, delete the cluster key in the jointree dict\n",
    "                del d[cluster]\n",
    "                break #delete just perfrom once,break for reducing the running time\n",
    "    # then delete the cluster which appears in other key's value\n",
    "    for k2,v2 in d.items():\n",
    "        for i in range(len(v2)):\n",
    "            if v2[i]==cluster:\n",
    "                del v2[i]\n",
    "                break  # one value list only contains one delete cluster, so break to reduce running time\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LHVS': ['SVO', 'VC'], 'SVO': ['OTB', 'LHVS'], 'OTB': ['SVO'], 'VC': ['LHVS']}\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"138pt\" height=\"188pt\"\r\n",
       " viewBox=\"0.00 0.00 138.25 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-184 134.247,-184 134.247,4 -4,4\"/>\r\n",
       "<!-- LHVS -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>LHVS</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"66.2474\" cy=\"-162\" rx=\"34.394\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"66.2474\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">LHVS</text>\r\n",
       "</g>\r\n",
       "<!-- SVO -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>SVO</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"29.2474\" cy=\"-90\" rx=\"29.4969\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"29.2474\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">SVO</text>\r\n",
       "</g>\r\n",
       "<!-- LHVS&#45;&#45;SVO -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>LHVS&#45;&#45;SVO</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M57.4789,-144.411C51.5808,-133.252 43.8379,-118.604 37.9529,-107.47\"/>\r\n",
       "</g>\r\n",
       "<!-- VC -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>VC</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"103.247\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"103.247\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">VC</text>\r\n",
       "</g>\r\n",
       "<!-- LHVS&#45;&#45;VC -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>LHVS&#45;&#45;VC</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M75.0159,-144.411C80.914,-133.252 88.6569,-118.604 94.5419,-107.47\"/>\r\n",
       "</g>\r\n",
       "<!-- OTB -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>OTB</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"29.2474\" cy=\"-18\" rx=\"29.4969\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"29.2474\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">OTB</text>\r\n",
       "</g>\r\n",
       "<!-- SVO&#45;&#45;OTB -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>SVO&#45;&#45;OTB</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M29.2474,-71.6966C29.2474,-60.8463 29.2474,-46.9167 29.2474,-36.1043\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Graph at 0x134103b76a0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test1\n",
    "\n",
    "del_jt=del_cluster(jointree,\"AT\")\n",
    "print(del_jt)\n",
    "drawgraph(del_jt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LHVS': ['SVO'], 'SVO': ['OTB', 'LHVS'], 'OTB': ['AT', 'SVO'], 'AT': ['OTB']}\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"77pt\" height=\"260pt\"\r\n",
       " viewBox=\"0.00 0.00 76.89 260.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 256)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-256 72.8939,-256 72.8939,4 -4,4\"/>\r\n",
       "<!-- LHVS -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>LHVS</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"34.4469\" cy=\"-234\" rx=\"34.394\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"34.4469\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">LHVS</text>\r\n",
       "</g>\r\n",
       "<!-- SVO -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>SVO</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"34.4469\" cy=\"-162\" rx=\"29.4969\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"34.4469\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">SVO</text>\r\n",
       "</g>\r\n",
       "<!-- LHVS&#45;&#45;SVO -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>LHVS&#45;&#45;SVO</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M34.4469,-215.697C34.4469,-204.846 34.4469,-190.917 34.4469,-180.104\"/>\r\n",
       "</g>\r\n",
       "<!-- OTB -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>OTB</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"34.4469\" cy=\"-90\" rx=\"29.4969\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"34.4469\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">OTB</text>\r\n",
       "</g>\r\n",
       "<!-- SVO&#45;&#45;OTB -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>SVO&#45;&#45;OTB</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M34.4469,-143.697C34.4469,-132.846 34.4469,-118.917 34.4469,-108.104\"/>\r\n",
       "</g>\r\n",
       "<!-- AT -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>AT</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"34.4469\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"34.4469\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">AT</text>\r\n",
       "</g>\r\n",
       "<!-- OTB&#45;&#45;AT -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>OTB&#45;&#45;AT</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M34.4469,-71.6966C34.4469,-60.8463 34.4469,-46.9167 34.4469,-36.1043\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Graph at 0x13414888c50>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test2\n",
    "\n",
    "del_jt2=del_cluster(jointree,\"VC\")\n",
    "print(del_jt2)\n",
    "drawgraph(del_jt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is some benchmark for task3, we will analyse them in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to transform the str outcomeSpace to a integer outcomeSpace\n",
    "\n",
    "def ttransform(f, os):\n",
    "    ff = deepcopy(f)\n",
    "    o = deepcopy(os)\n",
    "    d = dict()\n",
    "    for k, v in os.items():\n",
    "        #v\n",
    "        d[k] = dict(zip(v, range(len(v))))\n",
    "        o[k] = tuple(list(range(len(v))))\n",
    "    \n",
    "    for k, v in f.items():\n",
    "        ff[k] = dict()\n",
    "        ff[k]['dom'] = f[k]['dom']\n",
    "        ff[k]['table'] = odict()\n",
    "        \n",
    "        for kk, vv in f[k]['table'].items():\n",
    "            it = iter(list(f[k]['dom']))\n",
    "            l = []\n",
    "            for i in kk:\n",
    "                node = next(it)\n",
    "                l.append(d[node][i])\n",
    "            l = tuple(l)\n",
    "            ff[k]['table'][l] = vv\n",
    "\n",
    "    return ff, o\n",
    "\n",
    "# This function is used to transform a factor to a directed graph\n",
    "\n",
    "def factor_to_graph(f):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `factor`, factor dictionary.\n",
    "    \n",
    "    Return the directed grpah of f\n",
    "    \"\"\"\n",
    "    g = defaultdict(list)\n",
    "    for k in f.keys():\n",
    "        for n in f[k]['dom']:\n",
    "            if n == k:\n",
    "                continue\n",
    "            g[n].append(k)\n",
    "    return g\n",
    "\n",
    "\n",
    "def width(factors, order):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `factors`, a dictionary of factors, each factor is a dictionary of domain and probability values,\n",
    "    `order`, a list of variable names specifying an elimination order.\n",
    "    \n",
    "    Returns the width of the elimination order, i.e., the number of variables of the largest factor\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Initialize w, a variable that has a width of the elimination order\n",
    "    w = 0\n",
    "    # Let's make a copy of factors, so we can freely modify it without distroying the original dictionary\n",
    "    f = factors.copy()\n",
    "    # We process the factor in elimination order\n",
    "    for i, var in enumerate(order):\n",
    "        # This is the domain of the new factor. We use sets as it is handy to eliminate duplicate variables\n",
    "        newFactorDom = set()\n",
    "        # This is a list of factors that will be removed from f because they were joined with other factors\n",
    "        listFactorsRemove = list()\n",
    "        # Lets iterate over all factors\n",
    "        for f_id in f.keys():\n",
    "            # and select the ones that have the variable to be eliminated\n",
    "            if var in f[f_id]['dom']:\n",
    "                # Merge the newFactorDomain list with the domain of f_id\n",
    "                newFactorDom.update(f[f_id]['dom'])\n",
    "                # Update the list of factors to remove by appending f_id\n",
    "                listFactorsRemove.append(f_id)\n",
    "        # Now, we need to remove var from the domain of the new factor. We are simulating a summation\n",
    "        newFactorDom.remove(var)            # Remove var from the list new_dom by calling the method remove(). 1 line\n",
    "        # Let's check if we have found a new largest factor\n",
    "        if len(newFactorDom) > w:\n",
    "            w = len(newFactorDom)\n",
    "        # Now, we remove all factors that we joined in the simulation. We do it outside the for loop since it modifies the data structure\n",
    "        for f_id in listFactorsRemove:\n",
    "            del f[f_id]\n",
    "        # We will create a new factor with id equal a sequential number and insert it into f, so it can be used in future joins\n",
    "        f[i] = dict()\n",
    "        # We only insert the factor domain, since it is all that we need to simulate the elimination and measure width\n",
    "        f[i]['dom'] = tuple(newFactorDom)\n",
    "    return w\n",
    "\n",
    "\n",
    "\n",
    "f,o=load_from_file('child.net')\n",
    "factors,outcomeSpace=ttransform(f,o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = stochastic_minDegree_and_minFill(factor_to_graph(factors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BirthAsphyxia',\n",
       " 'CO2Report',\n",
       " 'CO2',\n",
       " 'GruntingReport',\n",
       " 'LVHreport',\n",
       " 'LVH',\n",
       " 'RUQO2',\n",
       " 'XrayReport',\n",
       " 'Age',\n",
       " 'ChestXray',\n",
       " 'Grunting',\n",
       " 'LowerBodyO2',\n",
       " 'LungFlow',\n",
       " 'Sick',\n",
       " 'Disease',\n",
       " 'DuctFlow',\n",
       " 'CardiacMixing',\n",
       " 'HypDistrib',\n",
       " 'HypoxiaInO2',\n",
       " 'LungParench']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elimination order width: 3\n",
      "Wall time: 5.03 ms\n"
     ]
    }
   ],
   "source": [
    "# The first test, has 20 nodes and 230 parameters\n",
    "\n",
    "\n",
    "######################\n",
    "# Test code\n",
    "print(\"Elimination order width: %d\" % width(factors, order))\n",
    "\n",
    "%time jt=elimination_to_jointree(order,factors,outcomeSpace)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"1183pt\" height=\"188pt\"\r\n",
       " viewBox=\"0.00 0.00 1183.03 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-184 1179.03,-184 1179.03,4 -4,4\"/>\r\n",
       "<!-- CardiacMixingLungParenchHypoxiaInO2HypDistrib -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>CardiacMixingLungParenchHypoxiaInO2HypDistrib</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"941.484\" cy=\"-162\" rx=\"200.665\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"941.484\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">CardiacMixingLungParenchHypoxiaInO2HypDistrib</text>\r\n",
       "</g>\r\n",
       "<!-- DuctFlowCardiacMixingHypDistribLungParench -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>DuctFlowCardiacMixingHypDistribLungParench</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"539.484\" cy=\"-90\" rx=\"187.667\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"539.484\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">DuctFlowCardiacMixingHypDistribLungParench</text>\r\n",
       "</g>\r\n",
       "<!-- CardiacMixingLungParenchHypoxiaInO2HypDistrib&#45;&#45;DuctFlowCardiacMixingHypDistribLungParench -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>CardiacMixingLungParenchHypoxiaInO2HypDistrib&#45;&#45;DuctFlowCardiacMixingHypDistribLungParench</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M853.761,-145.725C786.071,-133.938 692.932,-117.72 625.64,-106.002\"/>\r\n",
       "</g>\r\n",
       "<!-- DiseaseSickLungParench -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>DiseaseSickLungParench</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"941.484\" cy=\"-90\" rx=\"102.882\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"941.484\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">DiseaseSickLungParench</text>\r\n",
       "</g>\r\n",
       "<!-- CardiacMixingLungParenchHypoxiaInO2HypDistrib&#45;&#45;DiseaseSickLungParench -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>CardiacMixingLungParenchHypoxiaInO2HypDistrib&#45;&#45;DiseaseSickLungParench</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M941.484,-143.697C941.484,-132.846 941.484,-118.917 941.484,-108.104\"/>\r\n",
       "</g>\r\n",
       "<!-- DiseaseLVH -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>DiseaseLVH</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1118.48\" cy=\"-90\" rx=\"56.59\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1118.48\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">DiseaseLVH</text>\r\n",
       "</g>\r\n",
       "<!-- CardiacMixingLungParenchHypoxiaInO2HypDistrib&#45;&#45;DiseaseLVH -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>CardiacMixingLungParenchHypoxiaInO2HypDistrib&#45;&#45;DiseaseLVH</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M983.88,-144.233C1014.66,-132.059 1055.77,-115.801 1084.43,-104.468\"/>\r\n",
       "</g>\r\n",
       "<!-- DiseaseDuctFlowCardiacMixingLungParench -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>DiseaseDuctFlowCardiacMixingLungParench</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"175.484\" cy=\"-18\" rx=\"175.469\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"175.484\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">DiseaseDuctFlowCardiacMixingLungParench</text>\r\n",
       "</g>\r\n",
       "<!-- DuctFlowCardiacMixingHypDistribLungParench&#45;&#45;DiseaseDuctFlowCardiacMixingLungParench -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>DuctFlowCardiacMixingHypDistribLungParench&#45;&#45;DiseaseDuctFlowCardiacMixingLungParench</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M459.603,-73.6382C398.599,-61.9067 314.963,-45.8229 254.24,-34.1453\"/>\r\n",
       "</g>\r\n",
       "<!-- DiseaseLungFlowLungParench -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>DiseaseLungFlowLungParench</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"492.484\" cy=\"-18\" rx=\"123.478\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"492.484\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">DiseaseLungFlowLungParench</text>\r\n",
       "</g>\r\n",
       "<!-- DuctFlowCardiacMixingHypDistribLungParench&#45;&#45;DiseaseLungFlowLungParench -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>DuctFlowCardiacMixingHypDistribLungParench&#45;&#45;DiseaseLungFlowLungParench</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M527.866,-71.6966C520.581,-60.8463 511.229,-46.9167 503.969,-36.1043\"/>\r\n",
       "</g>\r\n",
       "<!-- LungParenchLungFlowChestXray -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>LungParenchLungFlowChestXray</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"767.484\" cy=\"-18\" rx=\"133.776\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"767.484\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">LungParenchLungFlowChestXray</text>\r\n",
       "</g>\r\n",
       "<!-- DuctFlowCardiacMixingHypDistribLungParench&#45;&#45;LungParenchLungFlowChestXray -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>DuctFlowCardiacMixingHypDistribLungParench&#45;&#45;LungParenchLungFlowChestXray</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M592.653,-72.6765C629.891,-61.2435 679.378,-46.0503 716.195,-34.7467\"/>\r\n",
       "</g>\r\n",
       "<!-- DiseaseSickAge -->\r\n",
       "<g id=\"node8\" class=\"node\"><title>DiseaseSickAge</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"988.484\" cy=\"-18\" rx=\"69.5877\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"988.484\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">DiseaseSickAge</text>\r\n",
       "</g>\r\n",
       "<!-- DiseaseSickLungParench&#45;&#45;DiseaseSickAge -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>DiseaseSickLungParench&#45;&#45;DiseaseSickAge</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M952.862,-72.055C960.251,-61.0492 969.843,-46.7636 977.212,-35.789\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Graph at 0x1341055edd8>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drawgraph(jt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,o=load_from_file('andes.net')\n",
    "factors,outcomeSpace=ttransform(f,o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GIVEN_1',\n",
       " 'HORIZ53',\n",
       " 'TRY13',\n",
       " 'TRY14',\n",
       " 'TRY15',\n",
       " 'TRY12',\n",
       " 'TRY26',\n",
       " 'TRY25',\n",
       " 'CHOOSE19',\n",
       " 'CHOOSE35',\n",
       " 'CHOOSE47',\n",
       " 'CHOOSE62',\n",
       " 'DISPLACEM0',\n",
       " 'FIND58',\n",
       " 'GOAL_99',\n",
       " 'GIVEN21',\n",
       " 'GOAL_2',\n",
       " 'GRAV2',\n",
       " 'GRAV78',\n",
       " 'SNode_151',\n",
       " 'IDENTIFY22',\n",
       " 'IDENTIFY41',\n",
       " 'IDENTIFY59',\n",
       " 'KINEMATI17',\n",
       " 'KNOWN8',\n",
       " 'NEED1',\n",
       " 'NEWTONS45',\n",
       " 'RApp2',\n",
       " 'SLIDING4',\n",
       " 'SNode_15',\n",
       " 'SNode_24',\n",
       " 'SNode_31',\n",
       " 'SNode_40',\n",
       " 'SNode_46',\n",
       " 'SNode_9',\n",
       " 'SYSTEM46',\n",
       " 'TRY24',\n",
       " 'TRY76',\n",
       " 'VELOCITY7',\n",
       " 'WEIGHT57',\n",
       " 'WRITE30',\n",
       " 'APPLY32',\n",
       " 'GOAL_84',\n",
       " 'SNode_86',\n",
       " 'NORMAL52',\n",
       " 'RApp1',\n",
       " 'SNode_21',\n",
       " 'SNode_3',\n",
       " 'APPLY61',\n",
       " 'DEFINE23',\n",
       " 'FIND49',\n",
       " 'IDENTIFY10',\n",
       " 'IDENTIFY39',\n",
       " 'IDENTIFY43',\n",
       " 'IDENTIFY9',\n",
       " 'NORMAL50',\n",
       " 'SNode_25',\n",
       " 'RESOLVE37',\n",
       " 'RESOLVE38',\n",
       " 'RESOLVE40',\n",
       " 'RESOLVE42',\n",
       " 'SNode_17',\n",
       " 'SYSTEM18',\n",
       " 'SNode_68',\n",
       " 'GOAL_50',\n",
       " 'SNode_51',\n",
       " 'SNode_7',\n",
       " 'SNode_71',\n",
       " 'VECTOR70',\n",
       " 'WRITE31',\n",
       " 'WRITE63',\n",
       " 'SNode_156',\n",
       " 'APPLY77',\n",
       " 'GOAL_150',\n",
       " 'EQUAL71',\n",
       " 'SNode_119',\n",
       " 'SNode_52',\n",
       " 'FORCE60',\n",
       " 'NULL48',\n",
       " 'SNode_65',\n",
       " 'SNode_5',\n",
       " 'SNode_6',\n",
       " 'TRY11',\n",
       " 'GOAL_48',\n",
       " 'WEIGHT56',\n",
       " 'WRITE64',\n",
       " 'GOAL_104',\n",
       " 'GOAL_149',\n",
       " 'GOAL_49',\n",
       " 'SNode_120',\n",
       " 'SNode_123',\n",
       " 'GOAL_57',\n",
       " 'GOAL_61',\n",
       " 'SNode_124',\n",
       " 'SNode_13',\n",
       " 'GOAL_81',\n",
       " 'RApp4',\n",
       " 'SNode_134',\n",
       " 'SNode_10',\n",
       " 'SNode_135',\n",
       " 'SNode_38',\n",
       " 'SNode_136',\n",
       " 'SNode_155',\n",
       " 'KINE29',\n",
       " 'SNode_44',\n",
       " 'SNode_54',\n",
       " 'BUGGY54',\n",
       " 'SNode_118',\n",
       " 'SNode_47',\n",
       " 'INCLINE51',\n",
       " 'SNode_12',\n",
       " 'STRAT_90',\n",
       " 'GOAL65',\n",
       " 'GOAL66',\n",
       " 'GOAL72',\n",
       " 'NEED67',\n",
       " 'SNode_106',\n",
       " 'SNode_152',\n",
       " 'SNode_59',\n",
       " 'SNode_60',\n",
       " 'SNode_11',\n",
       " 'SNode_16',\n",
       " 'SNode_41',\n",
       " 'SNode_55',\n",
       " 'GOAL_80',\n",
       " 'KNOWN6',\n",
       " 'SNode_8',\n",
       " 'RApp3',\n",
       " 'SNode_26',\n",
       " 'SNode_27',\n",
       " 'SNode_42',\n",
       " 'IDENTIFY55',\n",
       " 'RApp10',\n",
       " 'RApp5',\n",
       " 'RApp8',\n",
       " 'AXIS33',\n",
       " 'MAXIMIZE34',\n",
       " 'SNode_115',\n",
       " 'GOAL_98',\n",
       " 'CONSTANT5',\n",
       " 'SNode_131',\n",
       " 'SNode_117',\n",
       " 'SNode_133',\n",
       " 'GOAL_143',\n",
       " 'GOAL_56',\n",
       " 'GOAL_63',\n",
       " 'SNode_34',\n",
       " 'GOAL_66',\n",
       " 'GOAL_69',\n",
       " 'RApp11',\n",
       " 'RApp13',\n",
       " 'SNode_102',\n",
       " 'VAR20',\n",
       " 'VALUE3',\n",
       " 'GOAL_111',\n",
       " 'RApp7',\n",
       " 'GOAL_127',\n",
       " 'RApp9',\n",
       " 'SUM75',\n",
       " 'NEWTONS74',\n",
       " 'GOAL_79',\n",
       " 'RApp6',\n",
       " 'GOAL_107',\n",
       " 'GOAL_147',\n",
       " 'GOAL_153',\n",
       " 'GOAL_110',\n",
       " 'SNode_29',\n",
       " 'GOAL68',\n",
       " 'GOAL_126',\n",
       " 'SNode_67',\n",
       " 'SNode_70',\n",
       " 'SNode_91',\n",
       " 'SNode_92',\n",
       " 'SNode_95',\n",
       " 'GOAL_121',\n",
       " 'SNode_112',\n",
       " 'SNode_128',\n",
       " 'GOAL_142',\n",
       " 'SNode_33',\n",
       " 'GOAL_146',\n",
       " 'RApp12',\n",
       " 'SNode_28',\n",
       " 'SNode_93',\n",
       " 'SNode_73',\n",
       " 'GOAL_103',\n",
       " 'SNode_122',\n",
       " 'SNode_154',\n",
       " 'SNode_100',\n",
       " 'GOAL_114',\n",
       " 'GOAL_130',\n",
       " 'GOAL_113',\n",
       " 'GOAL_129',\n",
       " 'SNode_97',\n",
       " 'VECTOR69',\n",
       " 'EQUATION28',\n",
       " 'VECTOR27',\n",
       " 'SNode_88',\n",
       " 'GOAL_72',\n",
       " 'SNode_43',\n",
       " 'SNode_64',\n",
       " 'GOAL_108',\n",
       " 'GOAL_109',\n",
       " 'VECTOR73',\n",
       " 'COMPO16',\n",
       " 'GOAL_53',\n",
       " 'GOAL_62',\n",
       " 'GOAL_83',\n",
       " 'GOAL_87',\n",
       " 'NEED36',\n",
       " 'SNode_116',\n",
       " 'SNode_125',\n",
       " 'SNode_132',\n",
       " 'SNode_137',\n",
       " 'SNode_20',\n",
       " 'SNode_37',\n",
       " 'SNode_4',\n",
       " 'SNode_74',\n",
       " 'SNode_75',\n",
       " 'SNode_94',\n",
       " 'VECTOR44']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order = stochastic_minDegree_and_minFill(factor_to_graph(factors))\n",
    "order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elimination order width: 16\n",
      "Wall time: 2.79 s\n"
     ]
    }
   ],
   "source": [
    "# The second test, has 223 nodes and 1157 parameters\n",
    "\n",
    "print(\"Elimination order width: %d\" % width(factors, order))\n",
    "%time jt=elimination_to_jointree(order,factors,outcomeSpace)\n",
    "\n",
    "# The jointree is massive, so we dont plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,o=load_from_file('pathfinder.net')\n",
    "factors,outcomeSpace=ttransform(f,o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F1',\n",
       " 'F10',\n",
       " 'F108',\n",
       " 'F12',\n",
       " 'F14',\n",
       " 'F19',\n",
       " 'F23',\n",
       " 'F24',\n",
       " 'F25',\n",
       " 'F26',\n",
       " 'F27',\n",
       " 'F28',\n",
       " 'F29',\n",
       " 'F33',\n",
       " 'F34',\n",
       " 'F35',\n",
       " 'F36',\n",
       " 'F37',\n",
       " 'F43',\n",
       " 'F45',\n",
       " 'F46',\n",
       " 'F51',\n",
       " 'F57',\n",
       " 'F58',\n",
       " 'F59',\n",
       " 'F60',\n",
       " 'F63',\n",
       " 'F64',\n",
       " 'F65',\n",
       " 'F67',\n",
       " 'F68',\n",
       " 'F69',\n",
       " 'F7',\n",
       " 'F73',\n",
       " 'F75',\n",
       " 'F76',\n",
       " 'F77',\n",
       " 'F79',\n",
       " 'F80',\n",
       " 'F9',\n",
       " 'F91',\n",
       " 'F92',\n",
       " 'F101',\n",
       " 'F102',\n",
       " 'F103',\n",
       " 'F104',\n",
       " 'F105',\n",
       " 'F106',\n",
       " 'F11',\n",
       " 'F13',\n",
       " 'F15',\n",
       " 'F16',\n",
       " 'F22',\n",
       " 'F21',\n",
       " 'F90',\n",
       " 'F32',\n",
       " 'F42',\n",
       " 'F47',\n",
       " 'F49',\n",
       " 'F50',\n",
       " 'F52',\n",
       " 'F55',\n",
       " 'F54',\n",
       " 'F6',\n",
       " 'F62',\n",
       " 'F66',\n",
       " 'F61',\n",
       " 'F71',\n",
       " 'F95',\n",
       " 'F99',\n",
       " 'F100',\n",
       " 'F4',\n",
       " 'F107',\n",
       " 'F17',\n",
       " 'F18',\n",
       " 'F2',\n",
       " 'F5',\n",
       " 'F3',\n",
       " 'F78',\n",
       " 'F97',\n",
       " 'F30',\n",
       " 'F74',\n",
       " 'F98',\n",
       " 'F38',\n",
       " 'F40',\n",
       " 'F48',\n",
       " 'F53',\n",
       " 'F56',\n",
       " 'F8',\n",
       " 'F70',\n",
       " 'F81',\n",
       " 'F93',\n",
       " 'F94',\n",
       " 'F39',\n",
       " 'F96',\n",
       " 'F82',\n",
       " 'F86',\n",
       " 'F89',\n",
       " 'F83',\n",
       " 'F87',\n",
       " 'F88',\n",
       " 'F31',\n",
       " 'F20',\n",
       " 'F41',\n",
       " 'F44',\n",
       " 'F72',\n",
       " 'F84',\n",
       " 'F85',\n",
       " 'Fault']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order = stochastic_minDegree_and_minFill(factor_to_graph(factors))\n",
    "order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elimination order width: 6\n",
      "Wall time: 907 ms\n"
     ]
    }
   ],
   "source": [
    "# The third test, has 109 nodes and 77155 parameters\n",
    "\n",
    "print(\"Elimination order width: %d\" % width(factors, order))\n",
    "%time jt=elimination_to_jointree(order,factors,outcomeSpace)\n",
    "\n",
    "# The jointree is massive, so we dont plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,o=load_from_file('pigs.net')\n",
    "factors,outcomeSpace=ttransform(f,o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['p197075886',\n",
       " 'p751230786',\n",
       " 'p197119188',\n",
       " 'p197125588',\n",
       " 'p543378087',\n",
       " 'p197130288',\n",
       " 'p197130888',\n",
       " 'p82141488',\n",
       " 'p197132888',\n",
       " 'p277114088',\n",
       " 'p197143789',\n",
       " 'p197149689',\n",
       " 'p197162589',\n",
       " 'p82191389',\n",
       " 'p197168789',\n",
       " 'p197206590',\n",
       " 'p197240391',\n",
       " 'p197240491',\n",
       " 'p197252391',\n",
       " 'p197252591',\n",
       " 'p197258291',\n",
       " 'p197258391',\n",
       " 'p197258591',\n",
       " 'p197276591',\n",
       " 'p197288691',\n",
       " 'p197288791',\n",
       " 'p197303091',\n",
       " 'p197303191',\n",
       " 'p197201290',\n",
       " 'p197303291',\n",
       " 'p197314191',\n",
       " 'p197318792',\n",
       " 'p197343392',\n",
       " 'p197353592',\n",
       " 'p216124491',\n",
       " 'p216124591',\n",
       " 'p230057992',\n",
       " 'p230416387',\n",
       " 'p230433487',\n",
       " 'p603176686',\n",
       " 'p230474587',\n",
       " 'p230537588',\n",
       " 'p251336689',\n",
       " 'p230565789',\n",
       " 'p237016791',\n",
       " 'p237017391',\n",
       " 'p251428590',\n",
       " 'p237082692',\n",
       " 'p237082792',\n",
       " 'p251226287',\n",
       " 'p251337389',\n",
       " 'p251388889',\n",
       " 'p251463690',\n",
       " 'p251506491',\n",
       " 'p251564791',\n",
       " 'p277111088',\n",
       " 'p277195691',\n",
       " 'p277155690',\n",
       " 'p277195791',\n",
       " 'p277162190',\n",
       " 'p392087690',\n",
       " 'p82065086',\n",
       " 'p392115290',\n",
       " 'p627270088',\n",
       " 'p392115490',\n",
       " 'p392115590',\n",
       " 'p392120790',\n",
       " 'p750365488',\n",
       " 'p392150190',\n",
       " 'p627276488',\n",
       " 'p392157391',\n",
       " 'p751512889',\n",
       " 'p392203792',\n",
       " 'p441046286',\n",
       " 'p441118988',\n",
       " 'p441290591',\n",
       " 'p441290691',\n",
       " 'p441324091',\n",
       " 'p441324191',\n",
       " 'p48000191',\n",
       " 'p48000291',\n",
       " 'p48004891',\n",
       " 'p48007991',\n",
       " 'p48013791',\n",
       " 'p48022391',\n",
       " 'p48064191',\n",
       " 'p48064391',\n",
       " 'p48072391',\n",
       " 'p48084291',\n",
       " 'p48084391',\n",
       " 'p48084891',\n",
       " 'p48084991',\n",
       " 'p48092591',\n",
       " 'p48109691',\n",
       " 'p48109791',\n",
       " 'p48110491',\n",
       " 'p48110591',\n",
       " 'p48111891',\n",
       " 'p630398790',\n",
       " 'p48112891',\n",
       " 'p48124091',\n",
       " 'p630400490',\n",
       " 'p48127091',\n",
       " 'p630430091',\n",
       " 'p48128191',\n",
       " 'p48131791',\n",
       " 'p48131891',\n",
       " 'p630388990',\n",
       " 'p48139191',\n",
       " 'p48139291',\n",
       " 'p630426691',\n",
       " 'p48147992',\n",
       " 'p48148092',\n",
       " 'p630439091',\n",
       " 'p48172392',\n",
       " 'p48172492',\n",
       " 'p630390690',\n",
       " 'p48197592',\n",
       " 'p48213092',\n",
       " 'p48213192',\n",
       " 'p50052788',\n",
       " 'p630672087',\n",
       " 'p50168489',\n",
       " 'p50095388',\n",
       " 'p50139889',\n",
       " 'p50241090',\n",
       " 'p50261091',\n",
       " 'p522082985',\n",
       " 'p82050786',\n",
       " 'p522204687',\n",
       " 'p522208187',\n",
       " 'p522435092',\n",
       " 'p522449292',\n",
       " 'p543036891',\n",
       " 'p543036991',\n",
       " 'p543068091',\n",
       " 'p543068391',\n",
       " 'p543068491',\n",
       " 'p543072191',\n",
       " 'p543072291',\n",
       " 'p543084792',\n",
       " 'p543151292',\n",
       " 'p543151392',\n",
       " 'p751106191',\n",
       " 'p543416288',\n",
       " 'p543419788',\n",
       " 'p543420288',\n",
       " 'p543472088',\n",
       " 'p543517389',\n",
       " 'p543709391',\n",
       " 'p547328787',\n",
       " 'p603176486',\n",
       " 'p547469388',\n",
       " 'p547620489',\n",
       " 'p547633289',\n",
       " 'p547054590',\n",
       " 'p547629489',\n",
       " 'p609091487',\n",
       " 'p609134289',\n",
       " 'p609110188',\n",
       " 'p609183992',\n",
       " 'p753023491',\n",
       " 'p609164891',\n",
       " 'p627204487',\n",
       " 'p958237987',\n",
       " 'p95029088',\n",
       " 'p627246188',\n",
       " 'p627367791',\n",
       " 'p627396491',\n",
       " 'p627412591',\n",
       " 'p627412991',\n",
       " 'p630007589',\n",
       " 'p630014189',\n",
       " 'p630019789',\n",
       " 'p630031389',\n",
       " 'p630040991',\n",
       " 'p630052589',\n",
       " 'p630062389',\n",
       " 'p630064189',\n",
       " 'p630067789',\n",
       " 'p630071089',\n",
       " 'p630384190',\n",
       " 'p630088089',\n",
       " 'p630091391',\n",
       " 'p630147391',\n",
       " 'p630147591',\n",
       " 'p630152091',\n",
       " 'p630154291',\n",
       " 'p630155091',\n",
       " 'p630155891',\n",
       " 'p630172991',\n",
       " 'p630173091',\n",
       " 'p630182291',\n",
       " 'p630184291',\n",
       " 'p630194791',\n",
       " 'p630194891',\n",
       " 'p630194991',\n",
       " 'p630217392',\n",
       " 'p630249690',\n",
       " 'p630266190',\n",
       " 'p630328490',\n",
       " 'p630388390',\n",
       " 'p83567891',\n",
       " 'p630475686',\n",
       " 'p630643987',\n",
       " 'p630652887',\n",
       " 'p82152788',\n",
       " 'p630192689',\n",
       " 'p251494491',\n",
       " 'p251476190',\n",
       " 'p630655987',\n",
       " 'p630659387',\n",
       " 'p630772188',\n",
       " 'p630810088',\n",
       " 'p630815588',\n",
       " 'p630810288',\n",
       " 'p630813788',\n",
       " 'p630815088',\n",
       " 'p630886588',\n",
       " 'p751038090',\n",
       " 'p88127791',\n",
       " 'p751513589',\n",
       " 'p88067190',\n",
       " 'p392012788',\n",
       " 'p803043885',\n",
       " 'p82019685',\n",
       " 'p807012287',\n",
       " 'p82071386',\n",
       " 'p82142888',\n",
       " 'p82247790',\n",
       " 'p82152588',\n",
       " 'p82154688',\n",
       " 'p82093287',\n",
       " 'p82154988',\n",
       " 'p82236090',\n",
       " 'p82182889',\n",
       " 'p82183689',\n",
       " 'p82185289',\n",
       " 'p82191289',\n",
       " 'p82225190',\n",
       " 'p82243490',\n",
       " 'p82197489',\n",
       " 'p82198489',\n",
       " 'p82243390',\n",
       " 'p82292291',\n",
       " 'p82241490',\n",
       " 'p82265990',\n",
       " 'p82280791',\n",
       " 'p82282491',\n",
       " 'p82303591',\n",
       " 'p82303691',\n",
       " 'p82318091',\n",
       " 'p82318191',\n",
       " 'p82332291',\n",
       " 'p82334391',\n",
       " 'p82338291',\n",
       " 'p82338391',\n",
       " 'p82345291',\n",
       " 'p82347891',\n",
       " 'p82349391',\n",
       " 'p82349491',\n",
       " 'p82350491',\n",
       " 'p82350591',\n",
       " 'p82366892',\n",
       " 'p82422492',\n",
       " 'p83290288',\n",
       " 'p83306289',\n",
       " 'p83456290',\n",
       " 'p83314589',\n",
       " 'p83470790',\n",
       " 'p83324189',\n",
       " 'p83371889',\n",
       " 'p83572791',\n",
       " 'p83474091',\n",
       " 'p83572891',\n",
       " 'p95090289',\n",
       " 'p95247691',\n",
       " 'p958249187',\n",
       " 'p197140688',\n",
       " 'p197192390',\n",
       " 'p197211690',\n",
       " 'p216077190',\n",
       " 'p630299990',\n",
       " 'p630396290',\n",
       " 'p230757791',\n",
       " 'p237011591',\n",
       " 'p251260288',\n",
       " 'p251372589',\n",
       " 'p441214590',\n",
       " 'p50195390',\n",
       " 'p543551889',\n",
       " 'p543583789',\n",
       " 'p543654190',\n",
       " 'p543657690',\n",
       " 'p547097990',\n",
       " 'p609133389',\n",
       " 'p627320490',\n",
       " 'p630062489',\n",
       " 'p630239990',\n",
       " 'p630282090',\n",
       " 'p630319390',\n",
       " 'p630323790',\n",
       " 'p630349790',\n",
       " 'p630335990',\n",
       " 'p630384990',\n",
       " 'p630652587',\n",
       " 'p82154888',\n",
       " 'p82155088',\n",
       " 'p82229690',\n",
       " 'p82238890',\n",
       " 'p82251690',\n",
       " 'p82266890',\n",
       " 'p83403790',\n",
       " 'p95141490',\n",
       " 'p95147490',\n",
       " 'p197126088',\n",
       " 'p197130688',\n",
       " 'p197180690',\n",
       " 'p197210690',\n",
       " 'p197165689',\n",
       " 'p197229090',\n",
       " 'p197235390',\n",
       " 'p441119488',\n",
       " 'p441231890',\n",
       " 'p50141889',\n",
       " 'p50249390',\n",
       " 'p50249590',\n",
       " 'p630370190',\n",
       " 'p627275788',\n",
       " 'p627294789',\n",
       " 'p627343790',\n",
       " 'p627344390',\n",
       " 'p627350790',\n",
       " 'p630322190',\n",
       " 'p630328890',\n",
       " 'p630373890',\n",
       " 'p630845888',\n",
       " 'p751522389',\n",
       " 'p627333990',\n",
       " 'p82089087',\n",
       " 'p82105287',\n",
       " 'p82150988',\n",
       " 'p82206789',\n",
       " 'p82210989',\n",
       " 'p82258290',\n",
       " 'p82258390',\n",
       " 'p82277591',\n",
       " 'p82218289',\n",
       " 'p82211489',\n",
       " 'p197143589',\n",
       " 'p197224190',\n",
       " 'p197131388',\n",
       " 'p197256791',\n",
       " 'p251340389',\n",
       " 'p251476390',\n",
       " 'p441134788',\n",
       " 'p441231590',\n",
       " 'p48000691',\n",
       " 'p48022291',\n",
       " 'p50212890',\n",
       " 'p630311090',\n",
       " 'p48064091',\n",
       " 'p50197290',\n",
       " 'p50197390',\n",
       " 'p50241490',\n",
       " 'p522284388',\n",
       " 'p522334189',\n",
       " 'p522361390',\n",
       " 'p522369890',\n",
       " 'p522398991',\n",
       " 'p197180790',\n",
       " 'p627253288',\n",
       " 'p630058889',\n",
       " 'p630154689',\n",
       " 'p630154989',\n",
       " 'p630258890',\n",
       " 'p630328990',\n",
       " 'p82218889',\n",
       " 'p82224990',\n",
       " 'p82225690',\n",
       " 'p82228490',\n",
       " 'p82261490',\n",
       " 'p95084689',\n",
       " 'p197206490',\n",
       " 'p522279888',\n",
       " 'p82299691',\n",
       " 'p630068489',\n",
       " 'p82105387',\n",
       " 'p82121587',\n",
       " 'p82206389',\n",
       " 'p82261890',\n",
       " 'p826030789',\n",
       " 'p750261487',\n",
       " 'p197111387',\n",
       " 'p197114187',\n",
       " 'p197131588',\n",
       " 'p197131688',\n",
       " 'p197153289',\n",
       " 'p441183089',\n",
       " 'p547325687',\n",
       " 'p630322390',\n",
       " 'p627257588',\n",
       " 'p630373290',\n",
       " 'p630073589',\n",
       " 'p83500691',\n",
       " 'p50197190',\n",
       " 'p630043389',\n",
       " 'p630258690',\n",
       " 'p197263491',\n",
       " 'p627378291',\n",
       " 'p630501586',\n",
       " 'p82228290',\n",
       " 'p50197590',\n",
       " 'p630810388',\n",
       " 'p88014589',\n",
       " 'p50070388',\n",
       " 'p197252291',\n",
       " 'p630844188',\n",
       " 'p82206489',\n",
       " 'p547497788',\n",
       " 'p50132089',\n",
       " 'p751015990',\n",
       " 'p630258790',\n",
       " 'p547261686',\n",
       " 'p630388190',\n",
       " 'p630068889',\n",
       " 'p82307191',\n",
       " 'p82144488',\n",
       " 'p82144288',\n",
       " 'p197155489',\n",
       " 'p50133089',\n",
       " 'p50133689',\n",
       " 'p50140189',\n",
       " 'p630067989',\n",
       " 'p630388590',\n",
       " 'p630798688',\n",
       " 'p82133387',\n",
       " 'p82140988',\n",
       " 'p82150688',\n",
       " 'p82218589',\n",
       " 'p893080087']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order = stochastic_minDegree_and_minFill(factor_to_graph(factors))\n",
    "order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elimination order width: 11\n",
      "Wall time: 9.03 s\n"
     ]
    }
   ],
   "source": [
    "# The forth test, has 441 nodes and 5618 parameters\n",
    "\n",
    "print(\"Elimination order width: %d\" % width(factors, order))\n",
    "%time jt=elimination_to_jointree(order,factors,outcomeSpace)\n",
    "\n",
    "# The jointree is massive, so we dont plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,o=load_from_file('link.net')\n",
    "factors,outcomeSpace=ttransform(f,o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D0_10_d_p',\n",
       " 'D0_11_d_p',\n",
       " 'D0_12_d_p',\n",
       " 'D0_13_d_p',\n",
       " 'D0_14_d_p',\n",
       " 'D0_15_d_p',\n",
       " 'D0_16_d_p',\n",
       " 'D0_17_d_p',\n",
       " 'D0_18_d_p',\n",
       " 'D0_19_d_p',\n",
       " 'D0_1_d_p',\n",
       " 'D0_20_d_p',\n",
       " 'D0_21_d_p',\n",
       " 'D0_22_d_p',\n",
       " 'D0_23_d_p',\n",
       " 'D0_24_d_p',\n",
       " 'D0_25_d_p',\n",
       " 'D0_26_d_p',\n",
       " 'D0_27_d_p',\n",
       " 'D0_28_d_p',\n",
       " 'D0_29_d_p',\n",
       " 'D0_2_d_p',\n",
       " 'D0_30_d_p',\n",
       " 'D0_31_d_p',\n",
       " 'D0_32_d_p',\n",
       " 'D0_33_d_p',\n",
       " 'D0_34_d_p',\n",
       " 'D0_35_d_p',\n",
       " 'D0_36_d_p',\n",
       " 'D0_37_d_p',\n",
       " 'D0_38_d_p',\n",
       " 'D0_39_d_p',\n",
       " 'D0_3_d_p',\n",
       " 'D0_40_d_p',\n",
       " 'D0_41_d_p',\n",
       " 'D0_42_d_p',\n",
       " 'D0_43_d_p',\n",
       " 'D0_44_d_p',\n",
       " 'D0_45_d_p',\n",
       " 'D0_46_d_p',\n",
       " 'D0_47_d_p',\n",
       " 'D0_48_d_p',\n",
       " 'D0_49_d_p',\n",
       " 'D0_4_d_p',\n",
       " 'D0_50_d_p',\n",
       " 'D0_51_d_p',\n",
       " 'D0_52_d_p',\n",
       " 'D0_53_d_p',\n",
       " 'D0_54_d_p',\n",
       " 'D0_55_d_p',\n",
       " 'D0_56_d_p',\n",
       " 'D0_57_d_p',\n",
       " 'D0_58_d_p',\n",
       " 'D0_59_d_p',\n",
       " 'D0_5_d_p',\n",
       " 'D0_60_d_p',\n",
       " 'D0_61_d_p',\n",
       " 'D0_62_d_p',\n",
       " 'D0_63_d_p',\n",
       " 'D0_64_d_p',\n",
       " 'D0_65_d_p',\n",
       " 'D0_66_d_p',\n",
       " 'D0_67_d_p',\n",
       " 'D0_68_d_p',\n",
       " 'D0_69_d_p',\n",
       " 'D0_6_d_p',\n",
       " 'D0_70_d_p',\n",
       " 'D0_71_d_p',\n",
       " 'D0_72_d_p',\n",
       " 'D0_73_d_p',\n",
       " 'D0_7_d_p',\n",
       " 'D0_8_d_p',\n",
       " 'D0_9_d_p',\n",
       " 'D0_13_a_x',\n",
       " 'D0_17_a_x',\n",
       " 'D0_18_a_x',\n",
       " 'D0_19_a_x',\n",
       " 'D0_20_a_x',\n",
       " 'D0_21_a_x',\n",
       " 'D0_22_a_x',\n",
       " 'D0_23_a_x',\n",
       " 'D0_24_a_x',\n",
       " 'D0_25_a_x',\n",
       " 'D0_26_a_x',\n",
       " 'D0_29_a_x',\n",
       " 'D0_30_a_x',\n",
       " 'D0_31_a_x',\n",
       " 'D0_32_a_x',\n",
       " 'D0_33_a_x',\n",
       " 'D0_34_a_x',\n",
       " 'D0_35_a_x',\n",
       " 'D0_36_a_x',\n",
       " 'D0_37_a_x',\n",
       " 'D0_38_a_x',\n",
       " 'D0_40_a_x',\n",
       " 'D0_42_a_x',\n",
       " 'D0_43_a_x',\n",
       " 'D0_44_a_x',\n",
       " 'D0_45_a_x',\n",
       " 'D0_46_a_x',\n",
       " 'D0_47_a_x',\n",
       " 'D0_48_a_x',\n",
       " 'D0_49_a_x',\n",
       " 'D0_50_a_x',\n",
       " 'D0_51_a_x',\n",
       " 'D0_52_a_x',\n",
       " 'D0_53_a_x',\n",
       " 'D0_54_a_x',\n",
       " 'D0_55_a_x',\n",
       " 'D0_57_a_x',\n",
       " 'D0_58_a_x',\n",
       " 'D0_59_a_x',\n",
       " 'D0_9_a_x',\n",
       " 'N10_d_g',\n",
       " 'N11_d_g',\n",
       " 'N12_d_g',\n",
       " 'N13_d_g',\n",
       " 'N14_d_g',\n",
       " 'N15_d_g',\n",
       " 'N16_d_g',\n",
       " 'N17_d_g',\n",
       " 'N18_d_g',\n",
       " 'N19_d_g',\n",
       " 'N1_d_g',\n",
       " 'N20_d_g',\n",
       " 'N21_d_g',\n",
       " 'N22_d_g',\n",
       " 'N23_d_g',\n",
       " 'N24_d_g',\n",
       " 'N25_d_g',\n",
       " 'N26_d_g',\n",
       " 'N27_d_g',\n",
       " 'N28_d_g',\n",
       " 'N29_d_g',\n",
       " 'N2_d_g',\n",
       " 'N30_d_g',\n",
       " 'N31_d_g',\n",
       " 'N32_d_g',\n",
       " 'N33_d_g',\n",
       " 'N34_d_g',\n",
       " 'N35_d_g',\n",
       " 'N36_d_g',\n",
       " 'N37_d_g',\n",
       " 'N38_d_g',\n",
       " 'N39_d_g',\n",
       " 'N3_d_g',\n",
       " 'N40_d_g',\n",
       " 'N41_d_g',\n",
       " 'N42_d_g',\n",
       " 'N43_d_g',\n",
       " 'N44_d_g',\n",
       " 'N45_d_g',\n",
       " 'N46_d_g',\n",
       " 'N47_d_g',\n",
       " 'N48_d_g',\n",
       " 'N49_d_g',\n",
       " 'N4_d_g',\n",
       " 'N50_d_g',\n",
       " 'N51_d_g',\n",
       " 'N52_d_g',\n",
       " 'N53_d_g',\n",
       " 'N54_d_g',\n",
       " 'N55_d_g',\n",
       " 'N56_d_g',\n",
       " 'N57_d_g',\n",
       " 'N58_d_g',\n",
       " 'N59_d_g',\n",
       " 'N5_d_g',\n",
       " 'N60_d_g',\n",
       " 'N61_d_g',\n",
       " 'N62_d_g',\n",
       " 'N63_d_g',\n",
       " 'N64_d_g',\n",
       " 'N65_d_g',\n",
       " 'N66_d_g',\n",
       " 'N67_d_g',\n",
       " 'N68_d_g',\n",
       " 'N69_d_g',\n",
       " 'N6_d_g',\n",
       " 'N70_d_g',\n",
       " 'N71_d_g',\n",
       " 'N72_d_g',\n",
       " 'N73_d_g',\n",
       " 'N7_d_g',\n",
       " 'N8_d_g',\n",
       " 'N9_d_g',\n",
       " 'D0_27_a_f',\n",
       " 'D0_27_a_m',\n",
       " 'D0_28_a_f',\n",
       " 'D0_28_a_m',\n",
       " 'D0_39_a_f',\n",
       " 'D0_39_a_m',\n",
       " 'D0_41_a_f',\n",
       " 'D0_41_a_m',\n",
       " 'D0_56_a_f',\n",
       " 'D0_56_a_m',\n",
       " 'N14_a_f',\n",
       " 'N14_a_m',\n",
       " 'N14_d_f',\n",
       " 'N14_d_m',\n",
       " 'Z_22_a_f',\n",
       " 'Z_22_d_f',\n",
       " 'N15_a_f',\n",
       " 'N15_a_m',\n",
       " 'N15_d_f',\n",
       " 'N15_d_m',\n",
       " 'Z_23_a_m',\n",
       " 'Z_23_d_m',\n",
       " 'N16_a_f',\n",
       " 'N16_a_m',\n",
       " 'N16_d_f',\n",
       " 'N16_d_m',\n",
       " 'Z_24_a_m',\n",
       " 'N66_a_f',\n",
       " 'N66_a_m',\n",
       " 'Z_24_d_m',\n",
       " 'Z_71_a_f',\n",
       " 'N66_d_f',\n",
       " 'N66_d_m',\n",
       " 'Z_71_d_f',\n",
       " 'N69_a_f',\n",
       " 'N69_a_m',\n",
       " 'Z_70_a_m',\n",
       " 'N69_d_f',\n",
       " 'N69_d_m',\n",
       " 'N73_a_f',\n",
       " 'N73_a_m',\n",
       " 'Z_25_a_m',\n",
       " 'N73_d_f',\n",
       " 'N73_d_m',\n",
       " 'Z_25_d_m',\n",
       " 'Z_70_d_m',\n",
       " 'Z_27_a_f',\n",
       " 'Z_27_a_m',\n",
       " 'Z_28_a_f',\n",
       " 'Z_28_a_m',\n",
       " 'Z_39_a_f',\n",
       " 'Z_39_a_m',\n",
       " 'Z_41_a_f',\n",
       " 'Z_41_a_m',\n",
       " 'Z_56_a_f',\n",
       " 'Z_56_a_m',\n",
       " 'N23_a_m',\n",
       " 'Z_54_a_m',\n",
       " 'N24_a_m',\n",
       " 'Z_55_a_f',\n",
       " 'N25_a_m',\n",
       " 'Z_54_a_f',\n",
       " 'N27_d_f',\n",
       " 'N28_d_f',\n",
       " 'N29_a_f',\n",
       " 'N29_d_f',\n",
       " 'N30_a_f',\n",
       " 'N30_d_f',\n",
       " 'N31_a_f',\n",
       " 'N31_d_f',\n",
       " 'N32_a_f',\n",
       " 'N32_d_f',\n",
       " 'N33_a_f',\n",
       " 'N33_d_f',\n",
       " 'N34_a_f',\n",
       " 'N34_d_f',\n",
       " 'N35_a_f',\n",
       " 'N35_d_f',\n",
       " 'N36_a_f',\n",
       " 'N36_d_f',\n",
       " 'N37_a_f',\n",
       " 'N37_d_f',\n",
       " 'N38_a_f',\n",
       " 'N38_d_f',\n",
       " 'N39_d_f',\n",
       " 'N40_a_f',\n",
       " 'N40_d_f',\n",
       " 'N41_d_f',\n",
       " 'N42_a_f',\n",
       " 'N42_d_f',\n",
       " 'N43_a_f',\n",
       " 'N43_d_f',\n",
       " 'N44_a_f',\n",
       " 'N44_d_f',\n",
       " 'N45_a_f',\n",
       " 'N45_d_f',\n",
       " 'N46_a_f',\n",
       " 'N46_d_f',\n",
       " 'N47_a_f',\n",
       " 'N47_d_f',\n",
       " 'N48_a_f',\n",
       " 'N48_d_f',\n",
       " 'N49_a_f',\n",
       " 'N49_d_f',\n",
       " 'N50_a_f',\n",
       " 'N50_d_f',\n",
       " 'N51_a_f',\n",
       " 'N51_d_f',\n",
       " 'N52_a_f',\n",
       " 'N52_d_f',\n",
       " 'N53_a_f',\n",
       " 'N53_d_f',\n",
       " 'N56_d_f',\n",
       " 'N57_a_f',\n",
       " 'N57_d_f',\n",
       " 'N58_a_f',\n",
       " 'N58_d_f',\n",
       " 'N59_a_f',\n",
       " 'N59_d_f',\n",
       " 'N70_a_m',\n",
       " 'Z_26_a_f',\n",
       " 'N71_a_f',\n",
       " 'Z_26_a_m',\n",
       " 'Z_10_a_f',\n",
       " 'Z_10_a_m',\n",
       " 'Z_11_a_f',\n",
       " 'Z_11_a_m',\n",
       " 'Z_17_a_f',\n",
       " 'Z_17_a_m',\n",
       " 'Z_18_a_f',\n",
       " 'Z_18_a_m',\n",
       " 'Z_19_a_f',\n",
       " 'Z_19_a_m',\n",
       " 'Z_1_a_f',\n",
       " 'Z_1_a_m',\n",
       " 'Z_20_a_f',\n",
       " 'Z_20_a_m',\n",
       " 'Z_21_a_f',\n",
       " 'Z_21_a_m',\n",
       " 'Z_22_a_m',\n",
       " 'Z_23_a_f',\n",
       " 'Z_24_a_f',\n",
       " 'Z_25_a_f',\n",
       " 'Z_29_a_f',\n",
       " 'Z_29_a_m',\n",
       " 'Z_2_a_f',\n",
       " 'Z_2_a_m',\n",
       " 'Z_30_a_f',\n",
       " 'Z_30_a_m',\n",
       " 'Z_31_a_f',\n",
       " 'Z_31_a_m',\n",
       " 'Z_32_a_f',\n",
       " 'Z_32_a_m',\n",
       " 'Z_33_a_f',\n",
       " 'Z_33_a_m',\n",
       " 'Z_34_a_f',\n",
       " 'Z_34_a_m',\n",
       " 'Z_35_a_f',\n",
       " 'Z_35_a_m',\n",
       " 'Z_36_a_f',\n",
       " 'Z_36_a_m',\n",
       " 'Z_37_a_f',\n",
       " 'Z_37_a_m',\n",
       " 'Z_38_a_f',\n",
       " 'Z_38_a_m',\n",
       " 'Z_3_a_f',\n",
       " 'Z_3_a_m',\n",
       " 'Z_40_a_f',\n",
       " 'Z_40_a_m',\n",
       " 'Z_42_a_f',\n",
       " 'Z_42_a_m',\n",
       " 'Z_43_a_f',\n",
       " 'Z_43_a_m',\n",
       " 'Z_44_a_f',\n",
       " 'Z_44_a_m',\n",
       " 'Z_45_a_f',\n",
       " 'Z_45_a_m',\n",
       " 'Z_46_a_f',\n",
       " 'Z_46_a_m',\n",
       " 'Z_47_a_f',\n",
       " 'Z_47_a_m',\n",
       " 'Z_48_a_f',\n",
       " 'Z_48_a_m',\n",
       " 'Z_49_a_f',\n",
       " 'Z_49_a_m',\n",
       " 'Z_4_a_f',\n",
       " 'Z_4_a_m',\n",
       " 'Z_50_a_f',\n",
       " 'Z_50_a_m',\n",
       " 'Z_51_a_f',\n",
       " 'Z_51_a_m',\n",
       " 'Z_52_a_f',\n",
       " 'Z_52_a_m',\n",
       " 'Z_53_a_f',\n",
       " 'Z_53_a_m',\n",
       " 'Z_55_a_m',\n",
       " 'Z_57_a_f',\n",
       " 'Z_57_a_m',\n",
       " 'Z_58_a_f',\n",
       " 'Z_58_a_m',\n",
       " 'Z_59_a_f',\n",
       " 'Z_59_a_m',\n",
       " 'Z_64_a_f',\n",
       " 'Z_64_a_m',\n",
       " 'Z_65_a_f',\n",
       " 'Z_65_a_m',\n",
       " 'Z_67_a_f',\n",
       " 'Z_67_a_m',\n",
       " 'Z_68_a_f',\n",
       " 'Z_68_a_m',\n",
       " 'Z_70_a_f',\n",
       " 'Z_71_a_m',\n",
       " 'Z_72_a_f',\n",
       " 'Z_72_a_m',\n",
       " 'Z_7_a_f',\n",
       " 'Z_7_a_m',\n",
       " 'Z_8_a_f',\n",
       " 'Z_8_a_m',\n",
       " 'Z_9_a_f',\n",
       " 'Z_9_a_m',\n",
       " 'N12_a_f',\n",
       " 'N12_a_m',\n",
       " 'N12_d_f',\n",
       " 'N12_d_m',\n",
       " 'N23_d_m',\n",
       " 'Z_54_d_m',\n",
       " 'N24_d_m',\n",
       " 'Z_55_d_f',\n",
       " 'N25_d_m',\n",
       " 'Z_54_d_f',\n",
       " 'N60_a_f',\n",
       " 'N60_a_m',\n",
       " 'N60_d_f',\n",
       " 'N60_d_m',\n",
       " 'N61_a_f',\n",
       " 'N61_a_m',\n",
       " 'N61_d_f',\n",
       " 'N61_d_m',\n",
       " 'N62_a_f',\n",
       " 'N62_a_m',\n",
       " 'N62_d_f',\n",
       " 'N62_d_m',\n",
       " 'N63_a_f',\n",
       " 'N63_a_m',\n",
       " 'N63_d_f',\n",
       " 'N63_d_m',\n",
       " 'N70_d_m',\n",
       " 'Z_26_d_f',\n",
       " 'N71_d_f',\n",
       " 'Z_26_d_m',\n",
       " 'Z_17_d_f',\n",
       " 'Z_18_d_f',\n",
       " 'Z_1_d_f',\n",
       " 'Z_64_d_f',\n",
       " 'Z_1_d_m',\n",
       " 'Z_64_d_m',\n",
       " 'Z_2_d_f',\n",
       " 'Z_65_d_f',\n",
       " 'Z_2_d_m',\n",
       " 'Z_65_d_m',\n",
       " 'Z_56_d_f',\n",
       " 'Z_27_d_f',\n",
       " 'Z_28_d_f',\n",
       " 'Z_39_d_f',\n",
       " 'Z_41_d_f',\n",
       " 'Z_56_d_m',\n",
       " 'Z_27_d_m',\n",
       " 'Z_28_d_m',\n",
       " 'Z_39_d_m',\n",
       " 'Z_29_d_f',\n",
       " 'Z_29_d_m',\n",
       " 'Z_41_d_m',\n",
       " 'Z_30_d_f',\n",
       " 'Z_30_d_m',\n",
       " 'Z_31_d_f',\n",
       " 'Z_31_d_m',\n",
       " 'Z_32_d_f',\n",
       " 'Z_32_d_m',\n",
       " 'Z_33_d_f',\n",
       " 'Z_33_d_m',\n",
       " 'Z_34_d_f',\n",
       " 'Z_34_d_m',\n",
       " 'Z_35_d_f',\n",
       " 'Z_35_d_m',\n",
       " 'Z_36_d_f',\n",
       " 'Z_36_d_m',\n",
       " 'Z_37_d_f',\n",
       " 'Z_37_d_m',\n",
       " 'Z_38_d_f',\n",
       " 'Z_38_d_m',\n",
       " 'Z_40_d_f',\n",
       " 'Z_40_d_m',\n",
       " 'Z_42_d_f',\n",
       " 'Z_42_d_m',\n",
       " 'Z_43_d_f',\n",
       " 'Z_43_d_m',\n",
       " 'Z_44_d_f',\n",
       " 'Z_44_d_m',\n",
       " 'Z_45_d_f',\n",
       " 'Z_45_d_m',\n",
       " 'Z_46_d_f',\n",
       " 'Z_46_d_m',\n",
       " 'Z_47_d_f',\n",
       " 'Z_47_d_m',\n",
       " 'Z_48_d_f',\n",
       " 'Z_48_d_m',\n",
       " 'Z_49_d_f',\n",
       " 'Z_49_d_m',\n",
       " 'Z_50_d_f',\n",
       " 'Z_50_d_m',\n",
       " 'Z_51_d_f',\n",
       " 'Z_51_d_m',\n",
       " 'Z_52_d_f',\n",
       " 'Z_52_d_m',\n",
       " 'Z_53_d_f',\n",
       " 'Z_53_d_m',\n",
       " 'Z_57_d_f',\n",
       " 'Z_57_d_m',\n",
       " 'Z_58_d_f',\n",
       " 'Z_58_d_m',\n",
       " 'Z_59_d_f',\n",
       " 'Z_59_d_m',\n",
       " 'Z_55_d_m',\n",
       " 'Z_3_d_f',\n",
       " 'Z_4_d_f',\n",
       " 'Z_68_d_f',\n",
       " 'Z_3_d_m',\n",
       " 'Z_4_d_m',\n",
       " 'Z_68_d_m',\n",
       " 'Z_70_d_f',\n",
       " 'Z_10_d_f',\n",
       " 'Z_11_d_f',\n",
       " 'Z_9_d_f',\n",
       " 'Z_19_d_f',\n",
       " 'Z_20_d_f',\n",
       " 'Z_21_d_f',\n",
       " 'Z_23_d_f',\n",
       " 'Z_24_d_f',\n",
       " 'Z_67_d_f',\n",
       " 'Z_67_d_m',\n",
       " 'Z_71_d_m',\n",
       " 'Z_72_d_m',\n",
       " 'Z_7_d_m',\n",
       " 'Z_8_d_m',\n",
       " 'Z_17_d_m',\n",
       " 'Z_18_d_m',\n",
       " 'Z_22_d_m',\n",
       " 'Z_25_d_f',\n",
       " 'Z_10_d_m',\n",
       " 'Z_11_d_m',\n",
       " 'Z_9_d_m',\n",
       " 'Z_19_d_m',\n",
       " 'Z_20_d_m',\n",
       " 'Z_21_d_m',\n",
       " 'Z_72_d_f',\n",
       " 'Z_7_d_f',\n",
       " 'Z_8_d_f',\n",
       " 'N23_a_f',\n",
       " 'N23_d_f',\n",
       " 'N24_a_f',\n",
       " 'N24_d_f',\n",
       " 'N25_a_f',\n",
       " 'N25_d_f',\n",
       " 'N26_a_f',\n",
       " 'N26_d_f',\n",
       " 'N26_a_m',\n",
       " 'N26_d_m',\n",
       " 'N64_a_f',\n",
       " 'N64_d_f',\n",
       " 'N64_a_m',\n",
       " 'N64_d_m',\n",
       " 'N65_a_f',\n",
       " 'N65_d_f',\n",
       " 'N65_a_m',\n",
       " 'N65_d_m',\n",
       " 'N18_a_f',\n",
       " 'N18_d_f',\n",
       " 'N13_a_f',\n",
       " 'N13_a_m',\n",
       " 'N13_d_f',\n",
       " 'N13_d_m',\n",
       " 'N5_a_f',\n",
       " 'N5_a_m',\n",
       " 'N5_d_f',\n",
       " 'N5_d_m',\n",
       " 'N6_a_f',\n",
       " 'N6_a_m',\n",
       " 'N6_d_f',\n",
       " 'N6_d_m',\n",
       " 'N27_d_m',\n",
       " 'N28_d_m',\n",
       " 'N29_a_m',\n",
       " 'N29_d_m',\n",
       " 'N41_d_m',\n",
       " 'N56_d_m',\n",
       " 'N30_a_m',\n",
       " 'N30_d_m',\n",
       " 'N31_a_m',\n",
       " 'N31_d_m',\n",
       " 'N32_a_m',\n",
       " 'N32_d_m',\n",
       " 'N33_a_m',\n",
       " 'N33_d_m',\n",
       " 'N34_a_m',\n",
       " 'N34_d_m',\n",
       " 'N35_a_m',\n",
       " 'N35_d_m',\n",
       " 'N36_a_m',\n",
       " 'N36_d_m',\n",
       " 'N37_a_m',\n",
       " 'N37_d_m',\n",
       " 'N38_a_m',\n",
       " 'N38_d_m',\n",
       " 'N42_a_m',\n",
       " 'N42_d_m',\n",
       " 'N43_a_m',\n",
       " 'N43_d_m',\n",
       " 'N44_a_m',\n",
       " 'N44_d_m',\n",
       " 'N45_a_m',\n",
       " 'N45_d_m',\n",
       " 'N46_a_m',\n",
       " 'N46_d_m',\n",
       " 'N47_a_m',\n",
       " 'N47_d_m',\n",
       " 'N48_a_m',\n",
       " 'N48_d_m',\n",
       " 'N49_a_m',\n",
       " 'N49_d_m',\n",
       " 'N50_a_m',\n",
       " 'N50_d_m',\n",
       " 'N51_a_m',\n",
       " 'N51_d_m',\n",
       " 'N52_a_m',\n",
       " 'N52_d_m',\n",
       " 'N22_a_f',\n",
       " 'N22_d_f',\n",
       " 'N53_a_m',\n",
       " 'N53_d_m',\n",
       " 'N57_a_m',\n",
       " 'N57_d_m',\n",
       " 'N58_a_m',\n",
       " 'N58_d_m',\n",
       " 'N59_a_m',\n",
       " 'N59_d_m',\n",
       " 'N10_a_f',\n",
       " 'N10_d_f',\n",
       " 'N11_a_f',\n",
       " 'N11_d_f',\n",
       " 'N21_a_f',\n",
       " 'N21_d_f',\n",
       " 'N67_a_f',\n",
       " 'N67_d_f',\n",
       " 'N68_a_f',\n",
       " 'N68_d_f',\n",
       " 'N72_a_f',\n",
       " 'N72_d_f',\n",
       " 'N8_a_m',\n",
       " 'N8_d_m',\n",
       " 'N39_d_m',\n",
       " 'N40_a_m',\n",
       " 'N40_d_m',\n",
       " 'N10_a_m',\n",
       " 'N10_d_m',\n",
       " 'N11_a_m',\n",
       " 'N11_d_m',\n",
       " 'N70_a_f',\n",
       " 'N70_d_f',\n",
       " 'N71_a_m',\n",
       " 'N71_d_m',\n",
       " 'N72_a_m',\n",
       " 'N72_d_m',\n",
       " 'N8_a_f',\n",
       " 'N8_d_f',\n",
       " 'N19_a_m',\n",
       " 'N19_d_m',\n",
       " 'N2_a_f',\n",
       " 'N2_a_m',\n",
       " 'N2_d_f',\n",
       " 'N2_d_m',\n",
       " 'N7_a_m',\n",
       " 'N7_d_m',\n",
       " 'N7_a_f',\n",
       " 'N20_a_f',\n",
       " 'N20_d_f',\n",
       " 'N7_d_f',\n",
       " 'N19_a_f',\n",
       " 'N19_d_f',\n",
       " 'N17_a_f',\n",
       " 'N17_d_f',\n",
       " 'N20_a_m',\n",
       " 'N20_d_m',\n",
       " 'N21_a_m',\n",
       " 'N21_d_m',\n",
       " 'N54_a_m',\n",
       " 'N54_d_m',\n",
       " 'N55_a_f',\n",
       " 'N55_d_f',\n",
       " 'N67_a_m',\n",
       " 'N67_d_m',\n",
       " 'N68_a_m',\n",
       " 'N68_d_m',\n",
       " 'N1_a_f',\n",
       " 'N1_a_m',\n",
       " 'N1_d_f',\n",
       " 'N1_d_m',\n",
       " 'N55_a_m',\n",
       " 'N55_d_m',\n",
       " 'N4_a_f',\n",
       " 'N4_a_m',\n",
       " 'N4_d_f',\n",
       " 'N4_d_m',\n",
       " 'N17_a_m',\n",
       " 'N17_d_m',\n",
       " 'N18_a_m',\n",
       " 'N18_d_m',\n",
       " 'N22_a_m',\n",
       " 'N22_d_m',\n",
       " 'N3_a_f',\n",
       " 'N3_a_m',\n",
       " 'N3_d_f',\n",
       " 'N3_d_m',\n",
       " 'N54_a_f',\n",
       " 'N54_d_f',\n",
       " 'N9_a_f',\n",
       " 'N9_a_m',\n",
       " 'N9_d_f',\n",
       " 'N9_d_m']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order = stochastic_minDegree_and_minFill(factor_to_graph(factors))\n",
    "order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elimination order width: 15\n",
      "Wall time: 4min 45s\n"
     ]
    }
   ],
   "source": [
    "# The fifth test, has 724 nodes and 14211 parameters\n",
    "\n",
    "print(\"Elimination order width: %d\" % width(factors, order))\n",
    "%time jt=elimination_to_jointree(order,factors,outcomeSpace)\n",
    "\n",
    "# The jointree is massive, so we dont plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,o=load_from_file('munin.net')\n",
    "factors,outcomeSpace=ttransform(f,o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['L_ADM_MUPINSTAB',\n",
       " 'L_ADM_MUPSATEL',\n",
       " 'L_ADM_MVA_AMP',\n",
       " 'L_ADM_QUAL_MUPAMP',\n",
       " 'L_ADM_QUAL_MUPDUR',\n",
       " 'L_ADM_QUAL_MUPPOLY',\n",
       " 'L_ADM_QUAN_MUPAMP',\n",
       " 'L_ADM_MUPAMP',\n",
       " 'L_ADM_QUAN_MUPDUR',\n",
       " 'L_ADM_MUPDUR',\n",
       " 'L_ADM_REPSTIM_CMAPAMP',\n",
       " 'L_ADM_REPSTIM_DECR',\n",
       " 'L_ADM_REPSTIM_FACILI',\n",
       " 'L_ADM_REPSTIM_POST_DECR',\n",
       " 'L_ADM_SF_DENSITY',\n",
       " 'L_ADM_SF_JITTER',\n",
       " 'L_ADM_SPONT_DENERV_ACT',\n",
       " 'L_ADM_SPONT_HF_DISCH',\n",
       " 'L_ADM_SPONT_INS_ACT',\n",
       " 'L_ADM_SPONT_NEUR_DISCH',\n",
       " 'L_ADM_TA_CONCL',\n",
       " 'L_APB_MUPINSTAB',\n",
       " 'L_APB_MUPSATEL',\n",
       " 'L_APB_MVA_AMP',\n",
       " 'L_APB_QUAL_MUPAMP',\n",
       " 'L_APB_QUAL_MUPDUR',\n",
       " 'L_APB_QUAL_MUPPOLY',\n",
       " 'L_APB_QUAN_MUPAMP',\n",
       " 'L_APB_MUPAMP',\n",
       " 'L_APB_QUAN_MUPDUR',\n",
       " 'L_APB_MUPDUR',\n",
       " 'L_APB_REPSTIM_CMAPAMP',\n",
       " 'L_APB_REPSTIM_DECR',\n",
       " 'L_APB_REPSTIM_FACILI',\n",
       " 'L_APB_REPSTIM_POST_DECR',\n",
       " 'L_APB_SF_DENSITY',\n",
       " 'L_APB_SF_JITTER',\n",
       " 'L_APB_SPONT_DENERV_ACT',\n",
       " 'L_APB_SPONT_HF_DISCH',\n",
       " 'L_APB_SPONT_INS_ACT',\n",
       " 'L_APB_SPONT_NEUR_DISCH',\n",
       " 'L_APB_TA_CONCL',\n",
       " 'L_AXIL_AMP_E',\n",
       " 'L_AXIL_LAT_ED',\n",
       " 'L_DELT_MUPINSTAB',\n",
       " 'L_DELT_MUPSATEL',\n",
       " 'L_DELT_MVA_AMP',\n",
       " 'L_DELT_QUAL_MUPAMP',\n",
       " 'L_DELT_QUAL_MUPDUR',\n",
       " 'L_DELT_QUAL_MUPPOLY',\n",
       " 'L_DELT_QUAN_MUPAMP',\n",
       " 'L_DELT_MUPAMP',\n",
       " 'L_DELT_QUAN_MUPDUR',\n",
       " 'L_DELT_MUPDUR',\n",
       " 'L_DELT_REPSTIM_CMAPAMP',\n",
       " 'L_DELT_REPSTIM_DECR',\n",
       " 'L_DELT_REPSTIM_FACILI',\n",
       " 'L_DELT_REPSTIM_POST_DECR',\n",
       " 'L_DELT_SF_DENSITY',\n",
       " 'L_DELT_SF_JITTER',\n",
       " 'L_DELT_SPONT_DENERV_ACT',\n",
       " 'L_DELT_SPONT_HF_DISCH',\n",
       " 'L_DELT_SPONT_INS_ACT',\n",
       " 'L_DELT_SPONT_NEUR_DISCH',\n",
       " 'L_DELT_TA_CONCL',\n",
       " 'L_LNLBE_MEDD2_LD_EW',\n",
       " 'L_LNLBE_MEDD2_RD_EW',\n",
       " 'L_MEDD2_AMP_WD',\n",
       " 'L_MEDD2_CV_EW',\n",
       " 'L_MEDD2_CV_WD',\n",
       " 'L_MED_AMPR_EW',\n",
       " 'L_MED_AMP_WA',\n",
       " 'L_MED_CV_EW',\n",
       " 'L_MED_LAT_WA',\n",
       " 'L_SUR_AMP_CA',\n",
       " 'L_SUR_CV_CA',\n",
       " 'L_ULND5_AMP_WD',\n",
       " 'L_ULND5_CV_E',\n",
       " 'L_ULND5_CV_EW',\n",
       " 'L_ULND5_ALLCV_EW',\n",
       " 'L_ULND5_CV_WD',\n",
       " 'L_ULN_AMPR_E',\n",
       " 'L_ULN_AMPR_EW',\n",
       " 'L_ULN_AMP_WA',\n",
       " 'L_ULN_BLOCK_EW',\n",
       " 'L_ULN_CV_E',\n",
       " 'L_ULN_CV_EW',\n",
       " 'L_ULN_ALLCV_EW',\n",
       " 'L_ULN_LAT_WA',\n",
       " 'R_ADM_MUPINSTAB',\n",
       " 'R_ADM_MUPSATEL',\n",
       " 'R_ADM_MVA_AMP',\n",
       " 'R_ADM_QUAL_MUPAMP',\n",
       " 'R_ADM_QUAL_MUPDUR',\n",
       " 'R_ADM_QUAL_MUPPOLY',\n",
       " 'R_ADM_QUAN_MUPAMP',\n",
       " 'R_ADM_MUPAMP',\n",
       " 'R_ADM_QUAN_MUPDUR',\n",
       " 'R_ADM_MUPDUR',\n",
       " 'R_ADM_REPSTIM_CMAPAMP',\n",
       " 'R_ADM_REPSTIM_DECR',\n",
       " 'R_ADM_REPSTIM_FACILI',\n",
       " 'R_ADM_REPSTIM_POST_DECR',\n",
       " 'R_ADM_SF_DENSITY',\n",
       " 'R_ADM_SF_JITTER',\n",
       " 'R_ADM_SPONT_DENERV_ACT',\n",
       " 'R_ADM_SPONT_HF_DISCH',\n",
       " 'R_ADM_SPONT_INS_ACT',\n",
       " 'R_ADM_SPONT_NEUR_DISCH',\n",
       " 'R_ADM_TA_CONCL',\n",
       " 'R_APB_MUPINSTAB',\n",
       " 'R_APB_MUPSATEL',\n",
       " 'R_APB_MVA_AMP',\n",
       " 'R_APB_QUAL_MUPAMP',\n",
       " 'R_APB_QUAL_MUPDUR',\n",
       " 'R_APB_QUAL_MUPPOLY',\n",
       " 'R_APB_QUAN_MUPAMP',\n",
       " 'R_APB_MUPAMP',\n",
       " 'R_APB_QUAN_MUPDUR',\n",
       " 'R_APB_MUPDUR',\n",
       " 'R_APB_REPSTIM_CMAPAMP',\n",
       " 'R_APB_REPSTIM_DECR',\n",
       " 'R_APB_REPSTIM_FACILI',\n",
       " 'R_APB_REPSTIM_POST_DECR',\n",
       " 'R_APB_SF_DENSITY',\n",
       " 'R_APB_SF_JITTER',\n",
       " 'R_APB_SPONT_DENERV_ACT',\n",
       " 'R_APB_SPONT_HF_DISCH',\n",
       " 'R_APB_SPONT_INS_ACT',\n",
       " 'R_APB_SPONT_NEUR_DISCH',\n",
       " 'R_APB_TA_CONCL',\n",
       " 'R_AXIL_AMP_E',\n",
       " 'R_AXIL_LAT_ED',\n",
       " 'R_DELT_MUPINSTAB',\n",
       " 'R_DELT_MUPSATEL',\n",
       " 'R_DELT_MVA_AMP',\n",
       " 'R_DELT_QUAL_MUPAMP',\n",
       " 'R_DELT_QUAL_MUPDUR',\n",
       " 'R_DELT_QUAL_MUPPOLY',\n",
       " 'R_DELT_QUAN_MUPAMP',\n",
       " 'R_DELT_MUPAMP',\n",
       " 'R_DELT_QUAN_MUPDUR',\n",
       " 'R_DELT_MUPDUR',\n",
       " 'R_DELT_REPSTIM_CMAPAMP',\n",
       " 'R_DELT_REPSTIM_DECR',\n",
       " 'R_DELT_REPSTIM_FACILI',\n",
       " 'R_DELT_REPSTIM_POST_DECR',\n",
       " 'R_DELT_SF_DENSITY',\n",
       " 'R_DELT_SF_JITTER',\n",
       " 'R_DELT_SPONT_DENERV_ACT',\n",
       " 'R_DELT_SPONT_HF_DISCH',\n",
       " 'R_DELT_SPONT_INS_ACT',\n",
       " 'R_DELT_SPONT_NEUR_DISCH',\n",
       " 'R_DELT_TA_CONCL',\n",
       " 'R_LNLBE_MEDD2_LD_EW',\n",
       " 'R_LNLBE_MEDD2_RD_EW',\n",
       " 'R_MEDD2_AMP_WD',\n",
       " 'R_MEDD2_CV_EW',\n",
       " 'R_MEDD2_CV_WD',\n",
       " 'R_MED_AMPR_EW',\n",
       " 'R_MED_AMP_WA',\n",
       " 'R_MED_CV_EW',\n",
       " 'R_MED_LAT_WA',\n",
       " 'R_SUR_AMP_CA',\n",
       " 'R_SUR_CV_CA',\n",
       " 'R_ULND5_AMP_WD',\n",
       " 'R_ULND5_CV_E',\n",
       " 'R_ULND5_CV_EW',\n",
       " 'R_ULND5_ALLCV_EW',\n",
       " 'R_ULND5_CV_WD',\n",
       " 'R_ULN_AMPR_E',\n",
       " 'R_ULN_AMPR_EW',\n",
       " 'R_ULN_AMP_WA',\n",
       " 'R_ULN_BLOCK_EW',\n",
       " 'R_ULN_CV_E',\n",
       " 'R_ULN_CV_EW',\n",
       " 'R_ULN_ALLCV_EW',\n",
       " 'R_ULN_LAT_WA',\n",
       " 'L_ADM_DENERV',\n",
       " 'L_ADM_FORCE',\n",
       " 'L_ADM_MUDENS',\n",
       " 'L_ADM_MUSCLE_VOL',\n",
       " 'L_ADM_MVA_RECRUIT',\n",
       " 'L_ADM_NEUR_ACT',\n",
       " 'L_OTHER_ADM_NEUR_ACT',\n",
       " 'L_ADM_QUAN_MUPPOLY',\n",
       " 'L_ADM_VOL_ACT',\n",
       " 'L_ADM_ALLAMP_WA',\n",
       " 'L_APB_DENERV',\n",
       " 'L_APB_FORCE',\n",
       " 'L_APB_MUDENS',\n",
       " 'L_APB_MUSCLE_VOL',\n",
       " 'L_APB_MVA_RECRUIT',\n",
       " 'L_APB_NEUR_ACT',\n",
       " 'L_APB_QUAN_MUPPOLY',\n",
       " 'L_APB_VOL_ACT',\n",
       " 'L_APB_ALLAMP_WA',\n",
       " 'L_AXIL_DEL',\n",
       " 'L_DELT_DENERV',\n",
       " 'L_DELT_FORCE',\n",
       " 'L_DELT_MUDENS',\n",
       " 'L_DELT_MUSCLE_VOL',\n",
       " 'L_DELT_MVA_RECRUIT',\n",
       " 'L_DELT_NEUR_ACT',\n",
       " 'L_OTHER_DELT_NEUR_ACT',\n",
       " 'L_DELT_QUAN_MUPPOLY',\n",
       " 'L_DELT_VOL_ACT',\n",
       " 'L_DELT_ALLAMP',\n",
       " 'L_LNLBE_APB_DENERV',\n",
       " 'L_LNLBE_APB_DE_REGEN',\n",
       " 'L_LNLBE_APB_MALOSS',\n",
       " 'L_LNLBE_APB_MUDENS',\n",
       " 'L_LNLBE_APB_MUSIZE',\n",
       " 'L_LNLBE_APB_NEUR_ACT',\n",
       " 'L_LNLBE_MEDD2_BLOCK_EW',\n",
       " 'L_LNLBE_MEDD2_DIFSLOW_WD',\n",
       " 'L_LNLBE_MEDD2_DISP_EW',\n",
       " 'L_LNLBE_MEDD2_SALOSS_EW',\n",
       " 'L_LNLBE_MED_BLOCK',\n",
       " 'L_MED_BLOCK_EW',\n",
       " 'L_LNLBE_MED_DIFSLOW',\n",
       " 'L_LNLC8_ADM_DENERV',\n",
       " 'L_LNLLP_ADM_DENERV',\n",
       " 'L_LNLC8_ADM_DE_REGEN',\n",
       " 'L_LNLLP_ADM_DE_REGEN',\n",
       " 'L_LNLC8_ADM_MALOSS',\n",
       " 'L_LNLLP_ADM_MALOSS',\n",
       " 'L_LNLC8_ADM_MUDENS',\n",
       " 'L_LNLLP_ADM_MUDENS',\n",
       " 'L_LNLC8_ADM_MUSIZE',\n",
       " 'L_LNLLP_ADM_MUSIZE',\n",
       " 'L_LNLC8_ADM_NEUR_ACT',\n",
       " 'L_LNLLP_ADM_NEUR_ACT',\n",
       " 'L_LNLC8_LP_ADM_DENERV',\n",
       " 'L_LNLC8_LP_ADM_DE_REGEN',\n",
       " 'L_LNLC8_LP_ADM_MALOSS',\n",
       " 'L_LNLC8_LP_ADM_MUDENS',\n",
       " 'L_LNLC8_LP_ADM_MUSIZE',\n",
       " 'L_LNLC8_LP_ADM_NEUR_ACT',\n",
       " 'L_LNLLP_APB_DENERV',\n",
       " 'L_LNLT1_APB_DENERV',\n",
       " 'L_LNLT1_LP_APB_DENERV',\n",
       " 'L_LNLLP_APB_DE_REGEN',\n",
       " 'L_LNLT1_APB_DE_REGEN',\n",
       " 'L_LNLT1_LP_APB_DE_REGEN',\n",
       " 'L_LNLLP_APB_MALOSS',\n",
       " 'L_LNLT1_APB_MALOSS',\n",
       " 'L_LNLT1_LP_APB_MALOSS',\n",
       " 'L_LNLLP_APB_MUDENS',\n",
       " 'L_LNLT1_APB_MUDENS',\n",
       " 'L_LNLT1_LP_APB_MUDENS',\n",
       " 'L_LNLLP_APB_MUSIZE',\n",
       " 'L_LNLT1_APB_MUSIZE',\n",
       " 'L_LNLT1_LP_APB_MUSIZE',\n",
       " 'L_LNLLP_APB_NEUR_ACT',\n",
       " 'L_LNLT1_APB_NEUR_ACT',\n",
       " 'L_LNLT1_LP_APB_NEUR_ACT',\n",
       " 'L_LNLT1_LP_BE_APB_NEUR_ACT',\n",
       " 'L_DIFFN_LNLW_APB_NEUR_ACT',\n",
       " 'L_LNLLP_ULND5_SALOSS',\n",
       " 'L_LNLPC5_DIFFN_DELT_NEUR_ACT',\n",
       " 'L_LNLT1_LP_BE_APB_DENERV',\n",
       " 'L_LNLT1_LP_BE_APB_DE_REGEN',\n",
       " 'L_LNLT1_LP_BE_APB_MALOSS',\n",
       " 'L_LNLT1_LP_BE_APB_MUDENS',\n",
       " 'L_LNLT1_LP_BE_APB_MUSIZE',\n",
       " 'L_LNLW_ADM_DENERV',\n",
       " 'L_LNLW_ADM_DE_REGEN',\n",
       " 'L_LNLW_ADM_MALOSS',\n",
       " 'L_LNLW_ADM_MUDENS',\n",
       " 'L_LNLW_ADM_MUSIZE',\n",
       " 'L_LNLW_ADM_NEUR_ACT',\n",
       " 'L_LNLW_ULND5_BLOCK_WD',\n",
       " 'L_LNLW_ULND5_DISP_WD',\n",
       " 'L_LNLW_ULND5_LD_WD',\n",
       " 'L_LNLW_ULND5_RD_WD',\n",
       " 'L_LNLW_ULND5_SALOSS',\n",
       " 'L_LNLW_ULN_BLOCK',\n",
       " 'L_LNL_DIFFN_ADM_NEUR_ACT',\n",
       " 'L_LNL_ISCH_PATHO',\n",
       " 'L_LNL_ISCH_SEV',\n",
       " 'L_LNL_ISCH_SALOSS_CA',\n",
       " 'L_MEDD2_ALLAMP_WD',\n",
       " 'L_MEDD2_ALLCV_EW',\n",
       " 'L_MEDD2_ALLCV_WD',\n",
       " 'L_MEDD2_AMPR_EW',\n",
       " 'L_MEDD2_LD_EW',\n",
       " 'L_MEDD2_RD_EW',\n",
       " 'L_MEDD2_LSLOW_EW',\n",
       " 'L_MEDD2_DSLOW_EW',\n",
       " 'L_MED_ALLCV_EW',\n",
       " 'L_MED_ALLDEL_WA',\n",
       " 'L_MED_LD_EW',\n",
       " 'L_MED_RD_EW',\n",
       " 'L_MED_RDLDCV_EW',\n",
       " 'L_MED_DCV_EW',\n",
       " 'L_MYAS_ADM_MUDENS',\n",
       " 'L_OTHER_ADM_MUDENS',\n",
       " 'L_MYAS_ADM_NMT',\n",
       " 'L_MYAS_APB_MUDENS',\n",
       " 'L_MYAS_APB_NMT',\n",
       " 'L_MYAS_DELT_MUDENS',\n",
       " 'L_OTHER_DELT_MUDENS',\n",
       " 'L_MYAS_DELT_NMT',\n",
       " 'L_MYAS_OTHER_ADM_MUDENS',\n",
       " 'L_MYAS_OTHER_DELT_MUDENS',\n",
       " 'L_MYDY_ADM_DENERV',\n",
       " 'L_MYOP_ADM_DENERV',\n",
       " 'L_MYDY_ADM_DE_REGEN',\n",
       " 'L_MYOP_ADM_DE_REGEN',\n",
       " 'L_MYDY_ADM_MUDENS',\n",
       " 'L_MYOP_ADM_MUDENS',\n",
       " 'L_MYOP_MYDY_ADM_MUDENS',\n",
       " 'L_MUSCLE_ADM_MUDENS',\n",
       " 'L_LNL_DIFFN_ADM_MUDENS',\n",
       " 'L_MYDY_ADM_MUSIZE',\n",
       " 'L_MYOP_ADM_MUSIZE',\n",
       " 'L_MYDY_APB_DENERV',\n",
       " 'L_MYOP_APB_DENERV',\n",
       " 'L_MYDY_APB_DE_REGEN',\n",
       " 'L_MYOP_APB_DE_REGEN',\n",
       " 'L_MYDY_APB_MUDENS',\n",
       " 'L_MYOP_APB_MUDENS',\n",
       " 'L_MYOP_MYDY_APB_MUDENS',\n",
       " 'L_MUSCLE_APB_MUDENS',\n",
       " 'L_LNL_DIFFN_APB_MUDENS',\n",
       " 'L_DIFFN_LNLW_APB_MUDENS',\n",
       " 'L_MYDY_APB_MUSIZE',\n",
       " 'L_MYOP_APB_MUSIZE',\n",
       " 'L_MYDY_DELT_DENERV',\n",
       " 'L_MYOP_DELT_DENERV',\n",
       " 'L_MYDY_DELT_DE_REGEN',\n",
       " 'L_MYOP_DELT_DE_REGEN',\n",
       " 'L_MYDY_DELT_MUDENS',\n",
       " 'L_MYOP_DELT_MUDENS',\n",
       " 'L_MYOP_MYDY_DELT_MUDENS',\n",
       " 'L_MUSCLE_DELT_MUDENS',\n",
       " 'L_LNLPC5_DIFFN_DELT_MUDENS',\n",
       " 'L_MYDY_DELT_MUSIZE',\n",
       " 'L_MYOP_DELT_MUSIZE',\n",
       " 'L_MYOP_MYDY_ADM_DENERV',\n",
       " 'L_MYOP_MYDY_ADM_DE_REGEN',\n",
       " 'L_OTHER_ADM_DE_REGEN',\n",
       " 'L_MUSCLE_ADM_DE_REGEN',\n",
       " 'L_MYOP_MYDY_ADM_MUSIZE',\n",
       " 'L_OTHER_ADM_MUSIZE',\n",
       " 'L_MUSCLE_ADM_MUSIZE',\n",
       " 'L_MYOP_MYDY_APB_DENERV',\n",
       " 'L_MYOP_MYDY_APB_DE_REGEN',\n",
       " 'L_MYOP_MYDY_APB_MUSIZE',\n",
       " 'L_MYOP_MYDY_DELT_DENERV',\n",
       " 'L_MYOP_MYDY_DELT_DE_REGEN',\n",
       " 'L_OTHER_DELT_DE_REGEN',\n",
       " 'L_MUSCLE_DELT_DE_REGEN',\n",
       " 'L_MYOP_MYDY_DELT_MUSIZE',\n",
       " 'L_OTHER_DELT_MUSIZE',\n",
       " 'L_MUSCLE_DELT_MUSIZE',\n",
       " 'L_OTHER_ADM_DENERV',\n",
       " 'L_OTHER_ADM_MALOSS',\n",
       " 'L_OTHER_ADM_NMT',\n",
       " 'L_OTHER_AXIL_BLOCK',\n",
       " 'L_OTHER_DELT_DENERV',\n",
       " 'L_OTHER_DELT_MALOSS',\n",
       " 'L_OTHER_DELT_NMT',\n",
       " 'L_OTHER_ISCH_BLOCK',\n",
       " 'L_OTHER_ISCH_DIFSLOW',\n",
       " 'L_OTHER_ISCH_DISP',\n",
       " 'L_OTHER_ISCH_SALOSS',\n",
       " 'L_OTHER_ULND5_SALOSS',\n",
       " 'L_OTHER_ULN_BLOCK_WA',\n",
       " 'L_SUR_ALLAMP_CA',\n",
       " 'L_SUR_ALLCV_CA',\n",
       " 'L_SUR_LD_CA',\n",
       " 'L_SUR_RD_CA',\n",
       " 'L_SUR_LSLOW_CA',\n",
       " 'L_SUR_DSLOW_CA',\n",
       " 'L_ULND5_ALLAMP_WD',\n",
       " 'L_ULND5_ALLCV_E',\n",
       " 'L_ULND5_ALLCV_WD',\n",
       " 'L_ULND5_AMPR_E',\n",
       " 'L_ULND5_AMPR_EW',\n",
       " 'L_ULND5_DSLOW_EW',\n",
       " 'L_ULN_ALLCV_E',\n",
       " 'L_ULN_ALLDEL_WA',\n",
       " 'L_ULN_BLOCK_E',\n",
       " 'L_ULN_DCV_EW',\n",
       " 'L_ULN_LD_WA',\n",
       " 'L_ULN_RD_WA',\n",
       " 'L_ULN_RDLDDEL',\n",
       " 'L_ULN_DCV_WA',\n",
       " 'R_ADM_DENERV',\n",
       " 'R_ADM_FORCE',\n",
       " 'R_ADM_MUDENS',\n",
       " 'R_ADM_MUSCLE_VOL',\n",
       " 'R_ADM_MVA_RECRUIT',\n",
       " 'R_ADM_NEUR_ACT',\n",
       " 'R_OTHER_ADM_NEUR_ACT',\n",
       " 'R_ADM_QUAN_MUPPOLY',\n",
       " 'R_ADM_VOL_ACT',\n",
       " 'R_ADM_ALLAMP_WA',\n",
       " 'R_APB_DENERV',\n",
       " 'R_APB_FORCE',\n",
       " 'R_APB_MUDENS',\n",
       " 'R_APB_MUSCLE_VOL',\n",
       " 'R_APB_MVA_RECRUIT',\n",
       " 'R_APB_NEUR_ACT',\n",
       " 'R_APB_QUAN_MUPPOLY',\n",
       " 'R_APB_VOL_ACT',\n",
       " 'R_APB_ALLAMP_WA',\n",
       " 'R_AXIL_DEL',\n",
       " 'R_DELT_DENERV',\n",
       " 'R_DELT_FORCE',\n",
       " 'R_DELT_MUDENS',\n",
       " 'R_DELT_MUSCLE_VOL',\n",
       " 'R_DELT_MVA_RECRUIT',\n",
       " 'R_DELT_NEUR_ACT',\n",
       " 'R_OTHER_DELT_NEUR_ACT',\n",
       " 'R_DELT_QUAN_MUPPOLY',\n",
       " 'R_DELT_VOL_ACT',\n",
       " 'R_DELT_ALLAMP',\n",
       " 'R_LNLBE_APB_DENERV',\n",
       " 'R_LNLBE_APB_DE_REGEN',\n",
       " 'R_LNLBE_APB_MALOSS',\n",
       " 'R_LNLBE_APB_MUDENS',\n",
       " 'R_LNLBE_APB_MUSIZE',\n",
       " 'R_LNLBE_APB_NEUR_ACT',\n",
       " 'R_LNLBE_MEDD2_BLOCK_EW',\n",
       " 'R_LNLBE_MEDD2_DIFSLOW_WD',\n",
       " 'R_LNLBE_MEDD2_DISP_EW',\n",
       " 'R_LNLBE_MEDD2_SALOSS_EW',\n",
       " 'R_LNLBE_MED_BLOCK',\n",
       " 'R_MED_BLOCK_EW',\n",
       " 'R_LNLBE_MED_DIFSLOW',\n",
       " 'R_LNLC8_ADM_DENERV',\n",
       " 'R_LNLLP_ADM_DENERV',\n",
       " 'R_LNLC8_ADM_DE_REGEN',\n",
       " 'R_LNLLP_ADM_DE_REGEN',\n",
       " 'R_LNLC8_ADM_MALOSS',\n",
       " 'R_LNLLP_ADM_MALOSS',\n",
       " 'R_LNLC8_ADM_MUDENS',\n",
       " 'R_LNLLP_ADM_MUDENS',\n",
       " 'R_LNLC8_ADM_MUSIZE',\n",
       " 'R_LNLLP_ADM_MUSIZE',\n",
       " 'R_LNLC8_ADM_NEUR_ACT',\n",
       " 'R_LNLLP_ADM_NEUR_ACT',\n",
       " 'R_LNLC8_LP_ADM_DENERV',\n",
       " 'R_LNLC8_LP_ADM_DE_REGEN',\n",
       " 'R_LNLC8_LP_ADM_MALOSS',\n",
       " 'R_LNLC8_LP_ADM_MUDENS',\n",
       " 'R_LNLC8_LP_ADM_MUSIZE',\n",
       " 'R_LNLC8_LP_ADM_NEUR_ACT',\n",
       " 'R_LNLLP_APB_DENERV',\n",
       " 'R_LNLT1_APB_DENERV',\n",
       " 'R_LNLT1_LP_APB_DENERV',\n",
       " 'R_LNLLP_APB_DE_REGEN',\n",
       " 'R_LNLT1_APB_DE_REGEN',\n",
       " 'R_LNLT1_LP_APB_DE_REGEN',\n",
       " 'R_LNLLP_APB_MALOSS',\n",
       " 'R_LNLT1_APB_MALOSS',\n",
       " 'R_LNLT1_LP_APB_MALOSS',\n",
       " 'R_LNLLP_APB_MUDENS',\n",
       " 'R_LNLT1_APB_MUDENS',\n",
       " 'R_LNLT1_LP_APB_MUDENS',\n",
       " 'R_LNLLP_APB_MUSIZE',\n",
       " 'R_LNLT1_APB_MUSIZE',\n",
       " 'R_LNLT1_LP_APB_MUSIZE',\n",
       " 'R_LNLLP_APB_NEUR_ACT',\n",
       " 'R_LNLT1_APB_NEUR_ACT',\n",
       " 'R_LNLT1_LP_APB_NEUR_ACT',\n",
       " 'R_LNLT1_LP_BE_APB_NEUR_ACT',\n",
       " 'R_DIFFN_LNLW_APB_NEUR_ACT',\n",
       " 'R_LNLLP_ULND5_SALOSS',\n",
       " 'R_LNLPC5_DIFFN_DELT_NEUR_ACT',\n",
       " 'R_LNLT1_LP_BE_APB_DENERV',\n",
       " 'R_LNLT1_LP_BE_APB_DE_REGEN',\n",
       " 'R_LNLT1_LP_BE_APB_MALOSS',\n",
       " 'R_LNLT1_LP_BE_APB_MUDENS',\n",
       " 'R_LNLT1_LP_BE_APB_MUSIZE',\n",
       " 'R_LNLW_ADM_DENERV',\n",
       " 'R_LNLW_ADM_DE_REGEN',\n",
       " 'R_LNLW_ADM_MALOSS',\n",
       " 'R_LNLW_ADM_MUDENS',\n",
       " 'R_LNLW_ADM_MUSIZE',\n",
       " 'R_LNLW_ADM_NEUR_ACT',\n",
       " 'R_LNLW_ULND5_BLOCK_WD',\n",
       " 'R_LNLW_ULND5_DISP_WD',\n",
       " 'R_LNLW_ULND5_LD_WD',\n",
       " 'R_LNLW_ULND5_RD_WD',\n",
       " 'R_LNLW_ULND5_SALOSS',\n",
       " 'R_LNLW_ULN_BLOCK',\n",
       " 'R_LNL_DIFFN_ADM_NEUR_ACT',\n",
       " 'R_LNL_ISCH_PATHO',\n",
       " 'R_LNL_ISCH_SEV',\n",
       " 'R_LNL_ISCH_SALOSS_CA',\n",
       " 'R_MEDD2_ALLAMP_WD',\n",
       " 'R_MEDD2_ALLCV_EW',\n",
       " 'R_MEDD2_ALLCV_WD',\n",
       " 'R_MEDD2_AMPR_EW',\n",
       " 'R_MEDD2_LD_EW',\n",
       " 'R_MEDD2_RD_EW',\n",
       " 'R_MEDD2_LSLOW_EW',\n",
       " 'R_MEDD2_DSLOW_EW',\n",
       " 'R_MED_ALLCV_EW',\n",
       " 'R_MED_ALLDEL_WA',\n",
       " 'R_MED_LD_EW',\n",
       " 'R_MED_RD_EW',\n",
       " 'R_MED_RDLDCV_EW',\n",
       " 'R_MED_DCV_EW',\n",
       " 'R_MYAS_ADM_MUDENS',\n",
       " 'R_OTHER_ADM_MUDENS',\n",
       " 'R_MYAS_ADM_NMT',\n",
       " 'R_MYAS_APB_MUDENS',\n",
       " 'R_MYAS_APB_NMT',\n",
       " 'R_MYAS_DELT_MUDENS',\n",
       " 'R_OTHER_DELT_MUDENS',\n",
       " 'R_MYAS_DELT_NMT',\n",
       " 'R_MYAS_OTHER_ADM_MUDENS',\n",
       " 'R_MYAS_OTHER_DELT_MUDENS',\n",
       " 'R_MYDY_ADM_DENERV',\n",
       " 'R_MYOP_ADM_DENERV',\n",
       " 'R_MYDY_ADM_DE_REGEN',\n",
       " 'R_MYOP_ADM_DE_REGEN',\n",
       " 'R_MYDY_ADM_MUDENS',\n",
       " 'R_MYOP_ADM_MUDENS',\n",
       " 'R_MYOP_MYDY_ADM_MUDENS',\n",
       " 'R_MUSCLE_ADM_MUDENS',\n",
       " 'R_LNL_DIFFN_ADM_MUDENS',\n",
       " 'R_MYDY_ADM_MUSIZE',\n",
       " 'R_MYOP_ADM_MUSIZE',\n",
       " 'R_MYDY_APB_DENERV',\n",
       " 'R_MYOP_APB_DENERV',\n",
       " 'R_MYDY_APB_DE_REGEN',\n",
       " 'R_MYOP_APB_DE_REGEN',\n",
       " 'R_MYDY_APB_MUDENS',\n",
       " 'R_MYOP_APB_MUDENS',\n",
       " 'R_MYOP_MYDY_APB_MUDENS',\n",
       " 'R_MUSCLE_APB_MUDENS',\n",
       " 'R_LNL_DIFFN_APB_MUDENS',\n",
       " 'R_DIFFN_LNLW_APB_MUDENS',\n",
       " 'R_MYDY_APB_MUSIZE',\n",
       " 'R_MYOP_APB_MUSIZE',\n",
       " 'R_MYDY_DELT_DENERV',\n",
       " 'R_MYOP_DELT_DENERV',\n",
       " 'R_MYDY_DELT_DE_REGEN',\n",
       " 'R_MYOP_DELT_DE_REGEN',\n",
       " 'R_MYDY_DELT_MUDENS',\n",
       " 'R_MYOP_DELT_MUDENS',\n",
       " 'R_MYOP_MYDY_DELT_MUDENS',\n",
       " 'R_MUSCLE_DELT_MUDENS',\n",
       " 'R_LNLPC5_DIFFN_DELT_MUDENS',\n",
       " 'R_MYDY_DELT_MUSIZE',\n",
       " 'R_MYOP_DELT_MUSIZE',\n",
       " 'R_MYOP_MYDY_ADM_DENERV',\n",
       " 'R_MYOP_MYDY_ADM_DE_REGEN',\n",
       " 'R_OTHER_ADM_DE_REGEN',\n",
       " 'R_MUSCLE_ADM_DE_REGEN',\n",
       " 'R_MYOP_MYDY_ADM_MUSIZE',\n",
       " 'R_OTHER_ADM_MUSIZE',\n",
       " 'R_MUSCLE_ADM_MUSIZE',\n",
       " 'R_MYOP_MYDY_APB_DENERV',\n",
       " 'R_MYOP_MYDY_APB_DE_REGEN',\n",
       " 'R_MYOP_MYDY_APB_MUSIZE',\n",
       " 'R_MYOP_MYDY_DELT_DENERV',\n",
       " 'R_MYOP_MYDY_DELT_DE_REGEN',\n",
       " 'R_OTHER_DELT_DE_REGEN',\n",
       " 'R_MUSCLE_DELT_DE_REGEN',\n",
       " 'R_MYOP_MYDY_DELT_MUSIZE',\n",
       " 'R_OTHER_DELT_MUSIZE',\n",
       " 'R_MUSCLE_DELT_MUSIZE',\n",
       " 'R_OTHER_ADM_DENERV',\n",
       " 'R_OTHER_ADM_MALOSS',\n",
       " 'R_OTHER_ADM_NMT',\n",
       " 'R_OTHER_AXIL_BLOCK',\n",
       " 'R_OTHER_DELT_DENERV',\n",
       " 'R_OTHER_DELT_MALOSS',\n",
       " 'R_OTHER_DELT_NMT',\n",
       " 'R_OTHER_ISCH_BLOCK',\n",
       " 'R_OTHER_ISCH_DIFSLOW',\n",
       " 'R_OTHER_ISCH_DISP',\n",
       " 'R_OTHER_ISCH_SALOSS',\n",
       " 'R_OTHER_ULND5_SALOSS',\n",
       " 'R_OTHER_ULN_BLOCK_WA',\n",
       " 'R_SUR_ALLAMP_CA',\n",
       " 'R_SUR_ALLCV_CA',\n",
       " 'R_SUR_LD_CA',\n",
       " 'R_SUR_RD_CA',\n",
       " 'R_SUR_LSLOW_CA',\n",
       " 'R_SUR_DSLOW_CA',\n",
       " 'R_ULND5_ALLAMP_WD',\n",
       " 'R_ULND5_ALLCV_E',\n",
       " 'R_ULND5_ALLCV_WD',\n",
       " 'R_ULND5_AMPR_E',\n",
       " 'R_ULND5_AMPR_EW',\n",
       " 'R_ULND5_DSLOW_EW',\n",
       " 'R_ULN_ALLCV_E',\n",
       " 'R_ULN_ALLDEL_WA',\n",
       " 'R_ULN_BLOCK_E',\n",
       " 'R_ULN_DCV_EW',\n",
       " 'R_ULN_LD_WA',\n",
       " 'R_ULN_RD_WA',\n",
       " 'R_ULN_RDLDDEL',\n",
       " 'R_ULN_DCV_WA',\n",
       " 'L_AXIL_RD_ED',\n",
       " 'DIFFN_DUMMY_1',\n",
       " 'L_DE_REGEN_ADM_NMT',\n",
       " 'DIFFN_DUMMY_2',\n",
       " 'L_DE_REGEN_APB_NMT',\n",
       " 'L_DE_REGEN_DELT_NMT',\n",
       " 'DIFFN_DUMMY_3',\n",
       " 'L_DIFFN_LNLW_ADM_MUDENS',\n",
       " 'L_DIFFN_LNLW_ADM_NEUR_ACT',\n",
       " 'L_DIFFN_LNLW_ULN_BLOCK_WA',\n",
       " 'L_DIFFN_LNL_ISCH_SALOSS',\n",
       " 'L_LNLC8_LP_E_ADM_MUDENS',\n",
       " 'L_LNLC8_LP_E_ADM_NEUR_ACT',\n",
       " 'L_LNLW_MEDD2_RD_WD',\n",
       " 'L_LNL_DIFFN_APB_DENERV',\n",
       " 'L_LNL_DIFFN_APB_DE_REGEN',\n",
       " 'L_LNL_DIFFN_APB_MUSIZE',\n",
       " 'L_MEDD2_BLOCK_EW',\n",
       " 'L_MEDD2_DIFSLOW_EW',\n",
       " 'L_MED_DIFSLOW_EW',\n",
       " 'L_MUSCLE_ADM_DENERV',\n",
       " 'L_MUSCLE_APB_DENERV',\n",
       " 'L_MUSCLE_DELT_DENERV',\n",
       " 'L_MYAS_DE_REGEN_ADM_NMT',\n",
       " 'L_MYAS_DE_REGEN_DELT_NMT',\n",
       " 'L_NMT_ADM_DENERV',\n",
       " 'L_NMT_APB_DENERV',\n",
       " 'L_NMT_DELT_DENERV',\n",
       " 'L_OTHER_NMT_ADM_DENERV',\n",
       " 'L_OTHER_NMT_DELT_DENERV',\n",
       " 'L_SUR_DIFSLOW_CA',\n",
       " 'L_SUR_DISP_CA',\n",
       " 'L_ULN_DIFSLOW_EW',\n",
       " 'R_AXIL_RD_ED',\n",
       " 'R_DE_REGEN_ADM_NMT',\n",
       " 'R_DE_REGEN_APB_NMT',\n",
       " 'R_DE_REGEN_DELT_NMT',\n",
       " 'R_DIFFN_LNLW_ADM_MUDENS',\n",
       " 'R_DIFFN_LNLW_ADM_NEUR_ACT',\n",
       " 'R_DIFFN_LNLW_ULN_BLOCK_WA',\n",
       " 'R_DIFFN_LNL_ISCH_SALOSS',\n",
       " 'R_LNLC8_LP_E_ADM_MUDENS',\n",
       " 'R_LNLC8_LP_E_ADM_NEUR_ACT',\n",
       " 'R_LNLW_MEDD2_RD_WD',\n",
       " 'R_LNL_DIFFN_APB_DENERV',\n",
       " 'R_LNL_DIFFN_APB_DE_REGEN',\n",
       " 'R_LNL_DIFFN_APB_MUSIZE',\n",
       " 'R_MEDD2_BLOCK_EW',\n",
       " 'R_MEDD2_DIFSLOW_EW',\n",
       " 'R_MED_DIFSLOW_EW',\n",
       " 'R_MUSCLE_ADM_DENERV',\n",
       " 'R_MUSCLE_APB_DENERV',\n",
       " 'R_MUSCLE_DELT_DENERV',\n",
       " 'R_MYAS_DE_REGEN_ADM_NMT',\n",
       " 'R_MYAS_DE_REGEN_DELT_NMT',\n",
       " 'R_NMT_ADM_DENERV',\n",
       " 'R_NMT_APB_DENERV',\n",
       " 'R_NMT_DELT_DENERV',\n",
       " 'R_OTHER_NMT_ADM_DENERV',\n",
       " 'R_OTHER_NMT_DELT_DENERV',\n",
       " 'R_SUR_DIFSLOW_CA',\n",
       " 'R_SUR_DISP_CA',\n",
       " 'R_ULN_DIFSLOW_EW',\n",
       " 'DIFFN_SEV',\n",
       " 'DIFFN_TYPE',\n",
       " 'DIFFN_SENS_SEV',\n",
       " 'L_DIFFN_LNLW_ULND5_BLOCK_WD',\n",
       " 'L_DIFFN_LNLW_ULND5_DISP_WD',\n",
       " 'L_MEDD2_DIFSLOW_WD',\n",
       " 'L_MED_DIFSLOW_WA',\n",
       " 'L_MED_RD_WA',\n",
       " 'L_MED_LD_WA',\n",
       " 'L_ULN_DIFSLOW_WA',\n",
       " 'L_ULN_RD_EW',\n",
       " 'L_ULN_LD_EW',\n",
       " 'R_DIFFN_LNLW_ULND5_BLOCK_WD',\n",
       " 'R_DIFFN_LNLW_ULND5_DISP_WD',\n",
       " 'R_MEDD2_DIFSLOW_WD',\n",
       " 'R_MED_DIFSLOW_WA',\n",
       " 'R_MED_RD_WA',\n",
       " 'R_MED_LD_WA',\n",
       " 'R_ULN_DIFSLOW_WA',\n",
       " 'R_ULN_RD_EW',\n",
       " 'R_ULN_LD_EW',\n",
       " 'L_ADM_DE_REGEN',\n",
       " 'L_ADM_MULOSS',\n",
       " 'L_APB_DE_REGEN',\n",
       " 'L_APB_MULOSS',\n",
       " 'L_AXIL_BLOCK_ED',\n",
       " 'L_AXIL_DCV',\n",
       " 'L_LNLPC5_AXIL_DIFSLOW',\n",
       " 'L_AXIL_DIFSLOW_ED',\n",
       " 'L_DELT_DE_REGEN',\n",
       " 'L_DELT_MULOSS',\n",
       " 'L_DIFFN_ADM_MALOSS',\n",
       " 'L_DIFFN_ADM_NEUR_ACT',\n",
       " 'L_DIFFN_APB_NEUR_ACT',\n",
       " 'L_DIFFN_DELT_NEUR_ACT',\n",
       " 'L_DIFFN_ISCH_BLOCK',\n",
       " 'L_DIFFN_ISCH_DIFSLOW',\n",
       " 'L_DIFFN_ISCH_SALOSS',\n",
       " 'L_DIFFN_ISCH_DISP',\n",
       " 'L_SUR_BLOCK_CA',\n",
       " 'L_SUR_EFFAXLOSS',\n",
       " 'L_SUR_SALOSS',\n",
       " 'L_DIFFN_LNLW_ADM_DENERV',\n",
       " 'L_DIFFN_LNLW_ADM_DE_REGEN',\n",
       " 'L_DIFFN_LNLW_ADM_MUSIZE',\n",
       " 'L_DIFFN_LNLW_APB_DENERV',\n",
       " 'L_DIFFN_LNLW_APB_MALOSS',\n",
       " 'L_DIFFN_LNLW_APB_MUSIZE',\n",
       " 'L_DIFFN_LNLW_MEDD2_DISP_WD',\n",
       " 'L_MEDD2_DISP_EW',\n",
       " 'L_DIFFN_LNLW_MEDD2_SALOSS',\n",
       " 'L_DIFFN_LNLW_ULND5_SALOSS',\n",
       " 'L_LNLC8_LP_E_ADM_DENERV',\n",
       " 'L_LNLC8_LP_E_ADM_DE_REGEN',\n",
       " 'L_LNLC8_LP_E_ADM_MALOSS',\n",
       " 'L_LNLC8_LP_E_ADM_MUSIZE',\n",
       " 'L_LNLE_ULND5_RD_E',\n",
       " 'L_LNLE_ULND5_SALOSS',\n",
       " 'L_LNLE_ULN_BLOCK',\n",
       " 'L_LNLPC5_DIFFN_DELT_DENERV',\n",
       " 'L_LNLPC5_DIFFN_DELT_MALOSS',\n",
       " 'L_LNLPC5_DIFFN_DELT_MUSIZE',\n",
       " 'L_LNLW_MEDD2_LD_WD',\n",
       " 'L_MEDD2_RD_WD',\n",
       " 'L_MEDD2_LD_WD',\n",
       " 'L_LNL_DIFFN_ADM_DENERV',\n",
       " 'L_LNL_DIFFN_ADM_MALOSS',\n",
       " 'L_LNL_DIFFN_ADM_MUSIZE',\n",
       " 'L_LNL_DIFFN_ULND5_SALOSS',\n",
       " 'L_MEDD2_DISP_EWD',\n",
       " 'L_MEDD2_DSLOW_WD',\n",
       " 'L_MEDD2_EFFAXLOSS',\n",
       " 'L_MED_DCV_WA',\n",
       " 'L_OTHER_ULND5_LD',\n",
       " 'L_OTHER_ULND5_RD',\n",
       " 'L_ULND5_BLOCK_E',\n",
       " 'L_ULND5_BLOCK_EW',\n",
       " 'L_ULND5_DIFSLOW_EW',\n",
       " 'L_ULND5_DSLOW_E',\n",
       " 'L_ULND5_DSLOW_WD',\n",
       " 'L_ULND5_EFFAXLOSS',\n",
       " 'L_ULN_BLOCK_WA',\n",
       " 'L_ULN_DCV_E',\n",
       " 'R_ADM_DE_REGEN',\n",
       " 'R_ADM_MULOSS',\n",
       " 'R_APB_DE_REGEN',\n",
       " 'R_APB_MULOSS',\n",
       " 'R_AXIL_BLOCK_ED',\n",
       " 'R_AXIL_DCV',\n",
       " 'R_LNLPC5_AXIL_DIFSLOW',\n",
       " 'R_AXIL_DIFSLOW_ED',\n",
       " 'R_DELT_DE_REGEN',\n",
       " 'R_DELT_MULOSS',\n",
       " 'R_DIFFN_ADM_MALOSS',\n",
       " 'R_DIFFN_ADM_NEUR_ACT',\n",
       " 'R_DIFFN_APB_NEUR_ACT',\n",
       " 'R_DIFFN_DELT_NEUR_ACT',\n",
       " 'R_DIFFN_ISCH_BLOCK',\n",
       " 'R_DIFFN_ISCH_DIFSLOW',\n",
       " 'R_DIFFN_ISCH_SALOSS',\n",
       " 'R_DIFFN_ISCH_DISP',\n",
       " 'R_SUR_BLOCK_CA',\n",
       " 'R_SUR_EFFAXLOSS',\n",
       " 'R_SUR_SALOSS',\n",
       " 'R_DIFFN_LNLW_ADM_DENERV',\n",
       " 'R_DIFFN_LNLW_ADM_DE_REGEN',\n",
       " 'R_DIFFN_LNLW_ADM_MUSIZE',\n",
       " 'R_DIFFN_LNLW_APB_DENERV',\n",
       " 'R_DIFFN_LNLW_APB_MALOSS',\n",
       " 'R_DIFFN_LNLW_APB_MUSIZE',\n",
       " 'R_DIFFN_LNLW_MEDD2_DISP_WD',\n",
       " 'R_MEDD2_DISP_EW',\n",
       " 'R_DIFFN_LNLW_MEDD2_SALOSS',\n",
       " 'R_DIFFN_LNLW_ULND5_SALOSS',\n",
       " 'R_LNLC8_LP_E_ADM_DENERV',\n",
       " 'R_LNLC8_LP_E_ADM_DE_REGEN',\n",
       " 'R_LNLC8_LP_E_ADM_MALOSS',\n",
       " 'R_LNLC8_LP_E_ADM_MUSIZE',\n",
       " 'R_LNLE_ULND5_RD_E',\n",
       " 'R_LNLE_ULND5_SALOSS',\n",
       " 'R_LNLE_ULN_BLOCK',\n",
       " 'R_LNLPC5_DIFFN_DELT_DENERV',\n",
       " 'R_LNLPC5_DIFFN_DELT_MALOSS',\n",
       " 'R_LNLPC5_DIFFN_DELT_MUSIZE',\n",
       " 'R_LNLW_MEDD2_LD_WD',\n",
       " 'R_MEDD2_RD_WD',\n",
       " 'R_MEDD2_LD_WD',\n",
       " 'R_LNL_DIFFN_ADM_DENERV',\n",
       " 'R_LNL_DIFFN_ADM_MALOSS',\n",
       " 'R_LNL_DIFFN_ADM_MUSIZE',\n",
       " 'R_LNL_DIFFN_ULND5_SALOSS',\n",
       " 'R_MEDD2_DISP_EWD',\n",
       " 'R_MEDD2_DSLOW_WD',\n",
       " 'R_MEDD2_EFFAXLOSS',\n",
       " 'R_MED_DCV_WA',\n",
       " 'R_OTHER_ULND5_LD',\n",
       " 'R_OTHER_ULND5_RD',\n",
       " 'R_ULND5_BLOCK_E',\n",
       " 'R_ULND5_BLOCK_EW',\n",
       " 'R_ULND5_DIFSLOW_EW',\n",
       " 'R_ULND5_DSLOW_E',\n",
       " 'R_ULND5_DSLOW_WD',\n",
       " 'R_ULND5_EFFAXLOSS',\n",
       " 'R_ULN_BLOCK_WA',\n",
       " 'R_ULN_DCV_E',\n",
       " 'L_ULN_DIFSLOW_E',\n",
       " 'L_LNLE_ULN_DIFSLOW',\n",
       " 'L_ULN_RDLDCV_E',\n",
       " 'L_LNLE_ADM_MALOSS',\n",
       " 'R_ULN_DIFSLOW_E',\n",
       " 'R_LNLE_ULN_DIFSLOW',\n",
       " 'R_ULN_RDLDCV_E',\n",
       " 'R_LNLE_ADM_MALOSS',\n",
       " 'DIFFN_DISTR',\n",
       " 'DIFFN_MOT_SEV',\n",
       " 'L_DIFFN_ADM_MUDENS',\n",
       " 'L_DIFFN_APB_MUDENS',\n",
       " 'L_DIFFN_DELT_MUDENS',\n",
       " 'L_LNLE_DIFFN_ULND5_BLOCK_E',\n",
       " 'L_LNLE_DIFFN_ULND5_DIFSLOW_E',\n",
       " 'L_LNLE_DIFFN_ULND5_DIFSLOW_WD',\n",
       " 'L_LNLE_DIFFN_ULND5_DISP_E',\n",
       " 'L_OTHER_ULND5_DIFSLOW',\n",
       " 'L_LNLPC5_DELT_MALOSS',\n",
       " 'L_MEDD2_BLOCK_WD',\n",
       " 'R_DIFFN_ADM_MUDENS',\n",
       " 'R_DIFFN_APB_MUDENS',\n",
       " 'R_DIFFN_DELT_MUDENS',\n",
       " 'R_LNLE_DIFFN_ULND5_BLOCK_E',\n",
       " 'R_LNLE_DIFFN_ULND5_DIFSLOW_E',\n",
       " 'R_LNLE_DIFFN_ULND5_DIFSLOW_WD',\n",
       " 'R_LNLE_DIFFN_ULND5_DISP_E',\n",
       " 'R_LNLPC5_DELT_MALOSS',\n",
       " 'R_MEDD2_BLOCK_WD',\n",
       " 'L_DIFFN_APB_MALOSS',\n",
       " 'L_DIFFN_MED_DIFSLOW',\n",
       " 'L_DIFFN_AXIL_BLOCK',\n",
       " 'L_DIFFN_AXIL_DIFSLOW',\n",
       " 'L_DIFFN_LNLW_APB_DE_REGEN',\n",
       " 'L_DIFFN_DELT_MALOSS',\n",
       " 'R_OTHER_ULND5_DIFSLOW',\n",
       " 'L_LNLPC5_DELT_NEUR_ACT',\n",
       " 'L_LNLPC5_DELT_MUDENS',\n",
       " 'L_ULND5_DIFSLOW_E',\n",
       " 'L_DIFFN_MEDD2_DIFSLOW',\n",
       " 'L_DIFFN_MEDD2_SALOSS',\n",
       " 'L_ULND5_DIFSLOW_WD',\n",
       " 'L_DIFFN_MED_BLOCK',\n",
       " 'R_ULND5_DIFSLOW_E',\n",
       " 'R_ULND5_DIFSLOW_WD',\n",
       " 'L_DIFFN_ULND5_SALOSS',\n",
       " 'L_LNLE_ADM_NEUR_ACT',\n",
       " 'L_LNLE_ULND5_LD_E',\n",
       " 'L_ULND5_RD_E',\n",
       " 'L_LNLE_ULND5_DIFSLOW',\n",
       " 'L_LNLPC5_DIFFN_DELT_DE_REGEN',\n",
       " 'L_ULND5_RD_WD',\n",
       " 'L_LNLW_APB_NEUR_ACT',\n",
       " 'L_ULND5_LD_E',\n",
       " 'L_ULND5_LD_WD',\n",
       " 'L_ULND5_LSLOW_E',\n",
       " 'L_ULND5_LSLOW_WD',\n",
       " 'L_LNLW_MEDD2_DISP_WD',\n",
       " 'L_LNL_DIFFN_ADM_DE_REGEN',\n",
       " 'L_ULND5_BLOCK_WD',\n",
       " 'L_ULND5_DISP_EWD',\n",
       " 'L_ULND5_DISP_BED',\n",
       " 'R_DIFFN_APB_MALOSS',\n",
       " 'R_DIFFN_MED_DIFSLOW',\n",
       " 'L_OTHER_ULND5_DISP',\n",
       " 'L_ULND5_DISP_E',\n",
       " 'R_DIFFN_AXIL_BLOCK',\n",
       " 'R_DIFFN_AXIL_DIFSLOW',\n",
       " 'R_DIFFN_DELT_MALOSS',\n",
       " 'R_LNLPC5_DELT_NEUR_ACT',\n",
       " 'R_LNLPC5_DELT_MUDENS',\n",
       " 'R_DIFFN_LNLW_APB_DE_REGEN',\n",
       " 'R_DIFFN_MEDD2_DIFSLOW',\n",
       " 'R_DIFFN_MEDD2_SALOSS',\n",
       " 'R_DIFFN_MED_BLOCK',\n",
       " 'R_DIFFN_ULND5_SALOSS',\n",
       " 'R_LNLE_ADM_NEUR_ACT',\n",
       " 'R_LNLE_ULND5_LD_E',\n",
       " 'R_ULND5_RD_E',\n",
       " 'R_LNLPC5_DIFFN_DELT_DE_REGEN',\n",
       " 'R_LNLE_ULND5_DIFSLOW',\n",
       " 'R_ULND5_RD_WD',\n",
       " 'R_LNLW_APB_NEUR_ACT',\n",
       " 'R_ULND5_LD_E',\n",
       " 'R_ULND5_LD_WD',\n",
       " 'R_ULND5_LSLOW_E',\n",
       " 'R_ULND5_LSLOW_WD',\n",
       " 'R_LNLW_MEDD2_DISP_WD',\n",
       " 'R_LNL_DIFFN_ADM_DE_REGEN',\n",
       " 'R_ULND5_BLOCK_WD',\n",
       " 'R_ULND5_DISP_EWD',\n",
       " 'R_ULND5_DISP_BED',\n",
       " 'R_OTHER_ULND5_DISP',\n",
       " 'R_ULND5_DISP_E',\n",
       " 'L_DIFFN_ULND5_DIFSLOW',\n",
       " 'L_LNLLP_E_ULND5_SALOSS',\n",
       " 'L_DIFFN_LNLW_ADM_MALOSS',\n",
       " 'L_DIFFN_ULN_DIFSLOW',\n",
       " 'L_LNLW_MEDD2_BLOCK_WD',\n",
       " 'L_MEDD2_DISP_WD',\n",
       " 'L_LNLW_MEDD2_SALOSS_WD',\n",
       " 'L_MEDD2_LSLOW_WD',\n",
       " 'L_DIFFN_MEDD2_BLOCK',\n",
       " 'L_DIFFN_MEDD2_DISP',\n",
       " 'L_MEDD2_SALOSS',\n",
       " 'L_LNLW_APB_MALOSS',\n",
       " 'L_MED_RDLDDEL',\n",
       " 'L_LNLW_MED_BLOCK',\n",
       " 'L_LNLE_ADM_MUDENS',\n",
       " 'R_DIFFN_ULND5_DIFSLOW',\n",
       " 'R_LNLLP_E_ULND5_SALOSS',\n",
       " 'R_DIFFN_LNLW_ADM_MALOSS',\n",
       " 'R_DIFFN_ULN_DIFSLOW',\n",
       " 'R_LNLW_MEDD2_BLOCK_WD',\n",
       " 'R_MEDD2_DISP_WD',\n",
       " 'L_LNLW_APB_MUDENS',\n",
       " 'R_LNLE_ADM_MUDENS',\n",
       " 'R_LNLW_MEDD2_SALOSS_WD',\n",
       " 'R_MEDD2_LSLOW_WD',\n",
       " 'R_DIFFN_MEDD2_BLOCK',\n",
       " 'R_DIFFN_MEDD2_DISP',\n",
       " 'R_MEDD2_SALOSS',\n",
       " 'R_LNLW_APB_MALOSS',\n",
       " 'R_MED_RDLDDEL',\n",
       " 'R_LNLW_MED_BLOCK',\n",
       " 'R_LNLW_APB_MUDENS',\n",
       " 'L_DIFFN_ULN_BLOCK',\n",
       " 'L_DIFFN_ADM_DENERV',\n",
       " 'L_DIFFN_ADM_MUSIZE',\n",
       " 'L_DIFFN_APB_DENERV',\n",
       " 'L_DIFFN_APB_MUSIZE',\n",
       " 'L_DIFFN_DELT_DENERV',\n",
       " 'L_DIFFN_DELT_MUSIZE',\n",
       " 'L_ADM_MALOSS',\n",
       " 'L_LNLE_ULND5_BLOCK_E',\n",
       " 'L_LNLE_ADM_MUSIZE',\n",
       " 'R_DIFFN_ADM_DENERV',\n",
       " 'L_LNLE_ADM_DENERV',\n",
       " 'L_ADM_MUSIZE',\n",
       " 'L_DIFFN_ADM_DE_REGEN',\n",
       " 'R_DIFFN_ADM_MUSIZE',\n",
       " 'R_DIFFN_APB_DENERV',\n",
       " 'R_DIFFN_APB_MUSIZE',\n",
       " 'L_ADM_EFFMUS',\n",
       " 'R_DIFFN_DELT_DENERV',\n",
       " 'R_DIFFN_DELT_MUSIZE',\n",
       " 'L_ADM_NMT',\n",
       " 'R_LNLE_ULND5_BLOCK_E',\n",
       " 'L_LNLE_ADM_DE_REGEN',\n",
       " 'L_LNLE_ULN_TIME',\n",
       " 'L_LNLPC5_DELT_DENERV',\n",
       " 'L_DELT_MALOSS',\n",
       " 'L_DIFFN_DELT_DE_REGEN',\n",
       " 'L_MED_BLOCK_WA',\n",
       " 'L_LNLPC5_DELT_MUSIZE',\n",
       " 'L_APB_MALOSS',\n",
       " 'L_LNLW_APB_MUSIZE',\n",
       " 'L_DIFFN_APB_DE_REGEN',\n",
       " 'L_ULND5_DISP_BEW',\n",
       " 'L_ULND5_DISP_WD',\n",
       " 'L_DELT_EFFMUS',\n",
       " 'R_DELT_MALOSS',\n",
       " 'L_DELT_MUSIZE',\n",
       " 'R_DIFFN_DELT_DE_REGEN',\n",
       " 'L_DELT_NMT',\n",
       " 'L_LNLPC5_AXIL_PATHO',\n",
       " 'L_LNLPC5_AXIL_SEV',\n",
       " 'L_LNLPC5_AXIL_TIME',\n",
       " 'L_LNLPC5_DELT_DE_REGEN',\n",
       " 'R_DIFFN_ULN_BLOCK',\n",
       " 'R_ADM_MALOSS',\n",
       " 'R_LNLE_ADM_MUSIZE',\n",
       " 'R_LNLPC5_DELT_MUSIZE',\n",
       " 'L_LNLE_ULND5_DISP_E',\n",
       " 'L_OTHER_ULND5_BLOCK',\n",
       " 'L_ULND5_DISP_EED',\n",
       " 'L_DIFFN_ULND5_BLOCK',\n",
       " 'L_DIFFN_ULND5_DISP',\n",
       " 'L_ULND5_SALOSS',\n",
       " 'L_LNLE_ULN_PATHO',\n",
       " 'L_LNLE_ULN_SEV',\n",
       " 'R_DIFFN_ADM_DE_REGEN',\n",
       " 'L_LNLW_APB_DENERV',\n",
       " 'L_APB_EFFMUS',\n",
       " 'L_APB_MUSIZE',\n",
       " 'R_MED_BLOCK_WA',\n",
       " 'L_APB_NMT',\n",
       " 'L_LNLW_APB_DE_REGEN',\n",
       " 'L_LNLW_MED_TIME',\n",
       " 'L_LNLW_MED_PATHO',\n",
       " ...]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order = stochastic_minDegree_and_minFill(factor_to_graph(factors))\n",
    "order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elimination order width: 8\n",
      "Wall time: 1min 53s\n"
     ]
    }
   ],
   "source": [
    "# The last test, has 1041 nodes and 80592 parameters\n",
    "\n",
    "print(\"Elimination order width: %d\" % width(factors, order))\n",
    "%time jt=elimination_to_jointree(order,factors,outcomeSpace)\n",
    "\n",
    "# The jointree is massive, so we dont plot it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task4    Approximate inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 A function that let the user specify the number of chains.<br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this function, we ask user to specify the number of chains and randomly init all chains for the next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_chain_nb(factor, os, nb, e):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `factor`, a factor dict\n",
    "    `os`, outcomespace dict\n",
    "    `nb`, number of chains\n",
    "    `e`, evidence dict\n",
    "    \n",
    "    \n",
    "    Returns a new dict which stores information needed for the next step\n",
    "    \"\"\" \n",
    "    f = deepcopy(factor)\n",
    "    os = deepcopy(os)\n",
    "    for ee in e:\n",
    "        os = evidence(ee, e[ee], os)\n",
    "    # all need to be given    \n",
    "    variable_list = list(os.keys() - e.keys())\n",
    "    ll = list(sorted(os.keys()))\n",
    "    # dict sotring mapping info. like node A : index 0\n",
    "    variable_mapping = dict(zip(ll, range(len(os.keys()))))\n",
    "    # reverse dict of variable_mapping\n",
    "    index_mapping = dict(zip(range(len(os.keys())), ll))\n",
    "    # init chains\n",
    "    chains = [deque() for i in range(nb)]\n",
    "    for i in range(len(chains)):\n",
    "        l = []\n",
    "        for v in sorted(os.keys()):\n",
    "            if v in e.keys():\n",
    "                l.append(e[v])\n",
    "            else:\n",
    "                l.append(random.choice(os[v]))\n",
    "        chains[i].append(tuple(l))\n",
    "    return {'factor':f, 'os':os, 'chains':chains, 'vm':variable_mapping, 'im':index_mapping, 'vl':variable_list}\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usage\n",
    "d = set_chain_nb(medium_factor, medium_os, 2, {'Disease':'PFC', 'Sick':'yes'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 A function to mix up chains until convergence.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mixed function check if a window size of samples from several chains are mixed or not. It return R vector as the return value.<br> burn-in fucntion start burn-in period of Gibbs, we check if indicator vector arrays from several chains are mixed or not. If mixed or iterate to the max step, we can start sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixed(samples): \n",
    "    \"\"\"\n",
    "    argument \n",
    "    `sample`, samples list\n",
    "\n",
    "    Returns a vector R\n",
    "    \"\"\"\n",
    "    # convert to numpy\n",
    "    a = np.array(samples)\n",
    "    # get sample size\n",
    "    nn = a.shape[1]\n",
    "    # get chain size\n",
    "    cc = a.shape[0]\n",
    "    # compute theta_j\n",
    "    thetas = []\n",
    "    for c in a:\n",
    "        theta = None\n",
    "        # samples\n",
    "        for s in c:\n",
    "            if theta is None:\n",
    "                theta = deepcopy(s)\n",
    "            else:\n",
    "                theta += s\n",
    "        theta = theta / nn\n",
    "        thetas.append(theta)\n",
    "    # compute theta_mean\n",
    "    mean_theta = None\n",
    "    for t in thetas:\n",
    "        if mean_theta is None:\n",
    "            mean_theta = deepcopy(t)\n",
    "        else:\n",
    "            mean_theta += t\n",
    "    mean_theta = mean_theta / cc  \n",
    "    # compute sigma_j\n",
    "    sigmas = []\n",
    "    # chain\n",
    "    it = iter(thetas)\n",
    "    for c in a:\n",
    "        theta = next(it)\n",
    "        sigma = None\n",
    "        # samples\n",
    "        for s in c:\n",
    "            if sigma is None:\n",
    "                sigma = (s - theta) ** 2\n",
    "            else:\n",
    "                sigma += (s - theta) ** 2\n",
    "        sigma = sigma / (nn - 1)\n",
    "        sigmas.append(sigma)\n",
    "    # compute W \n",
    "    W = None\n",
    "    for s in sigmas:\n",
    "        if W is None:\n",
    "            W = deepcopy(s)\n",
    "        else:\n",
    "            W += s\n",
    "    W = W / cc\n",
    "    # compute B\n",
    "    B = None\n",
    "    for t in thetas:\n",
    "        if B is None:\n",
    "            B = (t - mean_theta) ** 2\n",
    "        else:\n",
    "            B += (t - mean_theta) ** 2          \n",
    "    B = (B * nn) / (cc - 1)\n",
    "    # remove rows which W is 0\n",
    "    W = W[np.nonzero(W)]\n",
    "    B = B[np.nonzero(W)]\n",
    "    # compute R\n",
    "    R = np.sqrt((W + ((B - W) / nn)) / W) \n",
    "    return R\n",
    "\n",
    "def s_normalize(f):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f`, a factor dict\n",
    "    \n",
    "    Returns a new factor dict which is the normalised version of f\n",
    "    \"\"\"\n",
    "    table = list()\n",
    "    sum = 0\n",
    "    i = 0\n",
    "    for k, p in f['table'].items():\n",
    "        sum = sum + p\n",
    "        i += 1\n",
    "    if sum == 0:\n",
    "        for k, p in f['table'].items():\n",
    "            table.append((k, 1/i))\n",
    "    else:\n",
    "        for k, p in f['table'].items():\n",
    "            table.append((k, p/sum))\n",
    "    return {'dom': f['dom'], 'table': odict(table)}\n",
    "\n",
    "def burnin(d, max_step = 1000, window = 20):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `d`, information dict from the previous step\n",
    "    `max_step`, max iteration step for burin-in period\n",
    "    `window`, window size for checking mixed\n",
    "    \n",
    "    Returns a new dict which stores information needed for the next step\n",
    "    \"\"\"\n",
    "    # get all needed info\n",
    "    f = d['factor']\n",
    "    chains = deepcopy(d['chains'])\n",
    "    samples = [deque() for i in range(len(chains))]\n",
    "    os = d['os']\n",
    "    variable_list = d['vl']\n",
    "    variable_mapping = d['vm']\n",
    "    im = d['im']\n",
    "    # init indicator\n",
    "    indicator = dict()\n",
    "    ii = 0\n",
    "    for k, v in os.items():\n",
    "        for i in v:\n",
    "            indicator[(k, i)] = ii\n",
    "            ii += 1\n",
    "    vvv = deepcopy(variable_list)\n",
    "        \n",
    "    # step\n",
    "    for i in range(max_step):\n",
    "        # each chain\n",
    "        for j in range(len(chains)):\n",
    "            a = chains[j]\n",
    "            sss = [0] * len(indicator)\n",
    "            # random shuffle the variable order\n",
    "            random.shuffle(vvv)\n",
    "            for v in vvv:      \n",
    "                # set other variable as fixed value\n",
    "                temp_os = deepcopy(os)\n",
    "                temp_list = deepcopy(variable_list)\n",
    "                temp_list.remove(v)\n",
    "                for other in temp_list:\n",
    "                    temp_os = evidence(other, a[-1][variable_mapping[other]], temp_os)\n",
    "                # to compute P(A|fixed values), we need to join A and its children node CPT\n",
    "                # get children node\n",
    "                related_list = set()\n",
    "                for kk in f:\n",
    "                    if v in f[kk]['dom']:\n",
    "                        related_list.add(kk)\n",
    "                related_list = list(related_list)\n",
    "                related_list.sort()\n",
    "                temp_list = related_list.copy()\n",
    "                temp_list.remove(v)\n",
    "                # get current sample\n",
    "                current_sample = tuple([a[-1][variable_mapping[i]] for i in temp_list])\n",
    "                # compute P(A|other fixed values)\n",
    "                first = None\n",
    "                p = None\n",
    "                for node in related_list:\n",
    "                    if first is None:\n",
    "                        first = node\n",
    "                        p = f[first]\n",
    "                        for kkk in p['dom']:\n",
    "                            if kkk != v:\n",
    "                                p = marginalize(p, kkk, temp_os)\n",
    "                    else:\n",
    "                        p = join(p, f[node], temp_os)\n",
    "                p = s_normalize(p)\n",
    "                # get probablities\n",
    "                prob_list = list(p['table'].values())\n",
    "                # use a random number to generate our choice\n",
    "                random_number = random.random()\n",
    "                choice = 0\n",
    "                for ii in range(1, len(prob_list) + 1):\n",
    "                    cum_sum_prob = sum(prob_list[: ii])\n",
    "                    if cum_sum_prob >= random_number:\n",
    "                        choice = ii - 1\n",
    "                        break                \n",
    "                choice = os[v][choice] \n",
    "                # set indicator vector\n",
    "                sss[indicator[(v, choice)]] += 1\n",
    "                # set new sample\n",
    "                new_sample = list(a[-1])\n",
    "                new_sample[variable_mapping[v]] = choice\n",
    "                new_sample = tuple(new_sample)\n",
    "                chains[j].append(new_sample)\n",
    "                chains[j].popleft()\n",
    "            # add indicator vector as a sample to judge if mixed\n",
    "            samples[j].append(tuple(sss))\n",
    "        # when we have enough samples to judge if mixed\n",
    "        if len(samples[0]) >= window:\n",
    "            s = None\n",
    "            # first time we achieve this, we directly check\n",
    "            if s is None:\n",
    "                s = 0\n",
    "                # check R\n",
    "                r = mixed(samples)    \n",
    "                if all(r < 1.1):\n",
    "                    return {'factor':f, 'chains':chains, 'os':os, 'vl':variable_list, 'vm':variable_mapping}\n",
    "            # the next time we need to resample after window size steps and check\n",
    "            else:\n",
    "                s += 1\n",
    "                if s == window:\n",
    "                    r = mixed(samples)    \n",
    "                    if all(r < 1.1):\n",
    "                        return {'factor':f, 'chains':chains, 'os':os, 'vl':variable_list, 'vm':variable_mapping}\n",
    "                    s = 0\n",
    "    return {'factor':f, 'chains':chains, 'os':os, 'vl':variable_list, 'vm':variable_mapping}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usage, d is the return value of set_chain_nb\n",
    "s = burnin(d, 10000000, 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 A function that samples the chains for a specified number of samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Sampling function starts Gibbs sampling and return a pandas datafram which stores samples we generated based on Gibbs sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(d, sample_size):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `d`, information dict from the previous step\n",
    "    `sample_size`, size of samples need to be generated\n",
    "    \n",
    "    Returns a pandas dataframe storing samples we generated\n",
    "    \"\"\"\n",
    "    # get info from dict\n",
    "    f = d['factor']\n",
    "    chains = deepcopy(d['chains'][0])\n",
    "    samples = []\n",
    "    os = d['os']\n",
    "    variable_list = d['vl']\n",
    "    variable_mapping = d['vm']\n",
    "    position = None\n",
    "    \n",
    "    vvv = deepcopy(variable_list)\n",
    "    # we need to iterator sample_size * len(variable_list) times\n",
    "    for i in range(sample_size * len(variable_list)):\n",
    "        # random shuffle the order we resample\n",
    "        random.shuffle(vvv)\n",
    "        for v in vvv:\n",
    "            a = chains\n",
    "            # set other variable as fixed\n",
    "            temp_os = deepcopy(os)\n",
    "            temp_list = deepcopy(variable_list)\n",
    "            temp_list.remove(v)\n",
    "            for other in temp_list:\n",
    "                temp_os = evidence(other, a[-1][variable_mapping[other]], temp_os)\n",
    "            # get children node\n",
    "            related_list = set()\n",
    "            for kk in f:\n",
    "                if v in f[kk]['dom']:\n",
    "                    related_list.add(kk)\n",
    "            related_list = list(related_list)\n",
    "            related_list.sort()\n",
    "            temp_list = related_list.copy()\n",
    "            temp_list.remove(v)\n",
    "            # get current sample\n",
    "            current_sample = tuple([a[-1][variable_mapping[i]] for i in temp_list])\n",
    "            # compute P(A|other fixed values)\n",
    "            first = None\n",
    "            p = None\n",
    "            for node in related_list:\n",
    "                if first is None:\n",
    "                    first = node\n",
    "                    p = f[first]\n",
    "                    for kkk in p['dom']:\n",
    "                        if kkk != v:\n",
    "                            p = marginalize(p, kkk, temp_os)\n",
    "                else:\n",
    "                    p = join(p, f[node], temp_os)\n",
    "            p = s_normalize(p)\n",
    "            # get probabilities\n",
    "            prob_list = list(p['table'].values())\n",
    "            # generate a random number to choose our sample\n",
    "            random_number = random.random()\n",
    "            choice = 0\n",
    "            for ii in range(1, len(prob_list) + 1):\n",
    "                cum_sum_prob = sum(prob_list[: ii])\n",
    "                if cum_sum_prob >= random_number:\n",
    "                    choice = ii - 1\n",
    "                    break\n",
    "            choice = os[v][choice]  \n",
    "            # set new sample value\n",
    "            new_sample = list(a[-1])\n",
    "            new_sample[variable_mapping[v]] = choice\n",
    "            new_sample = tuple(new_sample)\n",
    "            chains.append(new_sample)\n",
    "            chains.popleft()\n",
    "        # add to result list\n",
    "        samples.append(chains[-1])\n",
    "        # when we have enough samples return it as dataframe\n",
    "        if len(samples) == sample_size:\n",
    "            index = list(sorted(os.keys()))\n",
    "            df = pd.DataFrame(samples, columns = index)\n",
    "            return df\n",
    "    index = list(sorted(os.keys()))\n",
    "    df = pd.DataFrame(samples, columns = index)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usage, s is the return value of burnin\n",
    "df = sampling(s, 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 A function to answer queries based on the samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tutorial code\n",
    "def estProbTable(data, var_name, parent_names, outcomeSpace):\n",
    "    \"\"\"\n",
    "    Calculate a dictionary probability table by ML given\n",
    "    `data`, a dictionary or dataframe of observations\n",
    "    `var_name`, the column of the data to be used for the conditioned variable and\n",
    "    `var_outcomes`, a tuple of possible outcomes for the conditiona varible and\n",
    "    `parent_names`, a tuple of columns to be used for the parents and\n",
    "    `parent_outcomes` a tuple of all possible parent outcomes \n",
    "    Return a dictionary containing an estimated conditional probability table.\n",
    "    \"\"\"    \n",
    "    var_outcomes = outcomeSpace[var_name]\n",
    "    parent_outcomes = [outcomeSpace[var] for var in (parent_names)]\n",
    "    # cartesian product to generate a table of all possible outcomes\n",
    "    all_parent_combinations = product(*parent_outcomes)\n",
    "\n",
    "    prob_table = odict()\n",
    "    \n",
    "    for i, parent_combination in enumerate(all_parent_combinations):\n",
    "        cond_array = []\n",
    "        parent_vars = dict(zip(parent_names, parent_combination))\n",
    "        parent_index = allEqualThisIndex(data, **parent_vars)\n",
    "        for var_outcome in var_outcomes:\n",
    "            var_index = (np.asarray(data[var_name])==var_outcome)\n",
    "            prob_table[tuple(list(parent_combination)+[var_outcome])] = (var_index & parent_index).sum()/parent_index.sum()\n",
    "            \n",
    "    return {'dom': tuple(list(parent_names)+[var_name]), 'table': prob_table}\n",
    "\n",
    "\n",
    "\n",
    "def allEqualThisIndex(dict_of_arrays, **fixed_vars):\n",
    "    \"\"\"\n",
    "    Helper function to create a boolean index vector into a tabular data structure,\n",
    "    such that we return True only for rows of the table where, e.g.\n",
    "    column_a=fixed_vars['column_a'] and column_b=fixed_vars['column_b'].\n",
    "    \n",
    "    This is a simple task, but it's not *quite* obvious\n",
    "    for various obscure technical reasons.\n",
    "    \n",
    "    It is perhaps best explained by an example.\n",
    "    \n",
    "    >>> all_equal_this_index(\n",
    "    ...    {'X': [1, 1, 0], Y: [1, 0, 1]},\n",
    "    ...    X=1,\n",
    "    ...    Y=1\n",
    "    ... )\n",
    "    [True, False, False]\n",
    "    \"\"\"\n",
    "    # base index is a boolean vector, everywhere true\n",
    "    first_array = dict_of_arrays[list(dict_of_arrays.keys())[0]]\n",
    "    index = np.ones_like(first_array, dtype=np.bool_)\n",
    "    for var_name, var_val in fixed_vars.items():\n",
    "        index = index & (np.asarray(dict_of_arrays[var_name])==var_val)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gibbs_query function answer the query Q."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def gibbs_query(Q, data, outcomespace):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `Q`, Query variable list\n",
    "    `data`, samples dataframe\n",
    "    `outcomespace`, outcomespace dict\n",
    "    \n",
    "    Returns a table of query\n",
    "    \"\"\"\n",
    "    os = deepcopy(outcomespace)\n",
    "    r = None\n",
    "    # query all variable and join them together\n",
    "    for q in Q:\n",
    "        if r is None:\n",
    "            r = estProbTable(data, q, [], os)\n",
    "        else:\n",
    "            r = join(r, estProbTable(data, q, [], os), os)\n",
    "    return r\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usage, df is the return value of sampling\n",
    "\n",
    "\n",
    "# sample test \n",
    "# r1 = gibbs_query(['A'], df, s['os'])\n",
    "# r2 = gibbs_query(['B'], df, s['os'])\n",
    "# r3 = gibbs_query(['A','B'], df, s['os'])\n",
    "# printFactor(r1)\n",
    "# printFactor(r2)\n",
    "# printFactor(r3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r1 = gibbs_query(['Age'], df, s['os'])\n",
    "# printFactor(r1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "icu_factor test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "icu_factors = {\n",
    "    'H': {\n",
    "        'dom': ('H'),\n",
    "        'table': odict([\n",
    "            ((0,), 0.80),\n",
    "            ((1,), 0.20),\n",
    "        ])\n",
    "    },\n",
    "\n",
    "    'V': {\n",
    "        'dom': ('L', 'H', 'V'),\n",
    "        'table': odict([\n",
    "            ((0, 0, 0), 0.05),\n",
    "            ((0, 0, 1), 0.95),\n",
    "            ((0, 1, 0), 0.99),\n",
    "            ((0, 1, 1), 0.01),\n",
    "            ((1, 0, 0), 0),\n",
    "            ((1, 0, 1), 1),\n",
    "            ((1, 1, 0), 1),\n",
    "            ((1, 1, 1), 0),\n",
    "        ])\n",
    "    },\n",
    "\n",
    "    'C': {\n",
    "        'dom': ('V', 'C'),\n",
    "        'table': odict([\n",
    "            ((0, 0), 0.94),\n",
    "            ((0, 1), 0.04),\n",
    "            ((0, 2), 0.02),\n",
    "            ((1, 0), 0.02),\n",
    "            ((1, 1), 0.26),\n",
    "            ((1, 2), 0.72),\n",
    "        ])\n",
    "    },\n",
    "\n",
    "    'L': {\n",
    "        'dom': ('L'),\n",
    "        'table': odict([\n",
    "            ((0,), 0.95),\n",
    "            ((1,), 0.05),\n",
    "        ])\n",
    "    },\n",
    "\n",
    "    'S': {\n",
    "        'dom': ('L', 'H', 'S'),\n",
    "        'table': odict([\n",
    "            ((0, 0, 0), 0.04),\n",
    "            ((0, 0, 1), 0.96),\n",
    "            ((0, 1, 0), 0.48),\n",
    "            ((0, 1, 1), 0.52),\n",
    "            ((1, 0, 0), 0.95),\n",
    "            ((1, 0, 1), 0.05),\n",
    "            ((1, 1, 0), 0),\n",
    "            ((1, 1, 1), 1),\n",
    "        ])\n",
    "    },\n",
    "\n",
    "    'O': {\n",
    "        'dom': ('S', 'V', 'O'),\n",
    "        'table': odict([\n",
    "            ((0, 0, 0), 0.97),\n",
    "            ((0, 0, 1), 0.01),\n",
    "            ((0, 0, 2), 0.02),\n",
    "            ((0, 1, 0), 0.78),\n",
    "            ((0, 1, 1), 0.19),\n",
    "            ((0, 1, 2), 0.03),\n",
    "            ((1, 0, 0), 0.22),\n",
    "            ((1, 0, 1), 0.76),\n",
    "            ((1, 0, 2), 0.02),\n",
    "            ((1, 1, 0), 0.01),\n",
    "            ((1, 1, 1), 0.01),\n",
    "            ((1, 1, 2), 0.98),\n",
    "        ])\n",
    "    },\n",
    "\n",
    "    'T': {\n",
    "        'dom': ('A', 'T'),\n",
    "        'table': odict([\n",
    "            ((0, 0), 0.30),\n",
    "            ((0, 1), 0.70),\n",
    "            ((1, 0), 1),\n",
    "            ((1, 1), 0),\n",
    "        ])\n",
    "    },\n",
    "\n",
    "    'B': {\n",
    "        'dom': ('O', 'T', 'B'),\n",
    "        'table': odict([\n",
    "            ((0, 0, 0), 1),\n",
    "            ((0, 0, 1), 0),\n",
    "            ((0, 0, 2), 0),\n",
    "            ((0, 1, 0), 0.30),\n",
    "            ((0, 1, 1), 0.62),\n",
    "            ((0, 1, 2), 0.08),\n",
    "            ((1, 0, 0), 0.93),\n",
    "            ((1, 0, 1), 0.07),\n",
    "            ((1, 0, 2), 0),\n",
    "            ((1, 1, 0), 0.02),\n",
    "            ((1, 1, 1), 0.49),\n",
    "            ((1, 1, 2), 0.49),\n",
    "            ((2, 0, 0), 0.90),\n",
    "            ((2, 0, 1), 0.08),\n",
    "            ((2, 0, 2), 0.02),\n",
    "            ((2, 1, 0), 0.01),\n",
    "            ((2, 1, 1), 0.08),\n",
    "            ((2, 1, 2), 0.91),\n",
    "        ])\n",
    "    },\n",
    "\n",
    "    'A': {\n",
    "        'dom': ('A'),\n",
    "        'table': odict([\n",
    "            ((0,), 0.99),\n",
    "            ((1,), 0.01),\n",
    "        ])\n",
    "    }\n",
    "}\n",
    "\n",
    "outcomeSpace = dict(\n",
    "    H=(0, 1),\n",
    "    L=(0, 1),\n",
    "    A=(0, 1),\n",
    "    V=(0, 1),\n",
    "    S=(0, 1),\n",
    "    T=(0, 1),\n",
    "    C=(0, 1, 2),\n",
    "    O=(0, 1, 2),\n",
    "    B=(0, 1, 2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   B |     Pr |\n",
      "|-----+--------|\n",
      "|   0 | 0.0189 |\n",
      "|   1 | 0.4894 |\n",
      "|   2 | 0.4917 |\n"
     ]
    }
   ],
   "source": [
    "d = set_chain_nb(icu_factors, outcomeSpace, 2, {'T':1,'O':1})\n",
    "s = burnin(d, 1000000, 1000)\n",
    "df = sampling(s, 10000)\n",
    "r1 = gibbs_query(['B'], df, s['os'])\n",
    "printFactor(r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   B |   Pr |\n",
      "|-----+------|\n",
      "|   0 | 0.02 |\n",
      "|   1 | 0.49 |\n",
      "|   2 | 0.49 |\n"
     ]
    }
   ],
   "source": [
    "printFactor(query_t3(icu_factors,outcomeSpace,['B'],O=1,T=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   B |    Pr |\n",
      "|-----+-------|\n",
      "|   0 | 0.018 |\n",
      "|   1 | 0.477 |\n",
      "|   2 | 0.505 |\n"
     ]
    }
   ],
   "source": [
    "d = set_chain_nb(icu_factors, outcomeSpace, 2, {'T':1,'O':1})\n",
    "s = burnin(d, 1000, 100)\n",
    "df = sampling(s, 1000)\n",
    "r1 = gibbs_query(['B'], df, s['os'])\n",
    "printFactor(r1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "small_factor test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| xray   |     Pr |\n",
      "|--------+--------|\n",
      "| yes    | 0.9829 |\n",
      "| no     | 0.0171 |\n"
     ]
    }
   ],
   "source": [
    "d = set_chain_nb(small_factor, small_os, 2, {'either':'yes'})\n",
    "s = burnin(d, 1000000, 1000)\n",
    "df = sampling(s, 10000)\n",
    "r1 = gibbs_query(['xray'], df, s['os'])\n",
    "printFactor(r1)\n",
    "\n",
    "\n",
    "# P(xray | either=yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   xray |   Pr |\n",
      "|--------+------|\n",
      "|      0 | 0.98 |\n",
      "|      1 | 0.02 |\n"
     ]
    }
   ],
   "source": [
    "f,o=load_from_file('asia.net')\n",
    "factors,outcomeSpace=ttransform(f,o)\n",
    "printFactor(query_t3(factors,outcomeSpace,['xray'],either=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "medium_factor test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Age        |     Pr |\n",
      "|------------+--------|\n",
      "| 0-3_days   | 0.9447 |\n",
      "| 4-10_days  | 0.0303 |\n",
      "| 11-30_days | 0.025  |\n"
     ]
    }
   ],
   "source": [
    "d = set_chain_nb(medium_factor, medium_os, 2, {'Disease':'PFC', 'Sick':'yes'})\n",
    "s = burnin(d, 100000, 1000)\n",
    "df = sampling(s, 10000)\n",
    "r1 = gibbs_query(['Age'], df, s['os'])\n",
    "printFactor(r1)\n",
    "\n",
    "\n",
    "# P(Age | Disease = PFC, Sick = yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   Age |   Pr |\n",
      "|-------+------|\n",
      "|     0 | 0.95 |\n",
      "|     1 | 0.03 |\n",
      "|     2 | 0.02 |\n"
     ]
    }
   ],
   "source": [
    "f,o=load_from_file('child.net')\n",
    "factors,outcomeSpace=ttransform(f,o)\n",
    "printFactor(query_t3(factors,outcomeSpace,['Age'],Disease=0,Sick=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That's all for the jupyter part, we will analyze all the benchmark in our report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
